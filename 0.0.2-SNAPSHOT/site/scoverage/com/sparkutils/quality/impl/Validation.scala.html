<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/impl/Validation.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality.impl
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality
</span>4 <span style=''>import com.sparkutils.quality.VariablesLookup.Identifiers
</span>5 <span style=''>import com.sparkutils.quality.utils.RuleSuiteDocs.{IdTrEither, LambdaId, OutputExpressionId, RuleId}
</span>6 <span style=''>import com.sparkutils.quality.utils.{Docs, DocsParser, RuleSuiteDocs, WithDocs}
</span>7 <span style=''>import com.sparkutils.quality.{ExpressionLookup, ExpressionRule, HasExpr, HasRuleText, Id, NoOpRunOnPassProcessor, OutputExpression, Rule, RuleLogicUtils, RuleSuite, RunOnPassProcessor, VariablesLookup, namesFromSchema}
</span>8 <span style=''>import org.apache.spark.sql.{Column, DataFrame, QualitySparkUtils, Row, SparkSession}
</span>9 <span style=''>import org.apache.spark.sql.catalyst.expressions.{Expression, LambdaFunction}
</span>10 <span style=''>import org.apache.spark.sql.types.StructType
</span>11 <span style=''>
</span>12 <span style=''>import scala.collection.mutable
</span>13 <span style=''>
</span>14 <span style=''>sealed trait RuleRelevant
</span>15 <span style=''>sealed trait LambdaRelevant
</span>16 <span style=''>sealed trait OutputExpressionRelevant
</span>17 <span style=''>
</span>18 <span style=''>sealed trait HasId {
</span>19 <span style=''>  def id: Id
</span>20 <span style=''>}
</span>21 <span style=''>
</span>22 <span style=''>sealed trait HasOutputText {
</span>23 <span style=''>  def outputText: String
</span>24 <span style=''>}
</span>25 <span style=''>
</span>26 <span style=''>sealed trait HasNonIdText {
</span>27 <span style=''>  def nonIdText: String
</span>28 <span style=''>}
</span>29 <span style=''>
</span>30 <span style=''>/**
</span>31 <span style=''> * Base for RuleWarnings
</span>32 <span style=''> */
</span>33 <span style=''>sealed trait RuleWarning extends HasId with HasOutputText with HasNonIdText {
</span>34 <span style=''>  def warning: String
</span>35 <span style=''>
</span>36 <span style=''>  override def nonIdText: String = </span><span style='background: #AEF1AE'>warning</span><span style=''>
</span>37 <span style=''>
</span>38 <span style=''>  /**
</span>39 <span style=''>   * If the error is syntax based - defined by parsing, rather than any later stage
</span>40 <span style=''>   * @return
</span>41 <span style=''>   */
</span>42 <span style=''>  def syntax: Boolean = </span><span style='background: #F0ADAD'>false</span><span style=''>
</span>43 <span style=''>
</span>44 <span style=''>  def warningText = </span><span style='background: #AEF1AE'>s&quot;$warning, occurred when processing id $id&quot;</span><span style=''>
</span>45 <span style=''>
</span>46 <span style=''>  override def outputText: String = </span><span style='background: #AEF1AE'>warningText</span><span style=''>
</span>47 <span style=''>}
</span>48 <span style=''>
</span>49 <span style=''>sealed trait SyntaxWarning extends RuleWarning {
</span>50 <span style=''>  final override def syntax: Boolean = </span><span style='background: #F0ADAD'>true</span><span style=''>
</span>51 <span style=''>}
</span>52 <span style=''>
</span>53 <span style=''>sealed trait SyntaxNameWarning extends SyntaxWarning {
</span>54 <span style=''>  def name: String
</span>55 <span style=''>}
</span>56 <span style=''>
</span>57 <span style=''>case class LambdaPossibleSOE(id: Id) extends RuleWarning with LambdaRelevant {
</span>58 <span style=''>  val warning = </span><span style='background: #AEF1AE'>&quot;Possible SOE detected&quot;</span><span style=''>
</span>59 <span style=''>}
</span>60 <span style=''>
</span>61 <span style=''>case class NonLambdaDocParameters(id: Id) extends SyntaxWarning {
</span>62 <span style=''>  val warning = </span><span style='background: #AEF1AE'>&quot;Parameter documentation is present on a non lambda expression&quot;</span><span style=''>
</span>63 <span style=''>}
</span>64 <span style=''>
</span>65 <span style=''>case class ExtraDocParameter(id: Id, name: String) extends SyntaxNameWarning with LambdaRelevant {
</span>66 <span style=''>  val warning = </span><span style='background: #AEF1AE'>s&quot;Parameter $name is not found in the lambda expression&quot;</span><span style=''>
</span>67 <span style=''>}
</span>68 <span style=''>
</span>69 <span style=''>/**
</span>70 <span style=''> * Base for RuleErrors
</span>71 <span style=''> */
</span>72 <span style=''>sealed trait RuleError extends HasId with HasOutputText with HasNonIdText {
</span>73 <span style=''>  def error: String
</span>74 <span style=''>
</span>75 <span style=''>  override def nonIdText: String = </span><span style='background: #AEF1AE'>error</span><span style=''>
</span>76 <span style=''>  /**
</span>77 <span style=''>   * If the error is syntax based - defined by parsing, rather than any later stage
</span>78 <span style=''>   * @return
</span>79 <span style=''>   */
</span>80 <span style=''>  def syntax: Boolean = </span><span style='background: #F0ADAD'>false</span><span style=''>
</span>81 <span style=''>
</span>82 <span style=''>  def errorText = </span><span style='background: #AEF1AE'>s&quot;$error occurred when processing id $id&quot;</span><span style=''>
</span>83 <span style=''>
</span>84 <span style=''>  override def outputText: String = </span><span style='background: #AEF1AE'>errorText</span><span style=''>
</span>85 <span style=''>}
</span>86 <span style=''>
</span>87 <span style=''>sealed trait SyntaxError extends RuleError {
</span>88 <span style=''>  final override def syntax: Boolean = </span><span style='background: #F0ADAD'>true</span><span style=''>
</span>89 <span style=''>}
</span>90 <span style=''>
</span>91 <span style=''>sealed trait NameMissingError extends RuleError {
</span>92 <span style=''>  def name: String
</span>93 <span style=''>  final override def error = </span><span style='background: #AEF1AE'>s&quot;Name $name is missing&quot;</span><span style=''>
</span>94 <span style=''>}
</span>95 <span style=''>
</span>96 <span style=''>case class LambdaSyntaxError(id: Id, error: String) extends SyntaxError with LambdaRelevant
</span>97 <span style=''>case class LambdaStackOverflowError(id: Id) extends SyntaxError with LambdaRelevant {
</span>98 <span style=''>  val error = </span><span style='background: #AEF1AE'>&quot;A lambda function seems to infinitely recurse&quot;</span><span style=''>
</span>99 <span style=''>}
</span>100 <span style=''>case class LambdaNameError(name: String, id: Id) extends NameMissingError with LambdaRelevant
</span>101 <span style=''>case class LambdaMultipleImplementationWithSameArityError(name: String, count: Int, argLength: Int, ids: Set[Id]) extends SyntaxError with LambdaRelevant {
</span>102 <span style=''>  val error = </span><span style='background: #AEF1AE'>s&quot;Lambda function $name has $count implementations with $argLength arguments&quot;</span><span style=''>
</span>103 <span style=''>  val id = </span><span style='background: #AEF1AE'>ids.head</span><span style=''>
</span>104 <span style=''>}
</span>105 <span style=''>case class RuleSyntaxError(id: Id, error: String) extends SyntaxError with RuleRelevant
</span>106 <span style=''>case class RuleNameError(name: String, id: Id) extends NameMissingError with RuleRelevant
</span>107 <span style=''>case class OutputRuleSyntaxError(id: Id, error: String) extends SyntaxError with OutputExpressionRelevant
</span>108 <span style=''>case class OutputRuleNameError(name: String, id: Id) extends NameMissingError with OutputExpressionRelevant
</span>109 <span style=''>
</span>110 <span style=''>case class LambdaSparkFunctionNameError(name: String, id: Id) extends NameMissingError with LambdaRelevant
</span>111 <span style=''>case class SparkFunctionNameError(name: String, id: Id) extends NameMissingError with RuleRelevant
</span>112 <span style=''>case class OuputSparkFunctionNameError(name: String, id: Id) extends NameMissingError with OutputExpressionRelevant
</span>113 <span style=''>
</span>114 <span style=''>case class DataFrameSyntaxError(error: String) extends SyntaxError {
</span>115 <span style=''>  val id = </span><span style='background: #AEF1AE'>Validation.dataFrameSyntaxErrorId</span><span style=''>
</span>116 <span style=''>}
</span>117 <span style=''>
</span>118 <span style=''>object Validation {
</span>119 <span style=''>  val unknownSOEId = </span><span style='background: #AEF1AE'>Id(Int.MinValue,Int.MinValue)</span><span style=''>
</span>120 <span style=''>  val dataFrameSyntaxErrorId = </span><span style='background: #AEF1AE'>Id(Int.MinValue+1,Int.MinValue+1)</span><span style=''>
</span>121 <span style=''>}
</span>122 <span style=''>
</span>123 <span style=''>/**
</span>124 <span style=''> * Paramters to pass into showString for debugging / validation
</span>125 <span style=''> * @param numRows defaults to 1000
</span>126 <span style=''> * @param truncate
</span>127 <span style=''> * @param vertical
</span>128 <span style=''> */
</span>129 <span style=''>case class ShowParams(numRows: Int = 1000, truncate: Int = 0, vertical: Boolean = false)
</span>130 <span style=''>
</span>131 <span style=''>trait Validation {
</span>132 <span style=''>
</span>133 <span style=''>  /**
</span>134 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>135 <span style=''>   *
</span>136 <span style=''>   * @param schema which fields should the dataframe have
</span>137 <span style=''>   * @param ruleSuite
</span>138 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>139 <span style=''>   */
</span>140 <span style=''>  def validate(schema: StructType, ruleSuite: RuleSuite): (Set[RuleError], Set[RuleWarning]) = {
</span>141 <span style=''>    val (err, warns, out, docs, exp) = validate(Left(schema), ruleSuite)
</span>142 <span style=''>    </span><span style='background: #AEF1AE'>(err, warns)</span><span style=''>
</span>143 <span style=''>  }
</span>144 <span style=''>
</span>145 <span style=''>  /**
</span>146 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>147 <span style=''>   *
</span>148 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>149 <span style=''>   * @param ruleSuite
</span>150 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>151 <span style=''>   */
</span>152 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite): (Set[RuleError], Set[RuleWarning]) = {
</span>153 <span style=''>    val (err, warns, out, docs, exp) = validate(Right(frame), ruleSuite)
</span>154 <span style=''>    </span><span style='background: #AEF1AE'>(err, warns)</span><span style=''>
</span>155 <span style=''>  }
</span>156 <span style=''>
</span>157 <span style=''>  /**
</span>158 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>159 <span style=''>   *
</span>160 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>161 <span style=''>   * @param ruleSuite
</span>162 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>163 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>164 <span style=''>   */
</span>165 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite, runnerFunction: DataFrame =&gt; Column): (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) =
</span>166 <span style=''>    </span><span style='background: #AEF1AE'>validate(Right(frame), ruleSuite, runnerFunction = Some(runnerFunction))</span><span style=''>
</span>167 <span style=''>
</span>168 <span style=''>  /**
</span>169 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>170 <span style=''>   *
</span>171 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>172 <span style=''>   * @param ruleSuite
</span>173 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>174 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>175 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>176 <span style=''>   */
</span>177 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite, runnerFunction: DataFrame =&gt; Column, transformBeforeShow: DataFrame =&gt; DataFrame): (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) =
</span>178 <span style=''>    </span><span style='background: #AEF1AE'>validate(Right(frame), ruleSuite, runnerFunction = Some(runnerFunction), transformBeforeShow = transformBeforeShow)</span><span style=''>
</span>179 <span style=''>
</span>180 <span style=''>  val emptyDocs = </span><span style='background: #AEF1AE'>Docs()</span><span style=''>
</span>181 <span style=''>
</span>182 <span style=''>  /**
</span>183 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>184 <span style=''>   *
</span>185 <span style=''>   * @param schemaOrFrame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>186 <span style=''>   * @param ruleSuite
</span>187 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>188 <span style=''>   * @param showParams - configure how the output text is formatted using the same options and formatting as dataFrame.show
</span>189 <span style=''>   * @param qualityName - the column name to store the runnerFunction results in
</span>190 <span style=''>   * @param recursiveLambdasSOEIsOk - this signals that finding a recursive lambda SOE should not stop the evaluations - if true it will still try to run any runnerFunction but may not give the correct results
</span>191 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>192 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>193 <span style=''>   */
</span>194 <span style=''>  def validate(schemaOrFrame: Either[StructType, DataFrame], ruleSuite: RuleSuite, showParams: ShowParams = ShowParams(),
</span>195 <span style=''>               runnerFunction: Option[DataFrame =&gt; Column] = None, qualityName: String = &quot;Quality&quot;,
</span>196 <span style=''>               recursiveLambdasSOEIsOk: Boolean = false, transformBeforeShow: DataFrame =&gt; DataFrame = identity):
</span>197 <span style=''>                (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) = {
</span>198 <span style=''>    val schema = </span><span style='background: #AEF1AE'>schemaOrFrame.fold(identity, _.schema)</span><span style=''>
</span>199 <span style=''>
</span>200 <span style=''>    val names = </span><span style='background: #AEF1AE'>namesFromSchema(schema)</span><span style=''>
</span>201 <span style=''>
</span>202 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>203 <span style=''>
</span>204 <span style=''>    val ((lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, lambdas, lambdaDocWarnings, lambadaExpressionLookups)) =
</span>205 <span style=''>      validateLambdas(ruleSuite, recursiveLambdasSOEIsOk, names) match {
</span>206 <span style=''>        case Left(toReturn) =&gt; return toReturn
</span>207 <span style=''>        case Right(result) =&gt; result
</span>208 <span style=''>      }
</span>209 <span style=''>
</span>210 <span style=''>    </span><span style='background: #AEF1AE'>docsWarnings ++= lambdaDocWarnings</span><span style=''>
</span>211 <span style=''>
</span>212 <span style=''>    val (ruleErrors, ruleDocWarnings, rules, outputExpressions, ruleExpressionLookups) = validateRules(ruleSuite, lambdaLookups, names)
</span>213 <span style=''>
</span>214 <span style=''>    </span><span style='background: #AEF1AE'>docsWarnings ++= ruleDocWarnings</span><span style=''>
</span>215 <span style=''>
</span>216 <span style=''>    val (showOut, dfErrors) =
</span>217 <span style=''>      validateAgainstDataFrame(schemaOrFrame, showParams, runnerFunction, qualityName, transformBeforeShow, schema)
</span>218 <span style=''>
</span>219 <span style=''>    </span><span style='background: #AEF1AE'>(unknownLambdaSparkFunctionErrors ++ lambdaArityErrors ++ dfErrors ++ ruleErrors ++ lambdaNameErrors ++ lambdaSyntaxErrors.map(_._2.right.get).toSet,
</span>220 <span style=''></span><span style='background: #AEF1AE'>      potentialOverflows.map( LambdaPossibleSOE ) ++ (Set() ++ docsWarnings)
</span>221 <span style=''></span><span style='background: #AEF1AE'>      , showOut, RuleSuiteDocs(rules, outputExpressions, lambdas), lambadaExpressionLookups ++ ruleExpressionLookups)</span><span style=''>
</span>222 <span style=''>  }
</span>223 <span style=''>
</span>224 <span style=''>  protected def validateAgainstDataFrame(schemaOrFrame: Either[StructType, DataFrame], showParams: ShowParams, runnerFunction: Option[DataFrame =&gt; Column], qualityName: String, transformBeforeShow: DataFrame =&gt; DataFrame, schema: StructType) = {
</span>225 <span style=''>    val basedf = </span><span style='background: #AEF1AE'>schemaOrFrame.right.getOrElse {
</span>226 <span style=''></span><span style='background: #AEF1AE'>      val session = SparkSession.active
</span>227 <span style=''></span><span style='background: #AEF1AE'>      val empty = session.sparkContext.emptyRDD[Row]
</span>228 <span style=''></span><span style='background: #AEF1AE'>      session.createDataFrame(empty, schema)
</span>229 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>230 <span style=''>
</span>231 <span style=''>    val (showOut, dfErrors) =
</span>232 <span style=''>      runnerFunction.fold((&quot;&quot;, Set.empty[RuleError]))(rf =&gt; {
</span>233 <span style=''>        val runner = rf(basedf)
</span>234 <span style=''>        try {
</span>235 <span style=''>          val withRules = basedf.withColumn(qualityName, runner)
</span>236 <span style=''>          val transformed = transformBeforeShow(withRules)
</span>237 <span style=''>          (QualitySparkUtils.toString(transformed, showParams), Set.empty)
</span>238 <span style=''>        } catch {
</span>239 <span style=''>          case e: Throwable =&gt; (&quot;&quot;, Set(DataFrameSyntaxError(e.getMessage)))
</span>240 <span style=''>        }
</span>241 <span style=''>      })
</span>242 <span style=''>    </span><span style='background: #AEF1AE'>(showOut, dfErrors)</span><span style=''>
</span>243 <span style=''>  }
</span>244 <span style=''>
</span>245 <span style=''>  protected def validateRules(ruleSuite: RuleSuite, lambdaLookups: Map[String, Map[Id, Set[String]]], names: Set[String])= {
</span>246 <span style=''>    val doRule = </span><span style='background: #AEF1AE'>validateRule(lambdaLookups, names)</span><span style=''> _
</span>247 <span style=''>
</span>248 <span style=''>    var rules = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[Rule]]</span><span style=''>
</span>249 <span style=''>    var outputExpressions = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[RunOnPassProcessor]]</span><span style=''>
</span>250 <span style=''>    var exprLookups = </span><span style='background: #AEF1AE'>Map.empty[IdTrEither, ExpressionLookup]</span><span style=''>
</span>251 <span style=''>
</span>252 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>253 <span style=''>
</span>254 <span style=''>    def addDocs[T](id: Id, rule: T, expressionRule: HasRuleText): (Id, WithDocs[T]) =
</span>255 <span style=''>      </span><span style='background: #AEF1AE'>DocsParser.parse(expressionRule.rule).map { parseddocs =&gt;
</span>256 <span style=''></span><span style='background: #AEF1AE'>        val res = id -&gt; WithDocs(rule, parseddocs)
</span>257 <span style=''></span><span style='background: #AEF1AE'>        if (parseddocs.params.nonEmpty) {
</span>258 <span style=''></span><span style='background: #AEF1AE'>          docsWarnings += NonLambdaDocParameters(id)
</span>259 <span style=''></span><span style='background: #AEF1AE'>        }
</span>260 <span style=''></span><span style='background: #AEF1AE'>        res
</span>261 <span style=''></span><span style='background: #AEF1AE'>      }.getOrElse(id -&gt; WithDocs(rule, emptyDocs))</span><span style=''>
</span>262 <span style=''>
</span>263 <span style=''>    // do the rules
</span>264 <span style=''>    val ruleErrors =
</span>265 <span style=''>      </span><span style='background: #AEF1AE'>ruleSuite.ruleSets.flatMap { rs =&gt;
</span>266 <span style=''></span><span style='background: #AEF1AE'>        rs.rules.flatMap { r =&gt;
</span>267 <span style=''></span><span style='background: #AEF1AE'>          rules += addDocs(r.id, r, r.expression.asInstanceOf[HasRuleText])
</span>268 <span style=''></span><span style='background: #AEF1AE'>
</span>269 <span style=''></span><span style='background: #AEF1AE'>          val (ruleErrors, exprLookup) = doRule(r.id, r.expression.asInstanceOf[HasExpr].expr, false)
</span>270 <span style=''></span><span style='background: #AEF1AE'>          exprLookups += RuleId(r.id) -&gt; exprLookup
</span>271 <span style=''></span><span style='background: #AEF1AE'>
</span>272 <span style=''></span><span style='background: #AEF1AE'>          val outputErrors =
</span>273 <span style=''></span><span style='background: #AEF1AE'>            if (r.runOnPassProcessor != NoOpRunOnPassProcessor.noOp) {
</span>274 <span style=''></span><span style='background: #AEF1AE'>              outputExpressions += addDocs(r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[OutputExpression])
</span>275 <span style=''></span><span style='background: #AEF1AE'>
</span>276 <span style=''></span><span style='background: #AEF1AE'>              val (oErrors, oExprLookup) = doRule(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true)
</span>277 <span style=''></span><span style='background: #AEF1AE'>              exprLookups += OutputExpressionId(r.runOnPassProcessor.id) -&gt; oExprLookup
</span>278 <span style=''></span><span style='background: #AEF1AE'>              oErrors
</span>279 <span style=''></span><span style='background: #AEF1AE'>            } else
</span>280 <span style=''></span><span style='background: #AEF1AE'>              Set.empty
</span>281 <span style=''></span><span style='background: #AEF1AE'>
</span>282 <span style=''></span><span style='background: #AEF1AE'>          ruleErrors ++ outputErrors
</span>283 <span style=''></span><span style='background: #AEF1AE'>        }
</span>284 <span style=''></span><span style='background: #AEF1AE'>      }.toSet</span><span style=''>
</span>285 <span style=''>
</span>286 <span style=''>    </span><span style='background: #AEF1AE'>(ruleErrors, Set() ++ docsWarnings, Map() ++ rules, outputExpressions, Map() ++ exprLookups)</span><span style=''>
</span>287 <span style=''>  }
</span>288 <span style=''>
</span>289 <span style=''>  protected def validateLambdas(ruleSuite: RuleSuite, recursiveLambdasSOEIsOk: Boolean, names: Set[String]): Either[(Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]),
</span>290 <span style=''>    (Seq[(String, Either[(Id, Expression), LambdaSyntaxError])], Map[String, Map[Id, Set[String]]],
</span>291 <span style=''>      Set[Id], Set[LambdaSparkFunctionNameError], Set[LambdaMultipleImplementationWithSameArityError], Set[LambdaNameError], Map[Id, WithDocs[quality.LambdaFunction]], Set[RuleWarning], Map[IdTrEither, ExpressionLookup])] = {
</span>292 <span style=''>
</span>293 <span style=''>    var lambdas = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[quality.LambdaFunction]]</span><span style=''>
</span>294 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>295 <span style=''>
</span>296 <span style=''>    val (lambdaLeftExpressions, lambdaSyntaxErrors) = ruleSuite.lambdaFunctions.map { f =&gt;
</span>297 <span style=''>      (f.name,
</span>298 <span style=''>        try {
</span>299 <span style=''>          val expr = f.expr
</span>300 <span style=''>          val ret = Left((f.id, expr))
</span>301 <span style=''>
</span>302 <span style=''>          val args =
</span>303 <span style=''>            expr match {
</span>304 <span style=''>              case lambda: LambdaFunction =&gt; lambda.arguments.map(VariablesLookup.toName).toSet
</span>305 <span style=''>              case _ =&gt; Set.empty[String]
</span>306 <span style=''>            }
</span>307 <span style=''>
</span>308 <span style=''>          DocsParser.parse(f.rule).map { parseddocs =&gt;
</span>309 <span style=''>            lambdas += f.id -&gt; WithDocs(f, parseddocs)
</span>310 <span style=''>
</span>311 <span style=''>            parseddocs.params.keySet.foreach { name =&gt;
</span>312 <span style=''>              if (!args.contains(name)) {
</span>313 <span style=''>                docsWarnings += ExtraDocParameter(f.id, name)
</span>314 <span style=''>              }
</span>315 <span style=''>            }
</span>316 <span style=''>          }.getOrElse {
</span>317 <span style=''>            lambdas += f.id -&gt; WithDocs(f, emptyDocs)
</span>318 <span style=''>          }
</span>319 <span style=''>
</span>320 <span style=''>          ret
</span>321 <span style=''>        } catch {
</span>322 <span style=''>          case e: Throwable =&gt; Right(LambdaSyntaxError(f.id, e.getMessage))
</span>323 <span style=''>        })
</span>324 <span style=''>    }.partition {
</span>325 <span style=''>      _._2.isLeft
</span>326 <span style=''>    }
</span>327 <span style=''>
</span>328 <span style=''>    val lambdaNameToExpressions = </span><span style='background: #AEF1AE'>lambdaLeftExpressions.groupBy(p =&gt; p._1).mapValues(e =&gt; e.map(_._2.left.get).toMap)</span><span style=''>
</span>329 <span style=''>
</span>330 <span style=''>    val (lambdaLookups, potentialOverflows, unknownLambdaSparkFunctions) = try {
</span>331 <span style=''>      VariablesLookup.processLambdas(lambdaNameToExpressions)
</span>332 <span style=''>    } catch {
</span>333 <span style=''>      // SOE is possible with lambdas calling lambdas, capture that as a distinct issue
</span>334 <span style=''>      case soe: StackOverflowError =&gt;
</span>335 <span style=''>        if (recursiveLambdasSOEIsOk)
</span>336 <span style=''>        // type needed otherwise it gets stuck with the first param type derivation _1 &lt;: String instead of String
</span>337 <span style=''>          (Map.empty[String, Map[Id, Identifiers]], Set.empty[Id], Map.empty[Id, Set[String]])
</span>338 <span style=''>        else
</span>339 <span style=''>          return Left((Set(LambdaStackOverflowError(Validation.unknownSOEId)), Set.empty[RuleWarning], &quot;&quot;, RuleSuiteDocs(), Map.empty[IdTrEither, ExpressionLookup]))
</span>340 <span style=''>    }
</span>341 <span style=''>
</span>342 <span style=''>    // now that they are looked up, a bit duplicative but...
</span>343 <span style=''>    val exprLookups = </span><span style='background: #AEF1AE'>lambdaNameToExpressions.values.flatMap( m =&gt; m.map(pair =&gt; LambdaId(pair._1) -&gt; VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))).toMap</span><span style=''>
</span>344 <span style=''>
</span>345 <span style=''>    val unknownLambdaSparkFunctionErrors = </span><span style='background: #AEF1AE'>unknownLambdaSparkFunctions.flatMap(p =&gt; p._2.map(name =&gt;
</span>346 <span style=''></span><span style='background: #AEF1AE'>      LambdaSparkFunctionNameError(name, p._1))).toSet</span><span style=''>
</span>347 <span style=''>
</span>348 <span style=''>    val lambdaArityErrors = </span><span style='background: #AEF1AE'>lambdaNameToExpressions.filter(p =&gt; p._2.size &gt; 1).flatMap {
</span>349 <span style=''></span><span style='background: #AEF1AE'>      pairs =&gt;
</span>350 <span style=''></span><span style='background: #AEF1AE'>        val map = pairs._2
</span>351 <span style=''></span><span style='background: #AEF1AE'>
</span>352 <span style=''></span><span style='background: #AEF1AE'>        val counts = map.groupBy(_._2.children.size - 1) // one child is the return
</span>353 <span style=''></span><span style='background: #AEF1AE'>        val moreThan1 = counts.collectFirst { case f if f._2.size &gt; 1 =&gt; f }
</span>354 <span style=''></span><span style='background: #AEF1AE'>        moreThan1.map { f =&gt;
</span>355 <span style=''></span><span style='background: #AEF1AE'>          LambdaMultipleImplementationWithSameArityError(pairs._1, f._2.size, f._1, f._2.keySet)
</span>356 <span style=''></span><span style='background: #AEF1AE'>        }
</span>357 <span style=''></span><span style='background: #AEF1AE'>    }.toSet</span><span style=''>
</span>358 <span style=''>
</span>359 <span style=''>    // do we have variables used in the lambdas which are not in the schema?
</span>360 <span style=''>    val lambdaNameErrors: Set[LambdaNameError] =
</span>361 <span style=''>      </span><span style='background: #AEF1AE'>lambdaLookups.flatMap { p =&gt;
</span>362 <span style=''></span><span style='background: #AEF1AE'>        p._2.flatMap { pair =&gt;
</span>363 <span style=''></span><span style='background: #AEF1AE'>          val (id, identifiers) = pair
</span>364 <span style=''></span><span style='background: #AEF1AE'>          if (identifiers.diff(names).isEmpty)
</span>365 <span style=''></span><span style='background: #AEF1AE'>            None
</span>366 <span style=''></span><span style='background: #AEF1AE'>          else
</span>367 <span style=''></span><span style='background: #AEF1AE'>            Some(identifiers.diff(names).map(LambdaNameError(_, id)))
</span>368 <span style=''></span><span style='background: #AEF1AE'>        }
</span>369 <span style=''></span><span style='background: #AEF1AE'>      }.flatten.toSet</span><span style=''>
</span>370 <span style=''>    </span><span style='background: #AEF1AE'>Right((lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, Map() ++ lambdas, Set() ++ docsWarnings, exprLookups))</span><span style=''>
</span>371 <span style=''>  }
</span>372 <span style=''>
</span>373 <span style=''>  protected def validateRule(lambdaLookups: Map[String, Map[Id, Set[String]]], names: Set[String])(id: Id, exprThunk: =&gt; Expression, outputRule: Boolean): (Set[RuleError], ExpressionLookup) =
</span>374 <span style=''>    try {
</span>375 <span style=''>      </span><span style='background: #AEF1AE'>val expr = exprThunk
</span>376 <span style=''></span><span style='background: #AEF1AE'>      val exl @ ExpressionLookup(exprFields, unknownSparkFunctions, _, _) = VariablesLookup.fieldsFromExpression(expr, lambdaLookups)
</span>377 <span style=''></span><span style='background: #AEF1AE'>      val rules = exprFields.flatMap{
</span>378 <span style=''></span><span style='background: #AEF1AE'>        field =&gt;
</span>379 <span style=''></span><span style='background: #AEF1AE'>          if (names.contains(field))
</span>380 <span style=''></span><span style='background: #AEF1AE'>            None
</span>381 <span style=''></span><span style='background: #AEF1AE'>          else
</span>382 <span style=''></span><span style='background: #AEF1AE'>            Some(
</span>383 <span style=''></span><span style='background: #AEF1AE'>              if (!outputRule)
</span>384 <span style=''></span><span style='background: #AEF1AE'>                RuleNameError(field, id)
</span>385 <span style=''></span><span style='background: #AEF1AE'>              else
</span>386 <span style=''></span><span style='background: #AEF1AE'>                OutputRuleNameError(field, id)
</span>387 <span style=''></span><span style='background: #AEF1AE'>            )
</span>388 <span style=''></span><span style='background: #AEF1AE'>      }.toSet[RuleError]
</span>389 <span style=''></span><span style='background: #AEF1AE'>
</span>390 <span style=''></span><span style='background: #AEF1AE'>      val unknown = unknownSparkFunctions.map{ name =&gt;
</span>391 <span style=''></span><span style='background: #AEF1AE'>        if (!outputRule)
</span>392 <span style=''></span><span style='background: #AEF1AE'>          SparkFunctionNameError(name, id)
</span>393 <span style=''></span><span style='background: #AEF1AE'>        else
</span>394 <span style=''></span><span style='background: #AEF1AE'>          OuputSparkFunctionNameError(name, id)
</span>395 <span style=''></span><span style='background: #AEF1AE'>      }
</span>396 <span style=''></span><span style='background: #AEF1AE'>
</span>397 <span style=''></span><span style='background: #AEF1AE'>      (rules ++ unknown, exl)</span><span style=''>
</span>398 <span style=''>    } catch {
</span>399 <span style=''>      case e: Throwable =&gt; </span><span style='background: #AEF1AE'>(Set(
</span>400 <span style=''></span><span style='background: #AEF1AE'>        if (!outputRule)
</span>401 <span style=''></span><span style='background: #AEF1AE'>          RuleSyntaxError(id, e.getMessage)
</span>402 <span style=''></span><span style='background: #AEF1AE'>        else
</span>403 <span style=''></span><span style='background: #AEF1AE'>          OutputRuleSyntaxError(id, e.getMessage)
</span>404 <span style=''></span><span style='background: #AEF1AE'>      ), ExpressionLookup())</span><span style=''>
</span>405 <span style=''>    }
</span>406 <span style=''>
</span>407 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          2715
        </td>
        <td>
          1180
          -
          1187
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warning
        </td>
      </tr><tr>
        <td>
          42
        </td>
        <td>
          2716
        </td>
        <td>
          1322
          -
          1327
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          false
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          2721
        </td>
        <td>
          1390
          -
          1392
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasId.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.id
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          2717
        </td>
        <td>
          1351
          -
          1352
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          2720
        </td>
        <td>
          1352
          -
          1359
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warning
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          2722
        </td>
        <td>
          1349
          -
          1393
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;, occurred when processing id &quot;, &quot;&quot;).s(RuleWarning.this.warning, RuleWarning.this.id)
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          2719
        </td>
        <td>
          1392
          -
          1393
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          2718
        </td>
        <td>
          1359
          -
          1390
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;, occurred when processing id &quot;
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          2723
        </td>
        <td>
          1431
          -
          1442
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warningText
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warningText
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          2724
        </td>
        <td>
          1534
          -
          1538
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          true
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          2725
        </td>
        <td>
          1714
          -
          1737
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Possible SOE detected&quot;
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          2726
        </td>
        <td>
          1823
          -
          1886
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter documentation is present on a non lambda expression&quot;
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          2730
        </td>
        <td>
          2005
          -
          2061
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Parameter &quot;, &quot; is not found in the lambda expression&quot;).s(ExtraDocParameter.this.name)
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          2729
        </td>
        <td>
          2018
          -
          2022
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ExtraDocParameter.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExtraDocParameter.this.name
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          2728
        </td>
        <td>
          2022
          -
          2061
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is not found in the lambda expression&quot;
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          2727
        </td>
        <td>
          2007
          -
          2018
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter &quot;
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          2731
        </td>
        <td>
          2228
          -
          2233
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.error
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.error
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          2732
        </td>
        <td>
          2367
          -
          2372
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          false
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          2733
        </td>
        <td>
          2394
          -
          2395
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          2735
        </td>
        <td>
          2432
          -
          2433
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          2738
        </td>
        <td>
          2392
          -
          2433
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot; occurred when processing id &quot;, &quot;&quot;).s(RuleError.this.error, RuleError.this.id)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          2737
        </td>
        <td>
          2430
          -
          2432
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasId.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.id
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          2734
        </td>
        <td>
          2400
          -
          2430
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; occurred when processing id &quot;
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          2736
        </td>
        <td>
          2395
          -
          2400
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.error
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.error
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          2739
        </td>
        <td>
          2471
          -
          2480
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.errorText
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.errorText
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          2740
        </td>
        <td>
          2568
          -
          2572
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          true
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          2742
        </td>
        <td>
          2686
          -
          2698
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is missing&quot;
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          2741
        </td>
        <td>
          2676
          -
          2682
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Name &quot;
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          2744
        </td>
        <td>
          2674
          -
          2698
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Name &quot;, &quot; is missing&quot;).s(NameMissingError.this.name)
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          2743
        </td>
        <td>
          2682
          -
          2686
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.NameMissingError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NameMissingError.this.name
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          2745
        </td>
        <td>
          2894
          -
          2941
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;A lambda function seems to infinitely recurse&quot;
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          2748
        </td>
        <td>
          3242
          -
          3265
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; implementations with &quot;
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          2750
        </td>
        <td>
          3227
          -
          3231
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.name
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          2753
        </td>
        <td>
          3208
          -
          3285
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Lambda function &quot;, &quot; has &quot;, &quot; implementations with &quot;, &quot; arguments&quot;).s(LambdaMultipleImplementationWithSameArityError.this.name, LambdaMultipleImplementationWithSameArityError.this.count, LambdaMultipleImplementationWithSameArityError.this.argLength)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          2747
        </td>
        <td>
          3231
          -
          3237
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; has &quot;
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          2746
        </td>
        <td>
          3210
          -
          3227
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Lambda function &quot;
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          2749
        </td>
        <td>
          3274
          -
          3285
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; arguments&quot;
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          2752
        </td>
        <td>
          3265
          -
          3274
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.argLength
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.argLength
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          2751
        </td>
        <td>
          3237
          -
          3242
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.count
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.count
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          2754
        </td>
        <td>
          3297
          -
          3305
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.IterableLike.head
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.ids.head
        </td>
      </tr><tr>
        <td>
          115
        </td>
        <td>
          2755
        </td>
        <td>
          4104
          -
          4137
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.dataFrameSyntaxErrorId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.dataFrameSyntaxErrorId
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          2756
        </td>
        <td>
          4182
          -
          4211
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.Id.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.Id.apply(-2147483648, -2147483648)
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          2757
        </td>
        <td>
          4243
          -
          4276
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.Id.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.Id.apply(-2147483647, -2147483647)
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          2759
        </td>
        <td>
          4935
          -
          4935
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$1._2
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          2762
        </td>
        <td>
          4953
          -
          4953
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$1._5
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          2758
        </td>
        <td>
          4930
          -
          4930
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$1._1
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          2761
        </td>
        <td>
          4947
          -
          4947
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$1._4
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          2760
        </td>
        <td>
          4942
          -
          4942
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$1._3
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          2763
        </td>
        <td>
          4998
          -
          5010
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning]](err, warns)
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          2766
        </td>
        <td>
          5639
          -
          5639
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._3
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          2768
        </td>
        <td>
          5650
          -
          5650
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._5
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          2765
        </td>
        <td>
          5632
          -
          5632
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._2
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          2764
        </td>
        <td>
          5627
          -
          5627
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._1
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          2767
        </td>
        <td>
          5644
          -
          5644
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._4
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          2769
        </td>
        <td>
          5695
          -
          5707
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning]](err, warns)
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          2775
        </td>
        <td>
          6525
          -
          6525
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$7
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$7
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          2774
        </td>
        <td>
          6525
          -
          6525
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$6
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          2771
        </td>
        <td>
          6576
          -
          6596
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[org.apache.spark.sql.DataFrame =&gt; org.apache.spark.sql.Column](runnerFunction)
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          2773
        </td>
        <td>
          6525
          -
          6525
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$5
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          2776
        </td>
        <td>
          6525
          -
          6597
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate(x$1, x$2, x$4, x$3, x$5, x$6, x$7)
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          2770
        </td>
        <td>
          6534
          -
          6546
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, org.apache.spark.sql.DataFrame](frame)
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          2772
        </td>
        <td>
          6525
          -
          6525
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$3
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          2777
        </td>
        <td>
          7581
          -
          7593
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, org.apache.spark.sql.DataFrame](frame)
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          2780
        </td>
        <td>
          7572
          -
          7572
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$5
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          2782
        </td>
        <td>
          7572
          -
          7687
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate(x$1, x$2, x$5, x$3, x$6, x$7, x$4)
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          2779
        </td>
        <td>
          7572
          -
          7572
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$3
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          2778
        </td>
        <td>
          7623
          -
          7643
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[org.apache.spark.sql.DataFrame =&gt; org.apache.spark.sql.Column](runnerFunction)
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          2781
        </td>
        <td>
          7572
          -
          7572
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$6
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          2784
        </td>
        <td>
          7707
          -
          7707
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply$default$2
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          2783
        </td>
        <td>
          7707
          -
          7707
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply$default$1
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          2786
        </td>
        <td>
          7707
          -
          7713
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply(com.sparkutils.quality.utils.Docs.apply$default$1, com.sparkutils.quality.utils.Docs.apply$default$2, com.sparkutils.quality.utils.Docs.apply$default$3)
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          2785
        </td>
        <td>
          7707
          -
          7707
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply$default$3
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          2789
        </td>
        <td>
          9340
          -
          9378
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.fold
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          schemaOrFrame.fold[org.apache.spark.sql.types.StructType]({
  ((x: org.apache.spark.sql.types.StructType) =&gt; scala.Predef.identity[org.apache.spark.sql.types.StructType](x))
}, ((x$3: org.apache.spark.sql.DataFrame) =&gt; x$3.schema))
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          2788
        </td>
        <td>
          9369
          -
          9377
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.Dataset.schema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3.schema
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          2787
        </td>
        <td>
          9359
          -
          9367
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.identity
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.identity[org.apache.spark.sql.types.StructType](x)
        </td>
      </tr><tr>
        <td>
          200
        </td>
        <td>
          2790
        </td>
        <td>
          9396
          -
          9419
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.LookupIdFunctions.namesFromSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.namesFromSchema(schema)
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          2791
        </td>
        <td>
          9444
          -
          9470
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          2793
        </td>
        <td>
          9502
          -
          9502
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple9._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._2
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          2792
        </td>
        <td>
          9482
          -
          9482
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple9._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._1
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          2795
        </td>
        <td>
          9537
          -
          9537
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple9._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._4
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          2798
        </td>
        <td>
          9608
          -
          9608
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple9._7
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._7
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          2797
        </td>
        <td>
          9590
          -
          9590
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple9._6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._6
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          2800
        </td>
        <td>
          9636
          -
          9636
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple9._9
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._9
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          2794
        </td>
        <td>
          9517
          -
          9517
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple9._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._3
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          2796
        </td>
        <td>
          9571
          -
          9571
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple9._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._5
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          2799
        </td>
        <td>
          9617
          -
          9617
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple9._8
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._8
        </td>
      </tr><tr>
        <td>
          210
        </td>
        <td>
          2801
        </td>
        <td>
          9835
          -
          9869
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.Growable.++=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.++=(lambdaDocWarnings)
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          2802
        </td>
        <td>
          9880
          -
          9880
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._1
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          2804
        </td>
        <td>
          9909
          -
          9909
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._3
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          2806
        </td>
        <td>
          9935
          -
          9935
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._5
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          2803
        </td>
        <td>
          9892
          -
          9892
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._2
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          2805
        </td>
        <td>
          9916
          -
          9916
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._4
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          2807
        </td>
        <td>
          10012
          -
          10044
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.Growable.++=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.++=(ruleDocWarnings)
        </td>
      </tr><tr>
        <td>
          216
        </td>
        <td>
          2809
        </td>
        <td>
          10064
          -
          10064
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$6._2
        </td>
      </tr><tr>
        <td>
          216
        </td>
        <td>
          2808
        </td>
        <td>
          10055
          -
          10055
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$6._1
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          2810
        </td>
        <td>
          10231
          -
          10231
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          2813
        </td>
        <td>
          10323
          -
          10323
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          2822
        </td>
        <td>
          10197
          -
          10541
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple5.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple5.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning], String, com.sparkutils.quality.utils.RuleSuiteDocs, scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](unknownLambdaSparkFunctionErrors.++[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]](lambdaArityErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]).++[com.sparkutils.quality.impl.RuleError, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](dfErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]).++(ruleErrors).++(lambdaNameErrors).++(lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$7: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$7._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError]), potentialOverflows.map[com.sparkutils.quality.impl.LambdaPossibleSOE, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaPossibleSOE]](LambdaPossibleSOE)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]).++[com.sparkutils.quality.impl.RuleWarning, Set[com.sparkutils.quality.impl.RuleWarning]](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning]), showOut, com.sparkutils.quality.utils.RuleSuiteDocs.apply(rules, outputExpressions, lambdas), lambadaExpressionLookups.++[com.sparkutils.quality.ExpressionLookup](ruleExpressionLookups))
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          2815
        </td>
        <td>
          10198
          -
          10345
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownLambdaSparkFunctionErrors.++[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]](lambdaArityErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]).++[com.sparkutils.quality.impl.RuleError, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](dfErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]).++(ruleErrors).++(lambdaNameErrors).++(lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$7: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$7._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError])
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          2812
        </td>
        <td>
          10324
          -
          10338
        </td>
        <td>
          Select
        </td>
        <td>
          scala.util.Either.RightProjection.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._2.right.get
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          2811
        </td>
        <td>
          10252
          -
          10252
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          2814
        </td>
        <td>
          10301
          -
          10345
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$7: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$7._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError]
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          2819
        </td>
        <td>
          10353
          -
          10423
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          potentialOverflows.map[com.sparkutils.quality.impl.LambdaPossibleSOE, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaPossibleSOE]](LambdaPossibleSOE)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]).++[com.sparkutils.quality.impl.RuleWarning, Set[com.sparkutils.quality.impl.RuleWarning]](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning])
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          2816
        </td>
        <td>
          10375
          -
          10375
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          2818
        </td>
        <td>
          10397
          -
          10397
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning]
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          2817
        </td>
        <td>
          10401
          -
          10422
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          221
        </td>
        <td>
          2821
        </td>
        <td>
          10491
          -
          10540
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambadaExpressionLookups.++[com.sparkutils.quality.ExpressionLookup](ruleExpressionLookups)
        </td>
      </tr><tr>
        <td>
          221
        </td>
        <td>
          2820
        </td>
        <td>
          10441
          -
          10489
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.RuleSuiteDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.RuleSuiteDocs.apply(rules, outputExpressions, lambdas)
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          2826
        </td>
        <td>
          10810
          -
          10985
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.RightProjection.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          schemaOrFrame.right.getOrElse[org.apache.spark.sql.DataFrame]({
  val session: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession.active;
  val empty: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = session.sparkContext.emptyRDD[org.apache.spark.sql.Row]((ClassTag.apply[org.apache.spark.sql.Row](classOf[org.apache.spark.sql.Row]): scala.reflect.ClassTag[org.apache.spark.sql.Row]));
  session.createDataFrame(empty, schema)
})
        </td>
      </tr><tr>
        <td>
          226
        </td>
        <td>
          2823
        </td>
        <td>
          10862
          -
          10881
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.SparkSession.active
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active
        </td>
      </tr><tr>
        <td>
          227
        </td>
        <td>
          2824
        </td>
        <td>
          10900
          -
          10934
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.SparkContext.emptyRDD
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          session.sparkContext.emptyRDD[org.apache.spark.sql.Row]((ClassTag.apply[org.apache.spark.sql.Row](classOf[org.apache.spark.sql.Row]): scala.reflect.ClassTag[org.apache.spark.sql.Row]))
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          2825
        </td>
        <td>
          10941
          -
          10979
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.SparkSession.createDataFrame
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          session.createDataFrame(empty, schema)
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          2828
        </td>
        <td>
          11005
          -
          11005
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._2
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          2827
        </td>
        <td>
          10996
          -
          10996
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._1
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          2829
        </td>
        <td>
          11442
          -
          11461
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[String, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](showOut, dfErrors)
        </td>
      </tr><tr>
        <td>
          246
        </td>
        <td>
          2830
        </td>
        <td>
          11609
          -
          11643
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validateRule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validateRule(lambdaLookups, names)(id, exprThunk, outputRule)
        </td>
      </tr><tr>
        <td>
          248
        </td>
        <td>
          2831
        </td>
        <td>
          11663
          -
          11692
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]]
        </td>
      </tr><tr>
        <td>
          249
        </td>
        <td>
          2832
        </td>
        <td>
          11721
          -
          11764
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]]
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          2833
        </td>
        <td>
          11787
          -
          11826
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup]
        </td>
      </tr><tr>
        <td>
          252
        </td>
        <td>
          2834
        </td>
        <td>
          11851
          -
          11877
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          255
        </td>
        <td>
          2835
        </td>
        <td>
          11988
          -
          12007
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.HasRuleText.rule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expressionRule.rule
        </td>
      </tr><tr>
        <td>
          256
        </td>
        <td>
          2837
        </td>
        <td>
          12047
          -
          12079
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, parseddocs))
        </td>
      </tr><tr>
        <td>
          256
        </td>
        <td>
          2836
        </td>
        <td>
          12053
          -
          12079
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.WithDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.WithDocs.apply[T](rule, parseddocs)
        </td>
      </tr><tr>
        <td>
          257
        </td>
        <td>
          2843
        </td>
        <td>
          12088
          -
          12088
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          257
        </td>
        <td>
          2842
        </td>
        <td>
          12088
          -
          12088
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          257
        </td>
        <td>
          2838
        </td>
        <td>
          12092
          -
          12118
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.nonEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parseddocs.params.nonEmpty
        </td>
      </tr><tr>
        <td>
          258
        </td>
        <td>
          2840
        </td>
        <td>
          12132
          -
          12174
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.+=(NonLambdaDocParameters.apply(id))
        </td>
      </tr><tr>
        <td>
          258
        </td>
        <td>
          2839
        </td>
        <td>
          12148
          -
          12174
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.NonLambdaDocParameters.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NonLambdaDocParameters.apply(id)
        </td>
      </tr><tr>
        <td>
          258
        </td>
        <td>
          2841
        </td>
        <td>
          12132
          -
          12174
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.+=(NonLambdaDocParameters.apply(id))
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          2846
        </td>
        <td>
          12215
          -
          12246
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, Validation.this.emptyDocs))
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          2845
        </td>
        <td>
          12221
          -
          12246
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.WithDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.WithDocs.apply[T](rule, Validation.this.emptyDocs)
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          2847
        </td>
        <td>
          11971
          -
          12247
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.DocsParser.parse(expressionRule.rule).map[(com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[T])](((parseddocs: com.sparkutils.quality.utils.Docs) =&gt; {
  val res: (com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[T]) = scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, parseddocs));
  if (parseddocs.params.nonEmpty)
    docsWarnings.+=(NonLambdaDocParameters.apply(id))
  else
    ();
  res
})).getOrElse[(com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[T])](scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, Validation.this.emptyDocs)))
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          2844
        </td>
        <td>
          12236
          -
          12245
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.emptyDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.emptyDocs
        </td>
      </tr><tr>
        <td>
          265
        </td>
        <td>
          2873
        </td>
        <td>
          12323
          -
          12323
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          266
        </td>
        <td>
          2872
        </td>
        <td>
          12339
          -
          13177
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rs.rules.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((r: com.sparkutils.quality.Rule) =&gt; {
  rules = rules.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.id, r.expression.asInstanceOf[com.sparkutils.quality.HasExpr].expr, false): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((ruleErrors @ _), (exprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](ruleErrors, exprLookup)
  };
  val ruleErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
  val exprLookup: com.sparkutils.quality.ExpressionLookup = x$9._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup));
  val outputErrors: scala.collection.immutable.Set[_ &lt;: com.sparkutils.quality.impl.RuleError] = if (r.runOnPassProcessor.!=(com.sparkutils.quality.NoOpRunOnPassProcessor.noOp))
    {
      outputExpressions = outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$10: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
        case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](oErrors, oExprLookup)
      };
      val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$10._1;
      val oExprLookup: com.sparkutils.quality.ExpressionLookup = x$10._2;
      exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup));
      oErrors
    }
  else
    scala.Predef.Set.empty[Nothing];
  ruleErrors.++(outputErrors)
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError])
        </td>
      </tr><tr>
        <td>
          266
        </td>
        <td>
          2871
        </td>
        <td>
          12356
          -
          12356
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          2849
        </td>
        <td>
          12399
          -
          12437
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          2848
        </td>
        <td>
          12390
          -
          12394
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.Rule.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.id
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          2851
        </td>
        <td>
          12373
          -
          12438
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rules.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]))
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          2850
        </td>
        <td>
          12382
          -
          12438
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.addDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText])
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2852
        </td>
        <td>
          12455
          -
          12455
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$9._1
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2853
        </td>
        <td>
          12467
          -
          12467
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$9._2
        </td>
      </tr><tr>
        <td>
          270
        </td>
        <td>
          2855
        </td>
        <td>
          12552
          -
          12593
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup))
        </td>
      </tr><tr>
        <td>
          270
        </td>
        <td>
          2854
        </td>
        <td>
          12567
          -
          12593
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup)
        </td>
      </tr><tr>
        <td>
          273
        </td>
        <td>
          2867
        </td>
        <td>
          12693
          -
          13100
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  outputExpressions = outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$10: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](oErrors, oExprLookup)
  };
  val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$10._1;
  val oExprLookup: com.sparkutils.quality.ExpressionLookup = x$10._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup));
  oErrors
}
        </td>
      </tr><tr>
        <td>
          273
        </td>
        <td>
          2857
        </td>
        <td>
          12640
          -
          12691
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.!=(com.sparkutils.quality.NoOpRunOnPassProcessor.noOp)
        </td>
      </tr><tr>
        <td>
          273
        </td>
        <td>
          2856
        </td>
        <td>
          12664
          -
          12691
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.NoOpRunOnPassProcessor.noOp
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.NoOpRunOnPassProcessor.noOp
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          2861
        </td>
        <td>
          12730
          -
          12852
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.addDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression])
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          2858
        </td>
        <td>
          12738
          -
          12761
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.RunOnPassProcessor.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.id
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          2860
        </td>
        <td>
          12785
          -
          12851
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          2859
        </td>
        <td>
          12763
          -
          12783
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.Rule.runOnPassProcessor
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          2862
        </td>
        <td>
          12709
          -
          12852
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]))
        </td>
      </tr><tr>
        <td>
          276
        </td>
        <td>
          2864
        </td>
        <td>
          12882
          -
          12882
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$10._2
        </td>
      </tr><tr>
        <td>
          276
        </td>
        <td>
          2863
        </td>
        <td>
          12873
          -
          12873
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$10._1
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          2866
        </td>
        <td>
          12991
          -
          13064
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup))
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          2865
        </td>
        <td>
          13006
          -
          13064
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup)
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          2869
        </td>
        <td>
          13120
          -
          13129
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          2868
        </td>
        <td>
          13120
          -
          13129
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          282
        </td>
        <td>
          2870
        </td>
        <td>
          13141
          -
          13167
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleErrors.++(outputErrors)
        </td>
      </tr><tr>
        <td>
          284
        </td>
        <td>
          2874
        </td>
        <td>
          12296
          -
          13191
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.ruleSets.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((rs: com.sparkutils.quality.RuleSet) =&gt; rs.rules.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((r: com.sparkutils.quality.Rule) =&gt; {
  rules = rules.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.id, r.expression.asInstanceOf[com.sparkutils.quality.HasExpr].expr, false): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((ruleErrors @ _), (exprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](ruleErrors, exprLookup)
  };
  val ruleErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
  val exprLookup: com.sparkutils.quality.ExpressionLookup = x$9._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup));
  val outputErrors: scala.collection.immutable.Set[_ &lt;: com.sparkutils.quality.impl.RuleError] = if (r.runOnPassProcessor.!=(com.sparkutils.quality.NoOpRunOnPassProcessor.noOp))
    {
      outputExpressions = outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$10: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
        case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](oErrors, oExprLookup)
      };
      val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$10._1;
      val oExprLookup: com.sparkutils.quality.ExpressionLookup = x$10._2;
      exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup));
      oErrors
    }
  else
    scala.Predef.Set.empty[Nothing];
  ruleErrors.++(outputErrors)
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError])))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]).toSet[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          286
        </td>
        <td>
          2876
        </td>
        <td>
          13233
          -
          13247
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](rules)
        </td>
      </tr><tr>
        <td>
          286
        </td>
        <td>
          2875
        </td>
        <td>
          13210
          -
          13231
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          286
        </td>
        <td>
          2878
        </td>
        <td>
          13197
          -
          13289
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple5.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple5.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](ruleErrors, scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](rules), outputExpressions, scala.Predef.Map.apply[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, Nothing]().++[com.sparkutils.quality.ExpressionLookup](exprLookups))
        </td>
      </tr><tr>
        <td>
          286
        </td>
        <td>
          2877
        </td>
        <td>
          13268
          -
          13288
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, Nothing]().++[com.sparkutils.quality.ExpressionLookup](exprLookups)
        </td>
      </tr><tr>
        <td>
          293
        </td>
        <td>
          2879
        </td>
        <td>
          13850
          -
          13897
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]]
        </td>
      </tr><tr>
        <td>
          294
        </td>
        <td>
          2880
        </td>
        <td>
          13921
          -
          13947
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          296
        </td>
        <td>
          2882
        </td>
        <td>
          13981
          -
          13981
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$12._2
        </td>
      </tr><tr>
        <td>
          296
        </td>
        <td>
          2881
        </td>
        <td>
          13958
          -
          13958
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$12._1
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          2888
        </td>
        <td>
          14923
          -
          15006
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.mapValues
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaLeftExpressions.groupBy[String](((p: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; p._1)).mapValues[scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]](((e: Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])]) =&gt; e.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$13: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$13._2.left.get))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]).toMap[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])))
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          2885
        </td>
        <td>
          14984
          -
          14984
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          2884
        </td>
        <td>
          14985
          -
          14998
        </td>
        <td>
          Select
        </td>
        <td>
          scala.util.Either.LeftProjection.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$13._2.left.get
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          2887
        </td>
        <td>
          14979
          -
          15005
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$13: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$13._2.left.get))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]).toMap[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          2883
        </td>
        <td>
          14958
          -
          14962
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          2886
        </td>
        <td>
          15000
          -
          15000
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          2891
        </td>
        <td>
          15052
          -
          15052
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._3
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          2890
        </td>
        <td>
          15032
          -
          15032
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._2
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          2889
        </td>
        <td>
          15017
          -
          15017
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._1
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          2894
        </td>
        <td>
          15924
          -
          15931
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pair._2
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          2897
        </td>
        <td>
          15857
          -
          15857
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Map.canBuildFrom[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup]
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          2900
        </td>
        <td>
          15950
          -
          15950
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          2893
        </td>
        <td>
          15866
          -
          15883
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          2896
        </td>
        <td>
          15866
          -
          15947
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.ExpressionLookup](com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          2899
        </td>
        <td>
          15845
          -
          15845
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Iterable.canBuildFrom[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          2898
        </td>
        <td>
          15852
          -
          15948
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          m.map[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup), scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](((pair: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.ExpressionLookup](com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))))(immutable.this.Map.canBuildFrom[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup])
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          2892
        </td>
        <td>
          15875
          -
          15882
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pair._1
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          2901
        </td>
        <td>
          15807
          -
          15955
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaNameToExpressions.values.flatMap[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup), Iterable[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]](((m: scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) =&gt; m.map[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup), scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](((pair: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.ExpressionLookup](com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))))(immutable.this.Map.canBuildFrom[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup])))(collection.this.Iterable.canBuildFrom[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]).toMap[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup](scala.Predef.$conforms[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)])
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          2895
        </td>
        <td>
          15887
          -
          15947
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.VariablesLookup.fieldsFromExpression
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups)
        </td>
      </tr><tr>
        <td>
          345
        </td>
        <td>
          2906
        </td>
        <td>
          16035
          -
          16035
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          345
        </td>
        <td>
          2905
        </td>
        <td>
          16041
          -
          16105
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.map[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((name: String) =&gt; LambdaSparkFunctionNameError.apply(name, p._1)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError])
        </td>
      </tr><tr>
        <td>
          345
        </td>
        <td>
          2904
        </td>
        <td>
          16049
          -
          16049
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          2903
        </td>
        <td>
          16064
          -
          16104
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaSparkFunctionNameError.apply(name, p._1)
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          2902
        </td>
        <td>
          16099
          -
          16103
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          2907
        </td>
        <td>
          16000
          -
          16112
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownLambdaSparkFunctions.flatMap[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((p: (com.sparkutils.quality.Id, Set[String])) =&gt; p._2.map[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((name: String) =&gt; LambdaSparkFunctionNameError.apply(name, p._1)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError])))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]).toSet[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          348
        </td>
        <td>
          2908
        </td>
        <td>
          16178
          -
          16191
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.size.&gt;(1)
        </td>
      </tr><tr>
        <td>
          348
        </td>
        <td>
          2922
        </td>
        <td>
          16201
          -
          16201
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]
        </td>
      </tr><tr>
        <td>
          350
        </td>
        <td>
          2909
        </td>
        <td>
          16236
          -
          16244
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pairs._2
        </td>
      </tr><tr>
        <td>
          352
        </td>
        <td>
          2911
        </td>
        <td>
          16267
          -
          16302
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableLike.groupBy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          map.groupBy[Int](((x$15: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$15._2.children.size.-(1)))
        </td>
      </tr><tr>
        <td>
          352
        </td>
        <td>
          2910
        </td>
        <td>
          16279
          -
          16301
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.-
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$15._2.children.size.-(1)
        </td>
      </tr><tr>
        <td>
          353
        </td>
        <td>
          2912
        </td>
        <td>
          16386
          -
          16399
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.size.&gt;(1)
        </td>
      </tr><tr>
        <td>
          353
        </td>
        <td>
          2914
        </td>
        <td>
          16354
          -
          16406
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.collectFirst
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          counts.collectFirst[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] with Serializable {
    def &lt;init&gt;(): &lt;$anon: ((Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]), B1 &gt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
      case (f @ _) if f._2.size.&gt;(1) =&gt; f
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): Boolean = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
      case (f @ _) if f._2.size.&gt;(1) =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]))
        </td>
      </tr><tr>
        <td>
          353
        </td>
        <td>
          2913
        </td>
        <td>
          16374
          -
          16374
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          2921
        </td>
        <td>
          16415
          -
          16542
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet))))
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          2920
        </td>
        <td>
          16415
          -
          16542
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet)))
        </td>
      </tr><tr>
        <td>
          355
        </td>
        <td>
          2915
        </td>
        <td>
          16493
          -
          16501
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pairs._1
        </td>
      </tr><tr>
        <td>
          355
        </td>
        <td>
          2918
        </td>
        <td>
          16520
          -
          16531
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.immutable.MapLike.keySet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.keySet
        </td>
      </tr><tr>
        <td>
          355
        </td>
        <td>
          2917
        </td>
        <td>
          16514
          -
          16518
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._1
        </td>
      </tr><tr>
        <td>
          355
        </td>
        <td>
          2916
        </td>
        <td>
          16503
          -
          16512
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.size
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.size
        </td>
      </tr><tr>
        <td>
          355
        </td>
        <td>
          2919
        </td>
        <td>
          16446
          -
          16532
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet)
        </td>
      </tr><tr>
        <td>
          357
        </td>
        <td>
          2923
        </td>
        <td>
          16142
          -
          16554
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaNameToExpressions.filter(((p: (String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; p._2.size.&gt;(1))).flatMap[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]](((pairs: (String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; {
  val map: scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression] = pairs._2;
  val counts: scala.collection.immutable.Map[Int,scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]] = map.groupBy[Int](((x$15: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$15._2.children.size.-(1)));
  val moreThan1: Option[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] = counts.collectFirst[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](({
    @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] with Serializable {
      def &lt;init&gt;(): &lt;$anon: ((Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])&gt; = {
        $anonfun.super.&lt;init&gt;();
        ()
      };
      final override def applyOrElse[A1 &lt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]), B1 &gt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
        case (f @ _) if f._2.size.&gt;(1) =&gt; f
        case (defaultCase$ @ _) =&gt; default.apply(x1)
      };
      final def isDefinedAt(x1: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): Boolean = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
        case (f @ _) if f._2.size.&gt;(1) =&gt; true
        case (defaultCase$ @ _) =&gt; false
      }
    };
    new $anonfun()
  }: PartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]));
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet))))
}))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]).toSet[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]
        </td>
      </tr><tr>
        <td>
          361
        </td>
        <td>
          2938
        </td>
        <td>
          16710
          -
          16710
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          2936
        </td>
        <td>
          16738
          -
          16738
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          2937
        </td>
        <td>
          16725
          -
          16945
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)) =&gt; {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$16: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) = (pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) @unchecked) match {
    case (_1: com.sparkutils.quality.Id, _2: com.sparkutils.quality.VariablesLookup.Identifiers)(com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)((id @ _), (identifiers @ _)) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers](id, identifiers)
  };
  val id: com.sparkutils.quality.Id = x$16._1;
  val identifiers: com.sparkutils.quality.VariablesLookup.Identifiers = x$16._2;
  if (identifiers.diff(names).isEmpty)
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
}))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]])
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          2924
        </td>
        <td>
          16763
          -
          16763
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$16._1
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          2925
        </td>
        <td>
          16767
          -
          16767
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$16._2
        </td>
      </tr><tr>
        <td>
          364
        </td>
        <td>
          2926
        </td>
        <td>
          16801
          -
          16832
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SetLike.isEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.diff(names).isEmpty
        </td>
      </tr><tr>
        <td>
          365
        </td>
        <td>
          2927
        </td>
        <td>
          16846
          -
          16850
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          365
        </td>
        <td>
          2929
        </td>
        <td>
          16846
          -
          16850
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          365
        </td>
        <td>
          2928
        </td>
        <td>
          16846
          -
          16850
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          367
        </td>
        <td>
          2930
        </td>
        <td>
          16911
          -
          16933
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaNameError.apply(x$17, id)
        </td>
      </tr><tr>
        <td>
          367
        </td>
        <td>
          2933
        </td>
        <td>
          16878
          -
          16935
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError]))
        </td>
      </tr><tr>
        <td>
          367
        </td>
        <td>
          2935
        </td>
        <td>
          16878
          -
          16935
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
        </td>
      </tr><tr>
        <td>
          367
        </td>
        <td>
          2932
        </td>
        <td>
          16883
          -
          16934
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])
        </td>
      </tr><tr>
        <td>
          367
        </td>
        <td>
          2931
        </td>
        <td>
          16910
          -
          16910
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError]
        </td>
      </tr><tr>
        <td>
          367
        </td>
        <td>
          2934
        </td>
        <td>
          16878
          -
          16935
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
        </td>
      </tr><tr>
        <td>
          369
        </td>
        <td>
          2939
        </td>
        <td>
          16954
          -
          16954
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          369
        </td>
        <td>
          2940
        </td>
        <td>
          16688
          -
          16967
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaLookups.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((p: (String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.VariablesLookup.Identifiers])) =&gt; p._2.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)) =&gt; {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$16: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) = (pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) @unchecked) match {
    case (_1: com.sparkutils.quality.Id, _2: com.sparkutils.quality.VariablesLookup.Identifiers)(com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)((id @ _), (identifiers @ _)) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers](id, identifiers)
  };
  val id: com.sparkutils.quality.Id = x$16._1;
  val identifiers: com.sparkutils.quality.VariablesLookup.Identifiers = x$16._2;
  if (identifiers.diff(names).isEmpty)
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
}))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]])))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]).flatten[com.sparkutils.quality.impl.LambdaNameError](scala.Predef.$conforms[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]).toSet[com.sparkutils.quality.impl.LambdaNameError]
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          2942
        </td>
        <td>
          17123
          -
          17144
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          2944
        </td>
        <td>
          16972
          -
          17159
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, (Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup])](scala.Tuple9.apply[Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]](lambdas), scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), exprLookups))
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          2941
        </td>
        <td>
          17105
          -
          17121
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]](lambdas)
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          2943
        </td>
        <td>
          16978
          -
          17158
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple9.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple9.apply[Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]](lambdas), scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), exprLookups)
        </td>
      </tr><tr>
        <td>
          374
        </td>
        <td>
          2971
        </td>
        <td>
          17373
          -
          18070
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val expr: org.apache.spark.sql.catalyst.expressions.Expression = exprThunk;
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$18: (com.sparkutils.quality.ExpressionLookup, com.sparkutils.quality.VariablesLookup.Identifiers, com.sparkutils.quality.VariablesLookup.Identifiers) = (com.sparkutils.quality.VariablesLookup.fieldsFromExpression(expr, lambdaLookups): com.sparkutils.quality.ExpressionLookup @unchecked) match {
    case (exl @ (attributesUsed: com.sparkutils.quality.VariablesLookup.Identifiers, unknownSparkFunctions: com.sparkutils.quality.VariablesLookup.Identifiers, lambdas: Set[com.sparkutils.quality.Id], sparkFunctions: Set[String])com.sparkutils.quality.ExpressionLookup((exprFields @ _), (unknownSparkFunctions @ _), _, _)) =&gt; scala.Tuple3.apply[com.sparkutils.quality.ExpressionLookup, com.sparkutils.quality.VariablesLookup.Identifiers, com.sparkutils.quality.VariablesLookup.Identifiers](exl, exprFields, unknownSparkFunctions)
  };
  val exl: com.sparkutils.quality.ExpressionLookup = x$18._1;
  val exprFields: com.sparkutils.quality.VariablesLookup.Identifiers = x$18._2;
  val unknownSparkFunctions: com.sparkutils.quality.VariablesLookup.Identifiers = x$18._3;
  val rules: scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError] = exprFields.flatMap[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((field: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (names.contains(field))
  scala.this.Option.option2Iterable[Nothing](scala.None)
else
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
    RuleNameError.apply(field, id)
  else
    OutputRuleNameError.apply(field, id)))))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]).toSet[com.sparkutils.quality.impl.RuleError];
  val unknown: scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable] = unknownSparkFunctions.map[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((name: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (outputRule.unary_!)
    SparkFunctionNameError.apply(name, id)
  else
    OuputSparkFunctionNameError.apply(name, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]);
  scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](rules.++(unknown), exl)
}
        </td>
      </tr><tr>
        <td>
          376
        </td>
        <td>
          2945
        </td>
        <td>
          17404
          -
          17404
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._1
        </td>
      </tr><tr>
        <td>
          376
        </td>
        <td>
          2947
        </td>
        <td>
          17439
          -
          17439
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._3
        </td>
      </tr><tr>
        <td>
          376
        </td>
        <td>
          2946
        </td>
        <td>
          17427
          -
          17427
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._2
        </td>
      </tr><tr>
        <td>
          377
        </td>
        <td>
          2960
        </td>
        <td>
          17564
          -
          17564
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]
        </td>
      </tr><tr>
        <td>
          379
        </td>
        <td>
          2948
        </td>
        <td>
          17597
          -
          17618
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          names.contains(field)
        </td>
      </tr><tr>
        <td>
          380
        </td>
        <td>
          2951
        </td>
        <td>
          17632
          -
          17636
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          380
        </td>
        <td>
          2950
        </td>
        <td>
          17632
          -
          17636
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          380
        </td>
        <td>
          2949
        </td>
        <td>
          17632
          -
          17636
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          382
        </td>
        <td>
          2957
        </td>
        <td>
          17664
          -
          17821
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id))
        </td>
      </tr><tr>
        <td>
          382
        </td>
        <td>
          2959
        </td>
        <td>
          17664
          -
          17821
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id)))
        </td>
      </tr><tr>
        <td>
          382
        </td>
        <td>
          2958
        </td>
        <td>
          17664
          -
          17821
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id)))
        </td>
      </tr><tr>
        <td>
          383
        </td>
        <td>
          2952
        </td>
        <td>
          17688
          -
          17699
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          384
        </td>
        <td>
          2954
        </td>
        <td>
          17717
          -
          17741
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          384
        </td>
        <td>
          2953
        </td>
        <td>
          17717
          -
          17741
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          386
        </td>
        <td>
          2956
        </td>
        <td>
          17777
          -
          17807
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          386
        </td>
        <td>
          2955
        </td>
        <td>
          17777
          -
          17807
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          388
        </td>
        <td>
          2961
        </td>
        <td>
          17546
          -
          17846
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprFields.flatMap[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((field: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (names.contains(field))
  scala.this.Option.option2Iterable[Nothing](scala.None)
else
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
    RuleNameError.apply(field, id)
  else
    OutputRuleNameError.apply(field, id)))))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]).toSet[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          390
        </td>
        <td>
          2968
        </td>
        <td>
          17868
          -
          18039
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownSparkFunctions.map[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((name: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (outputRule.unary_!)
  SparkFunctionNameError.apply(name, id)
else
  OuputSparkFunctionNameError.apply(name, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable])
        </td>
      </tr><tr>
        <td>
          390
        </td>
        <td>
          2967
        </td>
        <td>
          17893
          -
          17893
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]
        </td>
      </tr><tr>
        <td>
          391
        </td>
        <td>
          2962
        </td>
        <td>
          17915
          -
          17926
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          392
        </td>
        <td>
          2963
        </td>
        <td>
          17938
          -
          17970
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.SparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          SparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          392
        </td>
        <td>
          2964
        </td>
        <td>
          17938
          -
          17970
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.SparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          SparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          394
        </td>
        <td>
          2966
        </td>
        <td>
          17994
          -
          18031
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OuputSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OuputSparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          394
        </td>
        <td>
          2965
        </td>
        <td>
          17994
          -
          18031
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OuputSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OuputSparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          397
        </td>
        <td>
          2969
        </td>
        <td>
          18048
          -
          18064
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rules.++(unknown)
        </td>
      </tr><tr>
        <td>
          397
        </td>
        <td>
          2970
        </td>
        <td>
          18047
          -
          18070
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](rules.++(unknown), exl)
        </td>
      </tr><tr>
        <td>
          399
        </td>
        <td>
          2985
        </td>
        <td>
          18112
          -
          18278
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleError](if (outputRule.unary_!)
  RuleSyntaxError.apply(id, e.getMessage())
else
  OutputRuleSyntaxError.apply(id, e.getMessage())), com.sparkutils.quality.ExpressionLookup.apply(com.sparkutils.quality.ExpressionLookup.apply$default$1, com.sparkutils.quality.ExpressionLookup.apply$default$2, com.sparkutils.quality.ExpressionLookup.apply$default$3, com.sparkutils.quality.ExpressionLookup.apply$default$4))
        </td>
      </tr><tr>
        <td>
          399
        </td>
        <td>
          2979
        </td>
        <td>
          18113
          -
          18257
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleError](if (outputRule.unary_!)
  RuleSyntaxError.apply(id, e.getMessage())
else
  OutputRuleSyntaxError.apply(id, e.getMessage()))
        </td>
      </tr><tr>
        <td>
          400
        </td>
        <td>
          2972
        </td>
        <td>
          18130
          -
          18141
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          401
        </td>
        <td>
          2975
        </td>
        <td>
          18153
          -
          18186
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          401
        </td>
        <td>
          2974
        </td>
        <td>
          18153
          -
          18186
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          401
        </td>
        <td>
          2973
        </td>
        <td>
          18173
          -
          18185
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Throwable.getMessage
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.getMessage()
        </td>
      </tr><tr>
        <td>
          403
        </td>
        <td>
          2978
        </td>
        <td>
          18210
          -
          18249
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          403
        </td>
        <td>
          2977
        </td>
        <td>
          18210
          -
          18249
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          403
        </td>
        <td>
          2976
        </td>
        <td>
          18236
          -
          18248
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Throwable.getMessage
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.getMessage()
        </td>
      </tr><tr>
        <td>
          404
        </td>
        <td>
          2981
        </td>
        <td>
          18259
          -
          18259
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$2
        </td>
      </tr><tr>
        <td>
          404
        </td>
        <td>
          2984
        </td>
        <td>
          18259
          -
          18277
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply(com.sparkutils.quality.ExpressionLookup.apply$default$1, com.sparkutils.quality.ExpressionLookup.apply$default$2, com.sparkutils.quality.ExpressionLookup.apply$default$3, com.sparkutils.quality.ExpressionLookup.apply$default$4)
        </td>
      </tr><tr>
        <td>
          404
        </td>
        <td>
          2980
        </td>
        <td>
          18259
          -
          18259
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$1
        </td>
      </tr><tr>
        <td>
          404
        </td>
        <td>
          2983
        </td>
        <td>
          18259
          -
          18259
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$4
        </td>
      </tr><tr>
        <td>
          404
        </td>
        <td>
          2982
        </td>
        <td>
          18259
          -
          18259
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$3
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>