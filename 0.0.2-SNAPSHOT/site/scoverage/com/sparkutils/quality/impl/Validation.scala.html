<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/impl/Validation.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality.impl
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality
</span>4 <span style=''>import com.sparkutils.quality.VariablesLookup.Identifiers
</span>5 <span style=''>import com.sparkutils.quality.utils.RuleSuiteDocs.{IdTrEither, LambdaId, OutputExpressionId, RuleId}
</span>6 <span style=''>import com.sparkutils.quality.utils.{Docs, DocsParser, RuleSuiteDocs, WithDocs}
</span>7 <span style=''>import com.sparkutils.quality.{ExpressionLookup, ExpressionRule, HasExpr, HasRuleText, Id, NoOpRunOnPassProcessor, OutputExpression, Rule, RuleLogicUtils, RuleSuite, RunOnPassProcessor, VariablesLookup, namesFromSchema}
</span>8 <span style=''>import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation
</span>9 <span style=''>import org.apache.spark.sql.{Column, DataFrame, QualitySparkUtils, Row, SparkSession}
</span>10 <span style=''>import org.apache.spark.sql.catalyst.expressions.{Expression, LambdaFunction, SubqueryExpression}
</span>11 <span style=''>import org.apache.spark.sql.catalyst.plans.logical.Project
</span>12 <span style=''>import org.apache.spark.sql.types.StructType
</span>13 <span style=''>
</span>14 <span style=''>import scala.collection.mutable
</span>15 <span style=''>
</span>16 <span style=''>sealed trait RuleRelevant
</span>17 <span style=''>sealed trait LambdaRelevant
</span>18 <span style=''>sealed trait OutputExpressionRelevant
</span>19 <span style=''>
</span>20 <span style=''>sealed trait HasId {
</span>21 <span style=''>  def id: Id
</span>22 <span style=''>}
</span>23 <span style=''>
</span>24 <span style=''>sealed trait HasOutputText {
</span>25 <span style=''>  def outputText: String
</span>26 <span style=''>}
</span>27 <span style=''>
</span>28 <span style=''>sealed trait HasNonIdText {
</span>29 <span style=''>  def nonIdText: String
</span>30 <span style=''>}
</span>31 <span style=''>
</span>32 <span style=''>/**
</span>33 <span style=''> * Base for RuleWarnings
</span>34 <span style=''> */
</span>35 <span style=''>sealed trait RuleWarning extends HasId with HasOutputText with HasNonIdText {
</span>36 <span style=''>  def warning: String
</span>37 <span style=''>
</span>38 <span style=''>  override def nonIdText: String = </span><span style='background: #AEF1AE'>warning</span><span style=''>
</span>39 <span style=''>
</span>40 <span style=''>  /**
</span>41 <span style=''>   * If the error is syntax based - defined by parsing, rather than any later stage
</span>42 <span style=''>   * @return
</span>43 <span style=''>   */
</span>44 <span style=''>  def syntax: Boolean = </span><span style='background: #F0ADAD'>false</span><span style=''>
</span>45 <span style=''>
</span>46 <span style=''>  def warningText = </span><span style='background: #AEF1AE'>s&quot;$warning, occurred when processing id $id&quot;</span><span style=''>
</span>47 <span style=''>
</span>48 <span style=''>  override def outputText: String = </span><span style='background: #AEF1AE'>warningText</span><span style=''>
</span>49 <span style=''>}
</span>50 <span style=''>
</span>51 <span style=''>sealed trait SyntaxWarning extends RuleWarning {
</span>52 <span style=''>  final override def syntax: Boolean = </span><span style='background: #F0ADAD'>true</span><span style=''>
</span>53 <span style=''>}
</span>54 <span style=''>
</span>55 <span style=''>sealed trait SyntaxNameWarning extends SyntaxWarning {
</span>56 <span style=''>  def name: String
</span>57 <span style=''>}
</span>58 <span style=''>
</span>59 <span style=''>case class LambdaPossibleSOE(id: Id) extends RuleWarning with LambdaRelevant {
</span>60 <span style=''>  val warning = </span><span style='background: #AEF1AE'>&quot;Possible SOE detected&quot;</span><span style=''>
</span>61 <span style=''>}
</span>62 <span style=''>
</span>63 <span style=''>case class NonLambdaDocParameters(id: Id) extends SyntaxWarning {
</span>64 <span style=''>  val warning = </span><span style='background: #AEF1AE'>&quot;Parameter documentation is present on a non lambda expression&quot;</span><span style=''>
</span>65 <span style=''>}
</span>66 <span style=''>
</span>67 <span style=''>case class ExtraDocParameter(id: Id, name: String) extends SyntaxNameWarning with LambdaRelevant {
</span>68 <span style=''>  val warning = </span><span style='background: #AEF1AE'>s&quot;Parameter $name is not found in the lambda expression&quot;</span><span style=''>
</span>69 <span style=''>}
</span>70 <span style=''>
</span>71 <span style=''>/**
</span>72 <span style=''> * Base for RuleErrors
</span>73 <span style=''> */
</span>74 <span style=''>sealed trait RuleError extends HasId with HasOutputText with HasNonIdText {
</span>75 <span style=''>  def error: String
</span>76 <span style=''>
</span>77 <span style=''>  override def nonIdText: String = </span><span style='background: #AEF1AE'>error</span><span style=''>
</span>78 <span style=''>  /**
</span>79 <span style=''>   * If the error is syntax based - defined by parsing, rather than any later stage
</span>80 <span style=''>   * @return
</span>81 <span style=''>   */
</span>82 <span style=''>  def syntax: Boolean = </span><span style='background: #F0ADAD'>false</span><span style=''>
</span>83 <span style=''>
</span>84 <span style=''>  def errorText = </span><span style='background: #AEF1AE'>s&quot;$error occurred when processing id $id&quot;</span><span style=''>
</span>85 <span style=''>
</span>86 <span style=''>  override def outputText: String = </span><span style='background: #AEF1AE'>errorText</span><span style=''>
</span>87 <span style=''>}
</span>88 <span style=''>
</span>89 <span style=''>sealed trait SyntaxError extends RuleError {
</span>90 <span style=''>  final override def syntax: Boolean = </span><span style='background: #F0ADAD'>true</span><span style=''>
</span>91 <span style=''>}
</span>92 <span style=''>
</span>93 <span style=''>sealed trait NameMissingError extends RuleError {
</span>94 <span style=''>  def name: String
</span>95 <span style=''>  final override def error = </span><span style='background: #AEF1AE'>s&quot;Name $name is missing&quot;</span><span style=''>
</span>96 <span style=''>}
</span>97 <span style=''>
</span>98 <span style=''>sealed trait ViewMissingError extends RuleError {
</span>99 <span style=''>  def name: String
</span>100 <span style=''>  final override def error = </span><span style='background: #F0ADAD'>s&quot;View $name is missing&quot;</span><span style=''>
</span>101 <span style=''>}
</span>102 <span style=''>
</span>103 <span style=''>case class LambdaSyntaxError(id: Id, error: String) extends SyntaxError with LambdaRelevant
</span>104 <span style=''>case class LambdaStackOverflowError(id: Id) extends SyntaxError with LambdaRelevant {
</span>105 <span style=''>  val error = </span><span style='background: #AEF1AE'>&quot;A lambda function seems to infinitely recurse&quot;</span><span style=''>
</span>106 <span style=''>}
</span>107 <span style=''>case class LambdaNameError(name: String, id: Id) extends NameMissingError with LambdaRelevant
</span>108 <span style=''>case class LambdaMultipleImplementationWithSameArityError(name: String, count: Int, argLength: Int, ids: Set[Id]) extends SyntaxError with LambdaRelevant {
</span>109 <span style=''>  val error = </span><span style='background: #AEF1AE'>s&quot;Lambda function $name has $count implementations with $argLength arguments&quot;</span><span style=''>
</span>110 <span style=''>  val id = </span><span style='background: #AEF1AE'>ids.head</span><span style=''>
</span>111 <span style=''>}
</span>112 <span style=''>case class LambdaViewError(name: String, id: Id) extends ViewMissingError with LambdaRelevant
</span>113 <span style=''>
</span>114 <span style=''>case class RuleSyntaxError(id: Id, error: String) extends SyntaxError with RuleRelevant
</span>115 <span style=''>case class RuleNameError(name: String, id: Id) extends NameMissingError with RuleRelevant
</span>116 <span style=''>case class RuleViewError(name: String, id: Id) extends ViewMissingError with RuleRelevant
</span>117 <span style=''>
</span>118 <span style=''>case class OutputRuleSyntaxError(id: Id, error: String) extends SyntaxError with OutputExpressionRelevant
</span>119 <span style=''>case class OutputRuleNameError(name: String, id: Id) extends NameMissingError with OutputExpressionRelevant
</span>120 <span style=''>case class OutputRuleViewError(name: String, id: Id) extends ViewMissingError with OutputExpressionRelevant
</span>121 <span style=''>
</span>122 <span style=''>case class LambdaSparkFunctionNameError(name: String, id: Id) extends NameMissingError with LambdaRelevant
</span>123 <span style=''>case class SparkFunctionNameError(name: String, id: Id) extends NameMissingError with RuleRelevant
</span>124 <span style=''>case class OuputSparkFunctionNameError(name: String, id: Id) extends NameMissingError with OutputExpressionRelevant
</span>125 <span style=''>
</span>126 <span style=''>case class DataFrameSyntaxError(error: String) extends SyntaxError {
</span>127 <span style=''>  val id = </span><span style='background: #AEF1AE'>Validation.dataFrameSyntaxErrorId</span><span style=''>
</span>128 <span style=''>}
</span>129 <span style=''>
</span>130 <span style=''>object Validation {
</span>131 <span style=''>  val unknownSOEId = </span><span style='background: #AEF1AE'>Id(Int.MinValue,Int.MinValue)</span><span style=''>
</span>132 <span style=''>  val dataFrameSyntaxErrorId = </span><span style='background: #AEF1AE'>Id(Int.MinValue+1,Int.MinValue+1)</span><span style=''>
</span>133 <span style=''>}
</span>134 <span style=''>
</span>135 <span style=''>/**
</span>136 <span style=''> * Paramters to pass into showString for debugging / validation
</span>137 <span style=''> * @param numRows defaults to 1000
</span>138 <span style=''> * @param truncate
</span>139 <span style=''> * @param vertical
</span>140 <span style=''> */
</span>141 <span style=''>case class ShowParams(numRows: Int = 1000, truncate: Int = 0, vertical: Boolean = false)
</span>142 <span style=''>
</span>143 <span style=''>trait Validation {
</span>144 <span style=''>
</span>145 <span style=''>  protected val defaultViewLookup: String =&gt; Boolean =
</span>146 <span style=''>    </span><span style='background: #AEF1AE'>SparkSession.active.catalog.tableExists(_)</span><span style=''>
</span>147 <span style=''>
</span>148 <span style=''>  /**
</span>149 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>150 <span style=''>   *
</span>151 <span style=''>   * @param schema which fields should the dataframe have
</span>152 <span style=''>   * @param ruleSuite
</span>153 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>154 <span style=''>   */
</span>155 <span style=''>  def validate_Lookup(schema: StructType, ruleSuite: RuleSuite, viewLookup: String =&gt; Boolean): (Set[RuleError], Set[RuleWarning]) = {
</span>156 <span style=''>    val (err, warns, out, docs, exp) = validate(Left(schema), ruleSuite, viewLookup = viewLookup)
</span>157 <span style=''>    </span><span style='background: #F0ADAD'>(err, warns)</span><span style=''>
</span>158 <span style=''>  }
</span>159 <span style=''>
</span>160 <span style=''>  /**
</span>161 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>162 <span style=''>   *
</span>163 <span style=''>   * @param schema which fields should the dataframe have
</span>164 <span style=''>   * @param ruleSuite
</span>165 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>166 <span style=''>   */
</span>167 <span style=''>  def validate(schema: StructType, ruleSuite: RuleSuite): (Set[RuleError], Set[RuleWarning]) = {
</span>168 <span style=''>    val (err, warns, out, docs, exp) = validate(Left(schema), ruleSuite)
</span>169 <span style=''>    </span><span style='background: #AEF1AE'>(err, warns)</span><span style=''>
</span>170 <span style=''>  }
</span>171 <span style=''>
</span>172 <span style=''>  /**
</span>173 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>174 <span style=''>   *
</span>175 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>176 <span style=''>   * @param ruleSuite
</span>177 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>178 <span style=''>   */
</span>179 <span style=''>  def validate_Lookup(frame: DataFrame, ruleSuite: RuleSuite, viewLookup: String =&gt; Boolean = defaultViewLookup): (Set[RuleError], Set[RuleWarning]) = {
</span>180 <span style=''>    val (err, warns, out, docs, exp) = validate(Right(frame), ruleSuite, viewLookup = viewLookup)
</span>181 <span style=''>    </span><span style='background: #F0ADAD'>(err, warns)</span><span style=''>
</span>182 <span style=''>  }
</span>183 <span style=''>
</span>184 <span style=''>  /**
</span>185 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>186 <span style=''>   *
</span>187 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>188 <span style=''>   * @param ruleSuite
</span>189 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>190 <span style=''>   */
</span>191 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite): (Set[RuleError], Set[RuleWarning]) = {
</span>192 <span style=''>    val (err, warns, out, docs, exp) = validate(Right(frame), ruleSuite)
</span>193 <span style=''>    </span><span style='background: #AEF1AE'>(err, warns)</span><span style=''>
</span>194 <span style=''>  }
</span>195 <span style=''>
</span>196 <span style=''>  /**
</span>197 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>198 <span style=''>   *
</span>199 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>200 <span style=''>   * @param ruleSuite
</span>201 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>202 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>203 <span style=''>   *
</span>204 <span style=''>   */
</span>205 <span style=''>  def validate_Lookup(frame: DataFrame, ruleSuite: RuleSuite, runnerFunction: DataFrame =&gt; Column, viewLookup: String =&gt; Boolean): (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) =
</span>206 <span style=''>    </span><span style='background: #F0ADAD'>validate(Right(frame), ruleSuite, runnerFunction = Some(runnerFunction), viewLookup = viewLookup)</span><span style=''>
</span>207 <span style=''>
</span>208 <span style=''>
</span>209 <span style=''>  /**
</span>210 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>211 <span style=''>   *
</span>212 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>213 <span style=''>   * @param ruleSuite
</span>214 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>215 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>216 <span style=''>   */
</span>217 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite, runnerFunction: DataFrame =&gt; Column): (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) =
</span>218 <span style=''>    </span><span style='background: #AEF1AE'>validate(Right(frame), ruleSuite, runnerFunction = Some(runnerFunction))</span><span style=''>
</span>219 <span style=''>
</span>220 <span style=''>  /**
</span>221 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>222 <span style=''>   *
</span>223 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>224 <span style=''>   * @param ruleSuite
</span>225 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>226 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>227 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>228 <span style=''>   */
</span>229 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite, runnerFunction: DataFrame =&gt; Column, transformBeforeShow: DataFrame =&gt; DataFrame, viewLookup: String =&gt; Boolean): (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) =
</span>230 <span style=''>    </span><span style='background: #F0ADAD'>validate(Right(frame), ruleSuite, runnerFunction = Some(runnerFunction), transformBeforeShow = transformBeforeShow, viewLookup = viewLookup)</span><span style=''>
</span>231 <span style=''>
</span>232 <span style=''>  /**
</span>233 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>234 <span style=''>   *
</span>235 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>236 <span style=''>   * @param ruleSuite
</span>237 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>238 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>239 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>240 <span style=''>   */
</span>241 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite, runnerFunction: DataFrame =&gt; Column, transformBeforeShow: DataFrame =&gt; DataFrame): (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) =
</span>242 <span style=''>    </span><span style='background: #AEF1AE'>validate(Right(frame), ruleSuite, runnerFunction = Some(runnerFunction), transformBeforeShow = transformBeforeShow)</span><span style=''>
</span>243 <span style=''>
</span>244 <span style=''>  val emptyDocs = </span><span style='background: #AEF1AE'>Docs()</span><span style=''>
</span>245 <span style=''>
</span>246 <span style=''>  /**
</span>247 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>248 <span style=''>   *
</span>249 <span style=''>   * @param schemaOrFrame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>250 <span style=''>   * @param ruleSuite
</span>251 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>252 <span style=''>   * @param showParams - configure how the output text is formatted using the same options and formatting as dataFrame.show
</span>253 <span style=''>   * @param qualityName - the column name to store the runnerFunction results in
</span>254 <span style=''>   * @param recursiveLambdasSOEIsOk - this signals that finding a recursive lambda SOE should not stop the evaluations - if true it will still try to run any runnerFunction but may not give the correct results
</span>255 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>256 <span style=''>   * @param viewLookup - for any subquery used looks up the view name for being present (quoted and with schema), defaults to the current spark catalogue
</span>257 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>258 <span style=''>   */
</span>259 <span style=''>  def validate(schemaOrFrame: Either[StructType, DataFrame], ruleSuite: RuleSuite, showParams: ShowParams = ShowParams(),
</span>260 <span style=''>               runnerFunction: Option[DataFrame =&gt; Column] = None, qualityName: String = &quot;Quality&quot;,
</span>261 <span style=''>               recursiveLambdasSOEIsOk: Boolean = false, transformBeforeShow: DataFrame =&gt; DataFrame = identity, viewLookup: String =&gt; Boolean = defaultViewLookup):
</span>262 <span style=''>                (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) = {
</span>263 <span style=''>    val schema = </span><span style='background: #AEF1AE'>schemaOrFrame.fold(identity, _.schema)</span><span style=''>
</span>264 <span style=''>
</span>265 <span style=''>    val names = </span><span style='background: #AEF1AE'>namesFromSchema(schema)</span><span style=''>
</span>266 <span style=''>
</span>267 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>268 <span style=''>
</span>269 <span style=''>    val ((lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, lambdas, lambdaDocWarnings, lambadaExpressionLookups, lambdaViewErrors)) =
</span>270 <span style=''>      validateLambdas(ruleSuite, recursiveLambdasSOEIsOk, names, viewLookup) match {
</span>271 <span style=''>        case Left(toReturn) =&gt; return toReturn
</span>272 <span style=''>        case Right(result) =&gt; result
</span>273 <span style=''>      }
</span>274 <span style=''>
</span>275 <span style=''>    </span><span style='background: #AEF1AE'>docsWarnings ++= lambdaDocWarnings</span><span style=''>
</span>276 <span style=''>
</span>277 <span style=''>    val (ruleErrors, ruleDocWarnings, rules, outputExpressions, ruleExpressionLookups) = validateRules(ruleSuite, lambdaLookups, names, viewLookup)
</span>278 <span style=''>
</span>279 <span style=''>    </span><span style='background: #AEF1AE'>docsWarnings ++= ruleDocWarnings</span><span style=''>
</span>280 <span style=''>
</span>281 <span style=''>    val (showOut, dfErrors) =
</span>282 <span style=''>      validateAgainstDataFrame(schemaOrFrame, showParams, runnerFunction, qualityName, transformBeforeShow, schema, viewLookup)
</span>283 <span style=''>
</span>284 <span style=''>    </span><span style='background: #AEF1AE'>(unknownLambdaSparkFunctionErrors ++ lambdaArityErrors ++ dfErrors ++ ruleErrors ++ lambdaNameErrors ++ lambdaSyntaxErrors.map(_._2.right.get).toSet ++ lambdaViewErrors,
</span>285 <span style=''></span><span style='background: #AEF1AE'>      potentialOverflows.map( LambdaPossibleSOE ) ++ (Set() ++ docsWarnings)
</span>286 <span style=''></span><span style='background: #AEF1AE'>      , showOut, RuleSuiteDocs(rules, outputExpressions, lambdas), lambadaExpressionLookups ++ ruleExpressionLookups)</span><span style=''>
</span>287 <span style=''>  }
</span>288 <span style=''>
</span>289 <span style=''>  protected def validateAgainstDataFrame(schemaOrFrame: Either[StructType, DataFrame], showParams: ShowParams, runnerFunction: Option[DataFrame =&gt; Column], qualityName: String, transformBeforeShow: DataFrame =&gt; DataFrame, schema: StructType, viewLookup: String =&gt; Boolean) = {
</span>290 <span style=''>    val basedf = </span><span style='background: #AEF1AE'>schemaOrFrame.right.getOrElse {
</span>291 <span style=''></span><span style='background: #AEF1AE'>      val session = SparkSession.active
</span>292 <span style=''></span><span style='background: #AEF1AE'>      val empty = session.sparkContext.emptyRDD[Row]
</span>293 <span style=''></span><span style='background: #AEF1AE'>      session.createDataFrame(empty, schema)
</span>294 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>295 <span style=''>
</span>296 <span style=''>    val (showOut, dfErrors) =
</span>297 <span style=''>      runnerFunction.fold((&quot;&quot;, Set.empty[RuleError]))(rf =&gt; {
</span>298 <span style=''>        val runner = rf(basedf)
</span>299 <span style=''>        try {
</span>300 <span style=''>          val withRules = basedf.withColumn(qualityName, runner)
</span>301 <span style=''>          val transformed = transformBeforeShow(withRules)
</span>302 <span style=''>          (QualitySparkUtils.toString(transformed, showParams), Set.empty)
</span>303 <span style=''>        } catch {
</span>304 <span style=''>          case e: Throwable =&gt; (&quot;&quot;, Set(DataFrameSyntaxError(e.getMessage)))
</span>305 <span style=''>        }
</span>306 <span style=''>      })
</span>307 <span style=''>    </span><span style='background: #AEF1AE'>(showOut, dfErrors)</span><span style=''>
</span>308 <span style=''>  }
</span>309 <span style=''>
</span>310 <span style=''>  protected def validateRules(ruleSuite: RuleSuite, lambdaLookups: Map[String, Map[Id, Set[String]]], names: Set[String], viewLookup: String =&gt; Boolean)= {
</span>311 <span style=''>    val doRule = </span><span style='background: #AEF1AE'>validateRule(lambdaLookups, names)</span><span style=''> _
</span>312 <span style=''>
</span>313 <span style=''>    var rules = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[Rule]]</span><span style=''>
</span>314 <span style=''>    var outputExpressions = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[RunOnPassProcessor]]</span><span style=''>
</span>315 <span style=''>    var exprLookups = </span><span style='background: #AEF1AE'>Map.empty[IdTrEither, ExpressionLookup]</span><span style=''>
</span>316 <span style=''>
</span>317 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>318 <span style=''>
</span>319 <span style=''>    def addDocs[T](id: Id, rule: T, expressionRule: HasRuleText): (Id, WithDocs[T]) =
</span>320 <span style=''>      </span><span style='background: #AEF1AE'>DocsParser.parse(expressionRule.rule).map { parseddocs =&gt;
</span>321 <span style=''></span><span style='background: #AEF1AE'>        val res = id -&gt; WithDocs(rule, parseddocs)
</span>322 <span style=''></span><span style='background: #AEF1AE'>        if (parseddocs.params.nonEmpty) {
</span>323 <span style=''></span><span style='background: #AEF1AE'>          docsWarnings += NonLambdaDocParameters(id)
</span>324 <span style=''></span><span style='background: #AEF1AE'>        }
</span>325 <span style=''></span><span style='background: #AEF1AE'>        res
</span>326 <span style=''></span><span style='background: #AEF1AE'>      }.getOrElse(id -&gt; WithDocs(rule, emptyDocs))</span><span style=''>
</span>327 <span style=''>
</span>328 <span style=''>    // do the rules
</span>329 <span style=''>    val ruleErrors =
</span>330 <span style=''>      </span><span style='background: #AEF1AE'>ruleSuite.ruleSets.flatMap { rs =&gt;
</span>331 <span style=''></span><span style='background: #AEF1AE'>        rs.rules.flatMap { r =&gt;
</span>332 <span style=''></span><span style='background: #AEF1AE'>          rules += addDocs(r.id, r, r.expression.asInstanceOf[HasRuleText])
</span>333 <span style=''></span><span style='background: #AEF1AE'>
</span>334 <span style=''></span><span style='background: #AEF1AE'>          val (ruleErrors, exprLookup) = doRule(r.id, r.expression.asInstanceOf[HasExpr].expr, false, viewLookup)
</span>335 <span style=''></span><span style='background: #AEF1AE'>          exprLookups += RuleId(r.id) -&gt; exprLookup
</span>336 <span style=''></span><span style='background: #AEF1AE'>
</span>337 <span style=''></span><span style='background: #AEF1AE'>          val outputErrors =
</span>338 <span style=''></span><span style='background: #AEF1AE'>            if (r.runOnPassProcessor != NoOpRunOnPassProcessor.noOp) {
</span>339 <span style=''></span><span style='background: #AEF1AE'>              outputExpressions += addDocs(r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[OutputExpression])
</span>340 <span style=''></span><span style='background: #AEF1AE'>
</span>341 <span style=''></span><span style='background: #AEF1AE'>              val (oErrors, oExprLookup) = doRule(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup)
</span>342 <span style=''></span><span style='background: #AEF1AE'>              exprLookups += OutputExpressionId(r.runOnPassProcessor.id) -&gt; oExprLookup
</span>343 <span style=''></span><span style='background: #AEF1AE'>              oErrors
</span>344 <span style=''></span><span style='background: #AEF1AE'>            } else
</span>345 <span style=''></span><span style='background: #AEF1AE'>              Set.empty
</span>346 <span style=''></span><span style='background: #AEF1AE'>
</span>347 <span style=''></span><span style='background: #AEF1AE'>          ruleErrors ++ outputErrors
</span>348 <span style=''></span><span style='background: #AEF1AE'>        }
</span>349 <span style=''></span><span style='background: #AEF1AE'>      }.toSet</span><span style=''>
</span>350 <span style=''>
</span>351 <span style=''>    </span><span style='background: #AEF1AE'>(ruleErrors, Set() ++ docsWarnings, Map() ++ rules, outputExpressions, Map() ++ exprLookups)</span><span style=''>
</span>352 <span style=''>  }
</span>353 <span style=''>
</span>354 <span style=''>  protected def validateLambdas(ruleSuite: RuleSuite, recursiveLambdasSOEIsOk: Boolean, names: Set[String], viewLookup: String =&gt; Boolean): Either[(Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]),
</span>355 <span style=''>    (Seq[(String, Either[(Id, Expression), LambdaSyntaxError])], Map[String, Map[Id, Set[String]]],
</span>356 <span style=''>      Set[Id], Set[LambdaSparkFunctionNameError], Set[LambdaMultipleImplementationWithSameArityError], Set[LambdaNameError], Map[Id, WithDocs[quality.LambdaFunction]], Set[RuleWarning], Map[IdTrEither, ExpressionLookup], Set[LambdaViewError])] = {
</span>357 <span style=''>
</span>358 <span style=''>    var lambdas = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[quality.LambdaFunction]]</span><span style=''>
</span>359 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>360 <span style=''>
</span>361 <span style=''>    val viewErrors = </span><span style='background: #AEF1AE'>ruleSuite.lambdaFunctions.flatMap { f =&gt;
</span>362 <span style=''></span><span style='background: #AEF1AE'>      try {
</span>363 <span style=''></span><span style='background: #AEF1AE'>        subQueryErrors(viewLookup, f.expr, LambdaViewError(_, f.id))
</span>364 <span style=''></span><span style='background: #AEF1AE'>      } catch {
</span>365 <span style=''></span><span style='background: #AEF1AE'>        // Might be a parser error, skip to let the below code pick it up
</span>366 <span style=''></span><span style='background: #AEF1AE'>        case _: Throwable =&gt; Set.empty[LambdaViewError]
</span>367 <span style=''></span><span style='background: #AEF1AE'>      }
</span>368 <span style=''></span><span style='background: #AEF1AE'>    }.toSet</span><span style=''>
</span>369 <span style=''>
</span>370 <span style=''>    val (lambdaLeftExpressions, lambdaSyntaxErrors) = ruleSuite.lambdaFunctions.map { f =&gt;
</span>371 <span style=''>      (f.name,
</span>372 <span style=''>        try {
</span>373 <span style=''>          val expr = f.expr
</span>374 <span style=''>          val ret = Left((f.id, expr))
</span>375 <span style=''>
</span>376 <span style=''>          val args =
</span>377 <span style=''>            expr match {
</span>378 <span style=''>              case lambda: LambdaFunction =&gt; lambda.arguments.map(VariablesLookup.toName).toSet
</span>379 <span style=''>              case _ =&gt; Set.empty[String]
</span>380 <span style=''>            }
</span>381 <span style=''>
</span>382 <span style=''>          DocsParser.parse(f.rule).map { parseddocs =&gt;
</span>383 <span style=''>            lambdas += f.id -&gt; WithDocs(f, parseddocs)
</span>384 <span style=''>
</span>385 <span style=''>            parseddocs.params.keySet.foreach { name =&gt;
</span>386 <span style=''>              if (!args.contains(name)) {
</span>387 <span style=''>                docsWarnings += ExtraDocParameter(f.id, name)
</span>388 <span style=''>              }
</span>389 <span style=''>            }
</span>390 <span style=''>          }.getOrElse {
</span>391 <span style=''>            lambdas += f.id -&gt; WithDocs(f, emptyDocs)
</span>392 <span style=''>          }
</span>393 <span style=''>
</span>394 <span style=''>          ret
</span>395 <span style=''>        } catch {
</span>396 <span style=''>          case e: Throwable =&gt; Right(LambdaSyntaxError(f.id, e.getMessage))
</span>397 <span style=''>        })
</span>398 <span style=''>    }.partition {
</span>399 <span style=''>      _._2.isLeft
</span>400 <span style=''>    }
</span>401 <span style=''>
</span>402 <span style=''>    val lambdaNameToExpressions = </span><span style='background: #AEF1AE'>lambdaLeftExpressions.groupBy(p =&gt; p._1).mapValues(e =&gt; e.map(_._2.left.get).toMap)</span><span style=''>
</span>403 <span style=''>
</span>404 <span style=''>    val (lambdaLookups, potentialOverflows, unknownLambdaSparkFunctions) = try {
</span>405 <span style=''>      VariablesLookup.processLambdas(lambdaNameToExpressions)
</span>406 <span style=''>    } catch {
</span>407 <span style=''>      // SOE is possible with lambdas calling lambdas, capture that as a distinct issue
</span>408 <span style=''>      case soe: StackOverflowError =&gt;
</span>409 <span style=''>        if (recursiveLambdasSOEIsOk)
</span>410 <span style=''>        // type needed otherwise it gets stuck with the first param type derivation _1 &lt;: String instead of String
</span>411 <span style=''>          (Map.empty[String, Map[Id, Identifiers]], Set.empty[Id], Map.empty[Id, Set[String]])
</span>412 <span style=''>        else
</span>413 <span style=''>          return Left((Set(LambdaStackOverflowError(Validation.unknownSOEId)), Set.empty[RuleWarning], &quot;&quot;, RuleSuiteDocs(), Map.empty[IdTrEither, ExpressionLookup]))
</span>414 <span style=''>    }
</span>415 <span style=''>
</span>416 <span style=''>    // now that they are looked up, a bit duplicative but...
</span>417 <span style=''>    val exprLookups = </span><span style='background: #AEF1AE'>lambdaNameToExpressions.values.flatMap( m =&gt; m.map(pair =&gt; LambdaId(pair._1) -&gt; VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))).toMap</span><span style=''>
</span>418 <span style=''>
</span>419 <span style=''>    val unknownLambdaSparkFunctionErrors = </span><span style='background: #AEF1AE'>unknownLambdaSparkFunctions.flatMap(p =&gt; p._2.map(name =&gt;
</span>420 <span style=''></span><span style='background: #AEF1AE'>      LambdaSparkFunctionNameError(name, p._1))).toSet</span><span style=''>
</span>421 <span style=''>
</span>422 <span style=''>    val lambdaArityErrors = </span><span style='background: #AEF1AE'>lambdaNameToExpressions.filter(p =&gt; p._2.size &gt; 1).flatMap {
</span>423 <span style=''></span><span style='background: #AEF1AE'>      pairs =&gt;
</span>424 <span style=''></span><span style='background: #AEF1AE'>        val map = pairs._2
</span>425 <span style=''></span><span style='background: #AEF1AE'>
</span>426 <span style=''></span><span style='background: #AEF1AE'>        val counts = map.groupBy(_._2.children.size - 1) // one child is the return
</span>427 <span style=''></span><span style='background: #AEF1AE'>        val moreThan1 = counts.collectFirst { case f if f._2.size &gt; 1 =&gt; f }
</span>428 <span style=''></span><span style='background: #AEF1AE'>        moreThan1.map { f =&gt;
</span>429 <span style=''></span><span style='background: #AEF1AE'>          LambdaMultipleImplementationWithSameArityError(pairs._1, f._2.size, f._1, f._2.keySet)
</span>430 <span style=''></span><span style='background: #AEF1AE'>        }
</span>431 <span style=''></span><span style='background: #AEF1AE'>    }.toSet</span><span style=''>
</span>432 <span style=''>
</span>433 <span style=''>    // do we have variables used in the lambdas which are not in the schema?
</span>434 <span style=''>    val lambdaNameErrors: Set[LambdaNameError] =
</span>435 <span style=''>      </span><span style='background: #AEF1AE'>lambdaLookups.flatMap { p =&gt;
</span>436 <span style=''></span><span style='background: #AEF1AE'>        p._2.flatMap { pair =&gt;
</span>437 <span style=''></span><span style='background: #AEF1AE'>          val (id, identifiers) = pair
</span>438 <span style=''></span><span style='background: #AEF1AE'>          if (identifiers.diff(names).isEmpty)
</span>439 <span style=''></span><span style='background: #AEF1AE'>            None
</span>440 <span style=''></span><span style='background: #AEF1AE'>          else
</span>441 <span style=''></span><span style='background: #AEF1AE'>            Some(identifiers.diff(names).map(LambdaNameError(_, id)))
</span>442 <span style=''></span><span style='background: #AEF1AE'>        }
</span>443 <span style=''></span><span style='background: #AEF1AE'>      }.flatten.toSet</span><span style=''>
</span>444 <span style=''>    </span><span style='background: #AEF1AE'>Right((lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, Map() ++ lambdas, Set() ++ docsWarnings, exprLookups, viewErrors))</span><span style=''>
</span>445 <span style=''>  }
</span>446 <span style=''>
</span>447 <span style=''>  protected def subQueryErrors[T](lookup: String =&gt; Boolean, expression: Expression, f: String =&gt; T): Set[T] = (</span><span style='background: #AEF1AE'>expression collect {
</span>448 <span style=''></span><span style='background: #AEF1AE'>    case s: SubqueryExpression =&gt; s.plan.collect{
</span>449 <span style=''></span><span style='background: #AEF1AE'>      case rel: UnresolvedRelation if !lookup(rel.tableName) =&gt;
</span>450 <span style=''></span><span style='background: #AEF1AE'>        f(rel.tableName)
</span>451 <span style=''></span><span style='background: #AEF1AE'>    }
</span>452 <span style=''></span><span style='background: #AEF1AE'>  }).flatten.toSet</span><span style=''>
</span>453 <span style=''>
</span>454 <span style=''>  protected def validateRule(lambdaLookups: Map[String, Map[Id, Set[String]]], names: Set[String])(id: Id, exprThunk: =&gt; Expression, outputRule: Boolean, viewLookup: String =&gt; Boolean): (Set[RuleError], ExpressionLookup) =
</span>455 <span style=''>    try {
</span>456 <span style=''>      </span><span style='background: #AEF1AE'>val expr = exprThunk
</span>457 <span style=''></span><span style='background: #AEF1AE'>      val exl @ ExpressionLookup(exprFields, unknownSparkFunctions, _, _) = VariablesLookup.fieldsFromExpression(expr, lambdaLookups)
</span>458 <span style=''></span><span style='background: #AEF1AE'>      val rules = exprFields.flatMap{
</span>459 <span style=''></span><span style='background: #AEF1AE'>        field =&gt;
</span>460 <span style=''></span><span style='background: #AEF1AE'>          if (names.contains(field))
</span>461 <span style=''></span><span style='background: #AEF1AE'>            None
</span>462 <span style=''></span><span style='background: #AEF1AE'>          else
</span>463 <span style=''></span><span style='background: #AEF1AE'>            Some(
</span>464 <span style=''></span><span style='background: #AEF1AE'>              if (!outputRule)
</span>465 <span style=''></span><span style='background: #AEF1AE'>                RuleNameError(field, id)
</span>466 <span style=''></span><span style='background: #AEF1AE'>              else
</span>467 <span style=''></span><span style='background: #AEF1AE'>                OutputRuleNameError(field, id)
</span>468 <span style=''></span><span style='background: #AEF1AE'>            )
</span>469 <span style=''></span><span style='background: #AEF1AE'>      }.toSet[RuleError]
</span>470 <span style=''></span><span style='background: #AEF1AE'>
</span>471 <span style=''></span><span style='background: #AEF1AE'>      val viewErrors = subQueryErrors(viewLookup, exprThunk, if (outputRule) OutputRuleViewError(_, id) else RuleViewError(_, id))
</span>472 <span style=''></span><span style='background: #AEF1AE'>
</span>473 <span style=''></span><span style='background: #AEF1AE'>      val unknown = unknownSparkFunctions.map{ name =&gt;
</span>474 <span style=''></span><span style='background: #AEF1AE'>        if (!outputRule)
</span>475 <span style=''></span><span style='background: #AEF1AE'>          SparkFunctionNameError(name, id)
</span>476 <span style=''></span><span style='background: #AEF1AE'>        else
</span>477 <span style=''></span><span style='background: #AEF1AE'>          OuputSparkFunctionNameError(name, id)
</span>478 <span style=''></span><span style='background: #AEF1AE'>      }
</span>479 <span style=''></span><span style='background: #AEF1AE'>
</span>480 <span style=''></span><span style='background: #AEF1AE'>      (rules ++ unknown ++ viewErrors, exl)</span><span style=''>
</span>481 <span style=''>    } catch {
</span>482 <span style=''>      case e: Throwable =&gt; </span><span style='background: #AEF1AE'>(Set(
</span>483 <span style=''></span><span style='background: #AEF1AE'>        if (!outputRule)
</span>484 <span style=''></span><span style='background: #AEF1AE'>          RuleSyntaxError(id, e.getMessage)
</span>485 <span style=''></span><span style='background: #AEF1AE'>        else
</span>486 <span style=''></span><span style='background: #AEF1AE'>          OutputRuleSyntaxError(id, e.getMessage)
</span>487 <span style=''></span><span style='background: #AEF1AE'>      ), ExpressionLookup())</span><span style=''>
</span>488 <span style=''>    }
</span>489 <span style=''>
</span>490 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          38
        </td>
        <td>
          2701
        </td>
        <td>
          1324
          -
          1331
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warning
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          2702
        </td>
        <td>
          1466
          -
          1471
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          false
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          2703
        </td>
        <td>
          1495
          -
          1496
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          2706
        </td>
        <td>
          1496
          -
          1503
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warning
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          2708
        </td>
        <td>
          1493
          -
          1537
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;, occurred when processing id &quot;, &quot;&quot;).s(RuleWarning.this.warning, RuleWarning.this.id)
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          2705
        </td>
        <td>
          1536
          -
          1537
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          2704
        </td>
        <td>
          1503
          -
          1534
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;, occurred when processing id &quot;
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          2707
        </td>
        <td>
          1534
          -
          1536
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasId.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.id
        </td>
      </tr><tr>
        <td>
          48
        </td>
        <td>
          2709
        </td>
        <td>
          1575
          -
          1586
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warningText
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warningText
        </td>
      </tr><tr>
        <td>
          52
        </td>
        <td>
          2710
        </td>
        <td>
          1678
          -
          1682
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          true
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          2711
        </td>
        <td>
          1858
          -
          1881
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Possible SOE detected&quot;
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          2712
        </td>
        <td>
          1967
          -
          2030
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter documentation is present on a non lambda expression&quot;
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          2715
        </td>
        <td>
          2162
          -
          2166
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ExtraDocParameter.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExtraDocParameter.this.name
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          2714
        </td>
        <td>
          2166
          -
          2205
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is not found in the lambda expression&quot;
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          2713
        </td>
        <td>
          2151
          -
          2162
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter &quot;
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          2716
        </td>
        <td>
          2149
          -
          2205
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Parameter &quot;, &quot; is not found in the lambda expression&quot;).s(ExtraDocParameter.this.name)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          2717
        </td>
        <td>
          2372
          -
          2377
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.error
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.error
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          2718
        </td>
        <td>
          2511
          -
          2516
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          false
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          2721
        </td>
        <td>
          2576
          -
          2577
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          2724
        </td>
        <td>
          2536
          -
          2577
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot; occurred when processing id &quot;, &quot;&quot;).s(RuleError.this.error, RuleError.this.id)
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          2723
        </td>
        <td>
          2574
          -
          2576
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasId.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.id
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          2720
        </td>
        <td>
          2544
          -
          2574
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; occurred when processing id &quot;
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          2722
        </td>
        <td>
          2539
          -
          2544
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.error
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.error
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          2719
        </td>
        <td>
          2538
          -
          2539
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          2725
        </td>
        <td>
          2615
          -
          2624
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.errorText
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.errorText
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          2726
        </td>
        <td>
          2712
          -
          2716
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          true
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          2730
        </td>
        <td>
          2818
          -
          2842
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Name &quot;, &quot; is missing&quot;).s(NameMissingError.this.name)
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          2729
        </td>
        <td>
          2826
          -
          2830
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.NameMissingError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NameMissingError.this.name
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          2728
        </td>
        <td>
          2830
          -
          2842
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is missing&quot;
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          2727
        </td>
        <td>
          2820
          -
          2826
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Name &quot;
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          2733
        </td>
        <td>
          2952
          -
          2956
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ViewMissingError.name
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ViewMissingError.this.name
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          2732
        </td>
        <td>
          2956
          -
          2968
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot; is missing&quot;
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          2731
        </td>
        <td>
          2946
          -
          2952
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;View &quot;
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          2734
        </td>
        <td>
          2944
          -
          2968
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;View &quot;, &quot; is missing&quot;).s(ViewMissingError.this.name)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          2735
        </td>
        <td>
          3164
          -
          3211
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;A lambda function seems to infinitely recurse&quot;
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          2739
        </td>
        <td>
          3544
          -
          3555
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; arguments&quot;
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          2742
        </td>
        <td>
          3535
          -
          3544
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.argLength
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.argLength
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          2741
        </td>
        <td>
          3507
          -
          3512
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.count
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.count
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          2738
        </td>
        <td>
          3512
          -
          3535
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; implementations with &quot;
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          2737
        </td>
        <td>
          3501
          -
          3507
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; has &quot;
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          2740
        </td>
        <td>
          3497
          -
          3501
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.name
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          2743
        </td>
        <td>
          3478
          -
          3555
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Lambda function &quot;, &quot; has &quot;, &quot; implementations with &quot;, &quot; arguments&quot;).s(LambdaMultipleImplementationWithSameArityError.this.name, LambdaMultipleImplementationWithSameArityError.this.count, LambdaMultipleImplementationWithSameArityError.this.argLength)
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          2736
        </td>
        <td>
          3480
          -
          3497
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Lambda function &quot;
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          2744
        </td>
        <td>
          3567
          -
          3575
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.IterableLike.head
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.ids.head
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          2745
        </td>
        <td>
          4668
          -
          4701
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.dataFrameSyntaxErrorId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.dataFrameSyntaxErrorId
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          2746
        </td>
        <td>
          4746
          -
          4775
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.Id.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.Id.apply(-2147483648, -2147483648)
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          2747
        </td>
        <td>
          4807
          -
          4840
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.Id.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.Id.apply(-2147483647, -2147483647)
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          2748
        </td>
        <td>
          5158
          -
          5200
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalog.Catalog.tableExists
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active.catalog.tableExists(x$1)
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          2750
        </td>
        <td>
          5640
          -
          5640
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._2
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          2753
        </td>
        <td>
          5658
          -
          5658
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._5
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          2749
        </td>
        <td>
          5635
          -
          5635
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._1
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          2752
        </td>
        <td>
          5652
          -
          5652
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._4
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          2751
        </td>
        <td>
          5647
          -
          5647
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._3
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          2754
        </td>
        <td>
          5728
          -
          5740
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning]](err, warns)
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          2757
        </td>
        <td>
          6153
          -
          6153
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._3
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          2759
        </td>
        <td>
          6164
          -
          6164
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._5
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          2756
        </td>
        <td>
          6146
          -
          6146
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._2
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          2755
        </td>
        <td>
          6141
          -
          6141
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._1
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          2758
        </td>
        <td>
          6158
          -
          6158
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._4
        </td>
      </tr><tr>
        <td>
          169
        </td>
        <td>
          2760
        </td>
        <td>
          6209
          -
          6221
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning]](err, warns)
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          2762
        </td>
        <td>
          6901
          -
          6901
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$4._2
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          2765
        </td>
        <td>
          6919
          -
          6919
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$4._5
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          2764
        </td>
        <td>
          6913
          -
          6913
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$4._4
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          2761
        </td>
        <td>
          6896
          -
          6896
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$4._1
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          2763
        </td>
        <td>
          6908
          -
          6908
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$4._3
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          2766
        </td>
        <td>
          6989
          -
          7001
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning]](err, warns)
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          2768
        </td>
        <td>
          7623
          -
          7623
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._2
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          2771
        </td>
        <td>
          7641
          -
          7641
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._5
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          2767
        </td>
        <td>
          7618
          -
          7618
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._1
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          2770
        </td>
        <td>
          7635
          -
          7635
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._4
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          2769
        </td>
        <td>
          7630
          -
          7630
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._3
        </td>
      </tr><tr>
        <td>
          193
        </td>
        <td>
          2772
        </td>
        <td>
          7686
          -
          7698
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning]](err, warns)
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          2775
        </td>
        <td>
          8559
          -
          8559
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Validation.this.validate$default$3
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          2774
        </td>
        <td>
          8610
          -
          8630
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[org.apache.spark.sql.DataFrame =&gt; org.apache.spark.sql.Column](runnerFunction)
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          2777
        </td>
        <td>
          8559
          -
          8559
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$6
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Validation.this.validate$default$6
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          2773
        </td>
        <td>
          8568
          -
          8580
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Right.apply[Nothing, org.apache.spark.sql.DataFrame](frame)
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          2776
        </td>
        <td>
          8559
          -
          8559
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Validation.this.validate$default$5
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          2779
        </td>
        <td>
          8559
          -
          8656
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Validation.this.validate(x$1, x$2, x$5, x$3, x$6, x$7, x$8, x$4)
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          2778
        </td>
        <td>
          8559
          -
          8559
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$7
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Validation.this.validate$default$7
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          2784
        </td>
        <td>
          9471
          -
          9471
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$6
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          2783
        </td>
        <td>
          9471
          -
          9471
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$5
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          2786
        </td>
        <td>
          9471
          -
          9471
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$8
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$8
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          2780
        </td>
        <td>
          9480
          -
          9492
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, org.apache.spark.sql.DataFrame](frame)
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          2782
        </td>
        <td>
          9471
          -
          9471
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$3
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          2785
        </td>
        <td>
          9471
          -
          9471
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$7
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$7
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          2787
        </td>
        <td>
          9471
          -
          9543
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate(x$1, x$2, x$4, x$3, x$5, x$6, x$7, x$8)
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          2781
        </td>
        <td>
          9522
          -
          9542
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[org.apache.spark.sql.DataFrame =&gt; org.apache.spark.sql.Column](runnerFunction)
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          2793
        </td>
        <td>
          10549
          -
          10689
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Validation.this.validate(x$1, x$2, x$6, x$3, x$7, x$8, x$4, x$5)
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          2792
        </td>
        <td>
          10549
          -
          10549
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$6
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Validation.this.validate$default$6
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          2789
        </td>
        <td>
          10600
          -
          10620
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[org.apache.spark.sql.DataFrame =&gt; org.apache.spark.sql.Column](runnerFunction)
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          2788
        </td>
        <td>
          10558
          -
          10570
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Right.apply[Nothing, org.apache.spark.sql.DataFrame](frame)
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          2791
        </td>
        <td>
          10549
          -
          10549
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Validation.this.validate$default$5
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          2790
        </td>
        <td>
          10549
          -
          10549
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Validation.this.validate$default$3
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          2795
        </td>
        <td>
          11715
          -
          11735
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[org.apache.spark.sql.DataFrame =&gt; org.apache.spark.sql.Column](runnerFunction)
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          2798
        </td>
        <td>
          11664
          -
          11664
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$6
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          2797
        </td>
        <td>
          11664
          -
          11664
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$5
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          2800
        </td>
        <td>
          11664
          -
          11779
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate(x$1, x$2, x$5, x$3, x$6, x$7, x$4, x$8)
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          2794
        </td>
        <td>
          11673
          -
          11685
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, org.apache.spark.sql.DataFrame](frame)
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          2796
        </td>
        <td>
          11664
          -
          11664
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$3
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          2799
        </td>
        <td>
          11664
          -
          11664
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate$default$8
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validate$default$8
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          2802
        </td>
        <td>
          11799
          -
          11799
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply$default$2
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          2801
        </td>
        <td>
          11799
          -
          11799
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply$default$1
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          2804
        </td>
        <td>
          11799
          -
          11805
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply(com.sparkutils.quality.utils.Docs.apply$default$1, com.sparkutils.quality.utils.Docs.apply$default$2, com.sparkutils.quality.utils.Docs.apply$default$3)
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          2803
        </td>
        <td>
          11799
          -
          11799
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply$default$3
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          2807
        </td>
        <td>
          13637
          -
          13675
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.fold
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          schemaOrFrame.fold[org.apache.spark.sql.types.StructType]({
  ((x: org.apache.spark.sql.types.StructType) =&gt; scala.Predef.identity[org.apache.spark.sql.types.StructType](x))
}, ((x$6: org.apache.spark.sql.DataFrame) =&gt; x$6.schema))
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          2806
        </td>
        <td>
          13666
          -
          13674
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.Dataset.schema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$6.schema
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          2805
        </td>
        <td>
          13656
          -
          13664
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.identity
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.identity[org.apache.spark.sql.types.StructType](x)
        </td>
      </tr><tr>
        <td>
          265
        </td>
        <td>
          2808
        </td>
        <td>
          13693
          -
          13716
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.LookupIdFunctions.namesFromSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.namesFromSchema(schema)
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          2809
        </td>
        <td>
          13741
          -
          13767
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2810
        </td>
        <td>
          13779
          -
          13779
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._1
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2819
        </td>
        <td>
          13959
          -
          13959
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._10
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._10
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2813
        </td>
        <td>
          13834
          -
          13834
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._4
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2816
        </td>
        <td>
          13905
          -
          13905
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._7
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._7
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2815
        </td>
        <td>
          13887
          -
          13887
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._6
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2818
        </td>
        <td>
          13933
          -
          13933
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._9
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._9
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2812
        </td>
        <td>
          13814
          -
          13814
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._3
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2811
        </td>
        <td>
          13799
          -
          13799
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._2
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2814
        </td>
        <td>
          13868
          -
          13868
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._5
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          2817
        </td>
        <td>
          13914
          -
          13914
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._8
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._8
        </td>
      </tr><tr>
        <td>
          275
        </td>
        <td>
          2820
        </td>
        <td>
          14162
          -
          14196
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.Growable.++=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.++=(lambdaDocWarnings)
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          2822
        </td>
        <td>
          14219
          -
          14219
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._2
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          2825
        </td>
        <td>
          14262
          -
          14262
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._5
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          2824
        </td>
        <td>
          14243
          -
          14243
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._4
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          2821
        </td>
        <td>
          14207
          -
          14207
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._1
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          2823
        </td>
        <td>
          14236
          -
          14236
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._3
        </td>
      </tr><tr>
        <td>
          279
        </td>
        <td>
          2826
        </td>
        <td>
          14351
          -
          14383
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.Growable.++=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.++=(ruleDocWarnings)
        </td>
      </tr><tr>
        <td>
          281
        </td>
        <td>
          2828
        </td>
        <td>
          14403
          -
          14403
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$9._2
        </td>
      </tr><tr>
        <td>
          281
        </td>
        <td>
          2827
        </td>
        <td>
          14394
          -
          14394
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$9._1
        </td>
      </tr><tr>
        <td>
          284
        </td>
        <td>
          2836
        </td>
        <td>
          14548
          -
          14912
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple5.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple5.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning], String, com.sparkutils.quality.utils.RuleSuiteDocs, scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](unknownLambdaSparkFunctionErrors.++[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]](lambdaArityErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]).++[com.sparkutils.quality.impl.RuleError, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](dfErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]).++(ruleErrors).++(lambdaNameErrors).++(lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$10: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$10._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError]).++(lambdaViewErrors), potentialOverflows.map[com.sparkutils.quality.impl.LambdaPossibleSOE, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaPossibleSOE]](LambdaPossibleSOE)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]).++[com.sparkutils.quality.impl.RuleWarning, Set[com.sparkutils.quality.impl.RuleWarning]](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning]), showOut, com.sparkutils.quality.utils.RuleSuiteDocs.apply(rules, outputExpressions, lambdas), lambadaExpressionLookups.++[com.sparkutils.quality.ExpressionLookup](ruleExpressionLookups))
        </td>
      </tr><tr>
        <td>
          284
        </td>
        <td>
          2829
        </td>
        <td>
          14549
          -
          14716
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownLambdaSparkFunctionErrors.++[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]](lambdaArityErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]).++[com.sparkutils.quality.impl.RuleError, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](dfErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]).++(ruleErrors).++(lambdaNameErrors).++(lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$10: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$10._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError]).++(lambdaViewErrors)
        </td>
      </tr><tr>
        <td>
          285
        </td>
        <td>
          2831
        </td>
        <td>
          14772
          -
          14793
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          285
        </td>
        <td>
          2833
        </td>
        <td>
          14724
          -
          14794
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          potentialOverflows.map[com.sparkutils.quality.impl.LambdaPossibleSOE, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaPossibleSOE]](LambdaPossibleSOE)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]).++[com.sparkutils.quality.impl.RuleWarning, Set[com.sparkutils.quality.impl.RuleWarning]](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning])
        </td>
      </tr><tr>
        <td>
          285
        </td>
        <td>
          2830
        </td>
        <td>
          14746
          -
          14746
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]
        </td>
      </tr><tr>
        <td>
          285
        </td>
        <td>
          2832
        </td>
        <td>
          14768
          -
          14768
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning]
        </td>
      </tr><tr>
        <td>
          286
        </td>
        <td>
          2834
        </td>
        <td>
          14812
          -
          14860
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.RuleSuiteDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.RuleSuiteDocs.apply(rules, outputExpressions, lambdas)
        </td>
      </tr><tr>
        <td>
          286
        </td>
        <td>
          2835
        </td>
        <td>
          14862
          -
          14911
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambadaExpressionLookups.++[com.sparkutils.quality.ExpressionLookup](ruleExpressionLookups)
        </td>
      </tr><tr>
        <td>
          290
        </td>
        <td>
          2840
        </td>
        <td>
          15212
          -
          15387
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.RightProjection.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          schemaOrFrame.right.getOrElse[org.apache.spark.sql.DataFrame]({
  val session: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession.active;
  val empty: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = session.sparkContext.emptyRDD[org.apache.spark.sql.Row]((ClassTag.apply[org.apache.spark.sql.Row](classOf[org.apache.spark.sql.Row]): scala.reflect.ClassTag[org.apache.spark.sql.Row]));
  session.createDataFrame(empty, schema)
})
        </td>
      </tr><tr>
        <td>
          291
        </td>
        <td>
          2837
        </td>
        <td>
          15264
          -
          15283
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.SparkSession.active
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active
        </td>
      </tr><tr>
        <td>
          292
        </td>
        <td>
          2838
        </td>
        <td>
          15302
          -
          15336
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.SparkContext.emptyRDD
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          session.sparkContext.emptyRDD[org.apache.spark.sql.Row]((ClassTag.apply[org.apache.spark.sql.Row](classOf[org.apache.spark.sql.Row]): scala.reflect.ClassTag[org.apache.spark.sql.Row]))
        </td>
      </tr><tr>
        <td>
          293
        </td>
        <td>
          2839
        </td>
        <td>
          15343
          -
          15381
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.SparkSession.createDataFrame
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          session.createDataFrame(empty, schema)
        </td>
      </tr><tr>
        <td>
          296
        </td>
        <td>
          2842
        </td>
        <td>
          15407
          -
          15407
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$11._2
        </td>
      </tr><tr>
        <td>
          296
        </td>
        <td>
          2841
        </td>
        <td>
          15398
          -
          15398
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$11._1
        </td>
      </tr><tr>
        <td>
          307
        </td>
        <td>
          2843
        </td>
        <td>
          15844
          -
          15863
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[String, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](showOut, dfErrors)
        </td>
      </tr><tr>
        <td>
          311
        </td>
        <td>
          2844
        </td>
        <td>
          16042
          -
          16076
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validateRule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validateRule(lambdaLookups, names)(id, exprThunk, outputRule, viewLookup)
        </td>
      </tr><tr>
        <td>
          313
        </td>
        <td>
          2845
        </td>
        <td>
          16096
          -
          16125
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]]
        </td>
      </tr><tr>
        <td>
          314
        </td>
        <td>
          2846
        </td>
        <td>
          16154
          -
          16197
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]]
        </td>
      </tr><tr>
        <td>
          315
        </td>
        <td>
          2847
        </td>
        <td>
          16220
          -
          16259
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup]
        </td>
      </tr><tr>
        <td>
          317
        </td>
        <td>
          2848
        </td>
        <td>
          16284
          -
          16310
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          320
        </td>
        <td>
          2849
        </td>
        <td>
          16421
          -
          16440
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.HasRuleText.rule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expressionRule.rule
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          2851
        </td>
        <td>
          16480
          -
          16512
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, parseddocs))
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          2850
        </td>
        <td>
          16486
          -
          16512
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.WithDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.WithDocs.apply[T](rule, parseddocs)
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          2852
        </td>
        <td>
          16525
          -
          16551
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.nonEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parseddocs.params.nonEmpty
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          2857
        </td>
        <td>
          16521
          -
          16521
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          2856
        </td>
        <td>
          16521
          -
          16521
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          323
        </td>
        <td>
          2855
        </td>
        <td>
          16565
          -
          16607
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.+=(NonLambdaDocParameters.apply(id))
        </td>
      </tr><tr>
        <td>
          323
        </td>
        <td>
          2854
        </td>
        <td>
          16565
          -
          16607
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.+=(NonLambdaDocParameters.apply(id))
        </td>
      </tr><tr>
        <td>
          323
        </td>
        <td>
          2853
        </td>
        <td>
          16581
          -
          16607
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.NonLambdaDocParameters.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NonLambdaDocParameters.apply(id)
        </td>
      </tr><tr>
        <td>
          326
        </td>
        <td>
          2861
        </td>
        <td>
          16404
          -
          16680
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.DocsParser.parse(expressionRule.rule).map[(com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[T])](((parseddocs: com.sparkutils.quality.utils.Docs) =&gt; {
  val res: (com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[T]) = scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, parseddocs));
  if (parseddocs.params.nonEmpty)
    docsWarnings.+=(NonLambdaDocParameters.apply(id))
  else
    ();
  res
})).getOrElse[(com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[T])](scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, Validation.this.emptyDocs)))
        </td>
      </tr><tr>
        <td>
          326
        </td>
        <td>
          2858
        </td>
        <td>
          16669
          -
          16678
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.emptyDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.emptyDocs
        </td>
      </tr><tr>
        <td>
          326
        </td>
        <td>
          2860
        </td>
        <td>
          16648
          -
          16679
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, Validation.this.emptyDocs))
        </td>
      </tr><tr>
        <td>
          326
        </td>
        <td>
          2859
        </td>
        <td>
          16654
          -
          16679
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.WithDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.WithDocs.apply[T](rule, Validation.this.emptyDocs)
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          2887
        </td>
        <td>
          16756
          -
          16756
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          2885
        </td>
        <td>
          16789
          -
          16789
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          2886
        </td>
        <td>
          16772
          -
          17634
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rs.rules.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((r: com.sparkutils.quality.Rule) =&gt; {
  rules = rules.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$12: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.id, r.expression.asInstanceOf[com.sparkutils.quality.HasExpr].expr, false, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((ruleErrors @ _), (exprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](ruleErrors, exprLookup)
  };
  val ruleErrors: Set[com.sparkutils.quality.impl.RuleError] = x$12._1;
  val exprLookup: com.sparkutils.quality.ExpressionLookup = x$12._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup));
  val outputErrors: scala.collection.immutable.Set[_ &lt;: com.sparkutils.quality.impl.RuleError] = if (r.runOnPassProcessor.!=(com.sparkutils.quality.NoOpRunOnPassProcessor.noOp))
    {
      outputExpressions = outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$13: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
        case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](oErrors, oExprLookup)
      };
      val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$13._1;
      val oExprLookup: com.sparkutils.quality.ExpressionLookup = x$13._2;
      exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup));
      oErrors
    }
  else
    scala.Predef.Set.empty[Nothing];
  ruleErrors.++(outputErrors)
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError])
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          2864
        </td>
        <td>
          16815
          -
          16871
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.addDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText])
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          2863
        </td>
        <td>
          16832
          -
          16870
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          2865
        </td>
        <td>
          16806
          -
          16871
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rules.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]))
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          2862
        </td>
        <td>
          16823
          -
          16827
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.Rule.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.id
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          2867
        </td>
        <td>
          16900
          -
          16900
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$12._2
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          2866
        </td>
        <td>
          16888
          -
          16888
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$12._1
        </td>
      </tr><tr>
        <td>
          335
        </td>
        <td>
          2869
        </td>
        <td>
          16997
          -
          17038
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup))
        </td>
      </tr><tr>
        <td>
          335
        </td>
        <td>
          2868
        </td>
        <td>
          17012
          -
          17038
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup)
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          2870
        </td>
        <td>
          17109
          -
          17136
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.NoOpRunOnPassProcessor.noOp
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.NoOpRunOnPassProcessor.noOp
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          2881
        </td>
        <td>
          17138
          -
          17557
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  outputExpressions = outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$13: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](oErrors, oExprLookup)
  };
  val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$13._1;
  val oExprLookup: com.sparkutils.quality.ExpressionLookup = x$13._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup));
  oErrors
}
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          2871
        </td>
        <td>
          17085
          -
          17136
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.!=(com.sparkutils.quality.NoOpRunOnPassProcessor.noOp)
        </td>
      </tr><tr>
        <td>
          339
        </td>
        <td>
          2873
        </td>
        <td>
          17208
          -
          17228
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.Rule.runOnPassProcessor
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor
        </td>
      </tr><tr>
        <td>
          339
        </td>
        <td>
          2876
        </td>
        <td>
          17154
          -
          17297
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]))
        </td>
      </tr><tr>
        <td>
          339
        </td>
        <td>
          2875
        </td>
        <td>
          17175
          -
          17297
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.addDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression])
        </td>
      </tr><tr>
        <td>
          339
        </td>
        <td>
          2872
        </td>
        <td>
          17183
          -
          17206
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.RunOnPassProcessor.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.id
        </td>
      </tr><tr>
        <td>
          339
        </td>
        <td>
          2874
        </td>
        <td>
          17230
          -
          17296
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]
        </td>
      </tr><tr>
        <td>
          341
        </td>
        <td>
          2878
        </td>
        <td>
          17327
          -
          17327
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$13._2
        </td>
      </tr><tr>
        <td>
          341
        </td>
        <td>
          2877
        </td>
        <td>
          17318
          -
          17318
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$13._1
        </td>
      </tr><tr>
        <td>
          342
        </td>
        <td>
          2879
        </td>
        <td>
          17463
          -
          17521
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup)
        </td>
      </tr><tr>
        <td>
          342
        </td>
        <td>
          2880
        </td>
        <td>
          17448
          -
          17521
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup))
        </td>
      </tr><tr>
        <td>
          345
        </td>
        <td>
          2882
        </td>
        <td>
          17577
          -
          17586
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          345
        </td>
        <td>
          2883
        </td>
        <td>
          17577
          -
          17586
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          347
        </td>
        <td>
          2884
        </td>
        <td>
          17598
          -
          17624
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleErrors.++(outputErrors)
        </td>
      </tr><tr>
        <td>
          349
        </td>
        <td>
          2888
        </td>
        <td>
          16729
          -
          17648
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.ruleSets.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((rs: com.sparkutils.quality.RuleSet) =&gt; rs.rules.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((r: com.sparkutils.quality.Rule) =&gt; {
  rules = rules.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$12: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.id, r.expression.asInstanceOf[com.sparkutils.quality.HasExpr].expr, false, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((ruleErrors @ _), (exprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](ruleErrors, exprLookup)
  };
  val ruleErrors: Set[com.sparkutils.quality.impl.RuleError] = x$12._1;
  val exprLookup: com.sparkutils.quality.ExpressionLookup = x$12._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup));
  val outputErrors: scala.collection.immutable.Set[_ &lt;: com.sparkutils.quality.impl.RuleError] = if (r.runOnPassProcessor.!=(com.sparkutils.quality.NoOpRunOnPassProcessor.noOp))
    {
      outputExpressions = outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$13: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
        case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](oErrors, oExprLookup)
      };
      val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$13._1;
      val oExprLookup: com.sparkutils.quality.ExpressionLookup = x$13._2;
      exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup));
      oErrors
    }
  else
    scala.Predef.Set.empty[Nothing];
  ruleErrors.++(outputErrors)
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError])))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]).toSet[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          2891
        </td>
        <td>
          17725
          -
          17745
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, Nothing]().++[com.sparkutils.quality.ExpressionLookup](exprLookups)
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          2890
        </td>
        <td>
          17690
          -
          17704
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](rules)
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          2889
        </td>
        <td>
          17667
          -
          17688
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          2892
        </td>
        <td>
          17654
          -
          17746
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple5.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple5.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](ruleErrors, scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](rules), outputExpressions, scala.Predef.Map.apply[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, Nothing]().++[com.sparkutils.quality.ExpressionLookup](exprLookups))
        </td>
      </tr><tr>
        <td>
          358
        </td>
        <td>
          2893
        </td>
        <td>
          18360
          -
          18407
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]]
        </td>
      </tr><tr>
        <td>
          359
        </td>
        <td>
          2894
        </td>
        <td>
          18431
          -
          18457
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          361
        </td>
        <td>
          2901
        </td>
        <td>
          18514
          -
          18514
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          2897
        </td>
        <td>
          18576
          -
          18600
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaViewError.apply(x$14, f.id)
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          2896
        </td>
        <td>
          18595
          -
          18599
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.LambdaFunction.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.id
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          2899
        </td>
        <td>
          18541
          -
          18601
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$14: String) =&gt; LambdaViewError.apply(x$14, f.id)))
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          2898
        </td>
        <td>
          18541
          -
          18601
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$14: String) =&gt; LambdaViewError.apply(x$14, f.id)))
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          2895
        </td>
        <td>
          18568
          -
          18574
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.HasRuleText.expr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.expr
        </td>
      </tr><tr>
        <td>
          366
        </td>
        <td>
          2900
        </td>
        <td>
          18721
          -
          18747
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          368
        </td>
        <td>
          2902
        </td>
        <td>
          18480
          -
          18767
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.lambdaFunctions.flatMap[com.sparkutils.quality.impl.LambdaViewError, Seq[com.sparkutils.quality.impl.LambdaViewError]](((f: com.sparkutils.quality.LambdaFunction) =&gt; try {
  Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$14: String) =&gt; LambdaViewError.apply(x$14, f.id)))
} catch {
  case (_: Throwable) =&gt; scala.Predef.Set.empty[com.sparkutils.quality.impl.LambdaViewError]
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaViewError]).toSet[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          2903
        </td>
        <td>
          18778
          -
          18778
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$16._1
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          2904
        </td>
        <td>
          18801
          -
          18801
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$16._2
        </td>
      </tr><tr>
        <td>
          402
        </td>
        <td>
          2906
        </td>
        <td>
          19805
          -
          19818
        </td>
        <td>
          Select
        </td>
        <td>
          scala.util.Either.LeftProjection.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$17._2.left.get
        </td>
      </tr><tr>
        <td>
          402
        </td>
        <td>
          2909
        </td>
        <td>
          19799
          -
          19825
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$17: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$17._2.left.get))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]).toMap[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])
        </td>
      </tr><tr>
        <td>
          402
        </td>
        <td>
          2908
        </td>
        <td>
          19820
          -
          19820
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          402
        </td>
        <td>
          2905
        </td>
        <td>
          19778
          -
          19782
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          402
        </td>
        <td>
          2907
        </td>
        <td>
          19804
          -
          19804
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          402
        </td>
        <td>
          2910
        </td>
        <td>
          19743
          -
          19826
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.mapValues
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaLeftExpressions.groupBy[String](((p: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; p._1)).mapValues[scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]](((e: Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])]) =&gt; e.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$17: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$17._2.left.get))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]).toMap[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])))
        </td>
      </tr><tr>
        <td>
          404
        </td>
        <td>
          2912
        </td>
        <td>
          19852
          -
          19852
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._2
        </td>
      </tr><tr>
        <td>
          404
        </td>
        <td>
          2911
        </td>
        <td>
          19837
          -
          19837
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._1
        </td>
      </tr><tr>
        <td>
          404
        </td>
        <td>
          2913
        </td>
        <td>
          19872
          -
          19872
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._3
        </td>
      </tr><tr>
        <td>
          417
        </td>
        <td>
          2921
        </td>
        <td>
          20665
          -
          20665
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Iterable.canBuildFrom[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]
        </td>
      </tr><tr>
        <td>
          417
        </td>
        <td>
          2915
        </td>
        <td>
          20686
          -
          20703
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)
        </td>
      </tr><tr>
        <td>
          417
        </td>
        <td>
          2918
        </td>
        <td>
          20686
          -
          20767
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.ExpressionLookup](com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))
        </td>
      </tr><tr>
        <td>
          417
        </td>
        <td>
          2917
        </td>
        <td>
          20707
          -
          20767
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.VariablesLookup.fieldsFromExpression
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups)
        </td>
      </tr><tr>
        <td>
          417
        </td>
        <td>
          2920
        </td>
        <td>
          20672
          -
          20768
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          m.map[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup), scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](((pair: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.ExpressionLookup](com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))))(immutable.this.Map.canBuildFrom[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup])
        </td>
      </tr><tr>
        <td>
          417
        </td>
        <td>
          2923
        </td>
        <td>
          20627
          -
          20775
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaNameToExpressions.values.flatMap[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup), Iterable[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]](((m: scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) =&gt; m.map[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup), scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](((pair: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.ExpressionLookup](com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))))(immutable.this.Map.canBuildFrom[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup])))(collection.this.Iterable.canBuildFrom[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]).toMap[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup](scala.Predef.$conforms[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)])
        </td>
      </tr><tr>
        <td>
          417
        </td>
        <td>
          2914
        </td>
        <td>
          20695
          -
          20702
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pair._1
        </td>
      </tr><tr>
        <td>
          417
        </td>
        <td>
          2916
        </td>
        <td>
          20744
          -
          20751
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pair._2
        </td>
      </tr><tr>
        <td>
          417
        </td>
        <td>
          2919
        </td>
        <td>
          20677
          -
          20677
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Map.canBuildFrom[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup]
        </td>
      </tr><tr>
        <td>
          417
        </td>
        <td>
          2922
        </td>
        <td>
          20770
          -
          20770
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]
        </td>
      </tr><tr>
        <td>
          419
        </td>
        <td>
          2927
        </td>
        <td>
          20861
          -
          20925
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.map[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((name: String) =&gt; LambdaSparkFunctionNameError.apply(name, p._1)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError])
        </td>
      </tr><tr>
        <td>
          419
        </td>
        <td>
          2926
        </td>
        <td>
          20869
          -
          20869
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          419
        </td>
        <td>
          2928
        </td>
        <td>
          20855
          -
          20855
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          420
        </td>
        <td>
          2924
        </td>
        <td>
          20919
          -
          20923
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          420
        </td>
        <td>
          2929
        </td>
        <td>
          20820
          -
          20932
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownLambdaSparkFunctions.flatMap[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((p: (com.sparkutils.quality.Id, Set[String])) =&gt; p._2.map[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((name: String) =&gt; LambdaSparkFunctionNameError.apply(name, p._1)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError])))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]).toSet[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          420
        </td>
        <td>
          2925
        </td>
        <td>
          20884
          -
          20924
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaSparkFunctionNameError.apply(name, p._1)
        </td>
      </tr><tr>
        <td>
          422
        </td>
        <td>
          2930
        </td>
        <td>
          20998
          -
          21011
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.size.&gt;(1)
        </td>
      </tr><tr>
        <td>
          422
        </td>
        <td>
          2944
        </td>
        <td>
          21021
          -
          21021
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]
        </td>
      </tr><tr>
        <td>
          424
        </td>
        <td>
          2931
        </td>
        <td>
          21056
          -
          21064
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pairs._2
        </td>
      </tr><tr>
        <td>
          426
        </td>
        <td>
          2933
        </td>
        <td>
          21087
          -
          21122
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableLike.groupBy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          map.groupBy[Int](((x$19: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$19._2.children.size.-(1)))
        </td>
      </tr><tr>
        <td>
          426
        </td>
        <td>
          2932
        </td>
        <td>
          21099
          -
          21121
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.-
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$19._2.children.size.-(1)
        </td>
      </tr><tr>
        <td>
          427
        </td>
        <td>
          2936
        </td>
        <td>
          21174
          -
          21226
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.collectFirst
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          counts.collectFirst[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] with Serializable {
    def &lt;init&gt;(): &lt;$anon: ((Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]), B1 &gt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
      case (f @ _) if f._2.size.&gt;(1) =&gt; f
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): Boolean = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
      case (f @ _) if f._2.size.&gt;(1) =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]))
        </td>
      </tr><tr>
        <td>
          427
        </td>
        <td>
          2935
        </td>
        <td>
          21194
          -
          21194
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          427
        </td>
        <td>
          2934
        </td>
        <td>
          21206
          -
          21219
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.size.&gt;(1)
        </td>
      </tr><tr>
        <td>
          428
        </td>
        <td>
          2942
        </td>
        <td>
          21235
          -
          21362
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet)))
        </td>
      </tr><tr>
        <td>
          428
        </td>
        <td>
          2943
        </td>
        <td>
          21235
          -
          21362
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet))))
        </td>
      </tr><tr>
        <td>
          429
        </td>
        <td>
          2939
        </td>
        <td>
          21334
          -
          21338
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._1
        </td>
      </tr><tr>
        <td>
          429
        </td>
        <td>
          2938
        </td>
        <td>
          21323
          -
          21332
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.size
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.size
        </td>
      </tr><tr>
        <td>
          429
        </td>
        <td>
          2941
        </td>
        <td>
          21266
          -
          21352
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet)
        </td>
      </tr><tr>
        <td>
          429
        </td>
        <td>
          2940
        </td>
        <td>
          21340
          -
          21351
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.immutable.MapLike.keySet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.keySet
        </td>
      </tr><tr>
        <td>
          429
        </td>
        <td>
          2937
        </td>
        <td>
          21313
          -
          21321
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pairs._1
        </td>
      </tr><tr>
        <td>
          431
        </td>
        <td>
          2945
        </td>
        <td>
          20962
          -
          21374
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaNameToExpressions.filter(((p: (String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; p._2.size.&gt;(1))).flatMap[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]](((pairs: (String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; {
  val map: scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression] = pairs._2;
  val counts: scala.collection.immutable.Map[Int,scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]] = map.groupBy[Int](((x$19: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$19._2.children.size.-(1)));
  val moreThan1: Option[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] = counts.collectFirst[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](({
    @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] with Serializable {
      def &lt;init&gt;(): &lt;$anon: ((Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])&gt; = {
        $anonfun.super.&lt;init&gt;();
        ()
      };
      final override def applyOrElse[A1 &lt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]), B1 &gt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
        case (f @ _) if f._2.size.&gt;(1) =&gt; f
        case (defaultCase$ @ _) =&gt; default.apply(x1)
      };
      final def isDefinedAt(x1: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): Boolean = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
        case (f @ _) if f._2.size.&gt;(1) =&gt; true
        case (defaultCase$ @ _) =&gt; false
      }
    };
    new $anonfun()
  }: PartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]));
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet))))
}))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]).toSet[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]
        </td>
      </tr><tr>
        <td>
          435
        </td>
        <td>
          2960
        </td>
        <td>
          21530
          -
          21530
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          436
        </td>
        <td>
          2959
        </td>
        <td>
          21545
          -
          21765
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)) =&gt; {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$20: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) = (pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) @unchecked) match {
    case (_1: com.sparkutils.quality.Id, _2: com.sparkutils.quality.VariablesLookup.Identifiers)(com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)((id @ _), (identifiers @ _)) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers](id, identifiers)
  };
  val id: com.sparkutils.quality.Id = x$20._1;
  val identifiers: com.sparkutils.quality.VariablesLookup.Identifiers = x$20._2;
  if (identifiers.diff(names).isEmpty)
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$21: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$21, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
}))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]])
        </td>
      </tr><tr>
        <td>
          436
        </td>
        <td>
          2958
        </td>
        <td>
          21558
          -
          21558
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          437
        </td>
        <td>
          2947
        </td>
        <td>
          21587
          -
          21587
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$20._2
        </td>
      </tr><tr>
        <td>
          437
        </td>
        <td>
          2946
        </td>
        <td>
          21583
          -
          21583
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$20._1
        </td>
      </tr><tr>
        <td>
          438
        </td>
        <td>
          2948
        </td>
        <td>
          21621
          -
          21652
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SetLike.isEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.diff(names).isEmpty
        </td>
      </tr><tr>
        <td>
          439
        </td>
        <td>
          2951
        </td>
        <td>
          21666
          -
          21670
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          439
        </td>
        <td>
          2950
        </td>
        <td>
          21666
          -
          21670
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          439
        </td>
        <td>
          2949
        </td>
        <td>
          21666
          -
          21670
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          441
        </td>
        <td>
          2954
        </td>
        <td>
          21703
          -
          21754
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$21: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$21, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])
        </td>
      </tr><tr>
        <td>
          441
        </td>
        <td>
          2957
        </td>
        <td>
          21698
          -
          21755
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$21: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$21, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
        </td>
      </tr><tr>
        <td>
          441
        </td>
        <td>
          2953
        </td>
        <td>
          21730
          -
          21730
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError]
        </td>
      </tr><tr>
        <td>
          441
        </td>
        <td>
          2956
        </td>
        <td>
          21698
          -
          21755
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$21: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$21, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
        </td>
      </tr><tr>
        <td>
          441
        </td>
        <td>
          2952
        </td>
        <td>
          21731
          -
          21753
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaNameError.apply(x$21, id)
        </td>
      </tr><tr>
        <td>
          441
        </td>
        <td>
          2955
        </td>
        <td>
          21698
          -
          21755
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$21: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$21, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError]))
        </td>
      </tr><tr>
        <td>
          443
        </td>
        <td>
          2962
        </td>
        <td>
          21508
          -
          21787
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaLookups.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((p: (String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.VariablesLookup.Identifiers])) =&gt; p._2.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)) =&gt; {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$20: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) = (pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) @unchecked) match {
    case (_1: com.sparkutils.quality.Id, _2: com.sparkutils.quality.VariablesLookup.Identifiers)(com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)((id @ _), (identifiers @ _)) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers](id, identifiers)
  };
  val id: com.sparkutils.quality.Id = x$20._1;
  val identifiers: com.sparkutils.quality.VariablesLookup.Identifiers = x$20._2;
  if (identifiers.diff(names).isEmpty)
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$21: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$21, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
}))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]])))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]).flatten[com.sparkutils.quality.impl.LambdaNameError](scala.Predef.$conforms[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]).toSet[com.sparkutils.quality.impl.LambdaNameError]
        </td>
      </tr><tr>
        <td>
          443
        </td>
        <td>
          2961
        </td>
        <td>
          21774
          -
          21774
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          444
        </td>
        <td>
          2963
        </td>
        <td>
          21925
          -
          21941
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]](lambdas)
        </td>
      </tr><tr>
        <td>
          444
        </td>
        <td>
          2966
        </td>
        <td>
          21792
          -
          21991
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, (Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError])](scala.Tuple10.apply[Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError]](lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]](lambdas), scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), exprLookups, viewErrors))
        </td>
      </tr><tr>
        <td>
          444
        </td>
        <td>
          2965
        </td>
        <td>
          21798
          -
          21990
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple10.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple10.apply[Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError]](lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]](lambdas), scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), exprLookups, viewErrors)
        </td>
      </tr><tr>
        <td>
          444
        </td>
        <td>
          2964
        </td>
        <td>
          21943
          -
          21964
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          447
        </td>
        <td>
          2973
        </td>
        <td>
          22128
          -
          22128
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          448
        </td>
        <td>
          2972
        </td>
        <td>
          22164
          -
          22274
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.trees.TreeNode.collect
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          s.plan.collect[T](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T] with Serializable {
    def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =&gt; T&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, B1 &gt;: T](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
      case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; f.apply(rel.tableName)
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
      case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T]))
        </td>
      </tr><tr>
        <td>
          448
        </td>
        <td>
          2971
        </td>
        <td>
          22178
          -
          22178
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          449
        </td>
        <td>
          2968
        </td>
        <td>
          22218
          -
          22240
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lookup.apply(rel.tableName).unary_!
        </td>
      </tr><tr>
        <td>
          449
        </td>
        <td>
          2967
        </td>
        <td>
          22226
          -
          22239
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedRelation.tableName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rel.tableName
        </td>
      </tr><tr>
        <td>
          450
        </td>
        <td>
          2969
        </td>
        <td>
          22254
          -
          22267
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedRelation.tableName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rel.tableName
        </td>
      </tr><tr>
        <td>
          450
        </td>
        <td>
          2970
        </td>
        <td>
          22252
          -
          22268
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Function1.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.apply(rel.tableName)
        </td>
      </tr><tr>
        <td>
          452
        </td>
        <td>
          2975
        </td>
        <td>
          22109
          -
          22293
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expression.collect[Seq[T]](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.expressions.Expression,Seq[T]] with Serializable {
    def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.expressions.Expression =&gt; Seq[T]&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.expressions.Expression, B1 &gt;: Seq[T]](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.expressions.Expression]: org.apache.spark.sql.catalyst.expressions.Expression): org.apache.spark.sql.catalyst.expressions.Expression @unchecked) match {
      case (s @ (_: org.apache.spark.sql.catalyst.expressions.SubqueryExpression)) =&gt; s.plan.collect[T](({
        @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T] with Serializable {
          def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =&gt; T&gt; = {
            $anonfun.super.&lt;init&gt;();
            ()
          };
          final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, B1 &gt;: T](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
            case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; f.apply(rel.tableName)
            case (defaultCase$ @ _) =&gt; default.apply(x1)
          };
          final def isDefinedAt(x1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
            case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; true
            case (defaultCase$ @ _) =&gt; false
          }
        };
        new $anonfun()
      }: PartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T]))
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: org.apache.spark.sql.catalyst.expressions.Expression): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.expressions.Expression]: org.apache.spark.sql.catalyst.expressions.Expression): org.apache.spark.sql.catalyst.expressions.Expression @unchecked) match {
      case (s @ (_: org.apache.spark.sql.catalyst.expressions.SubqueryExpression)) =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[org.apache.spark.sql.catalyst.expressions.Expression,Seq[T]])).flatten[T](scala.Predef.$conforms[Seq[T]]).toSet[T]
        </td>
      </tr><tr>
        <td>
          452
        </td>
        <td>
          2974
        </td>
        <td>
          22280
          -
          22280
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[Seq[T]]
        </td>
      </tr><tr>
        <td>
          455
        </td>
        <td>
          3007
        </td>
        <td>
          22534
          -
          23377
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val expr: org.apache.spark.sql.catalyst.expressions.Expression = exprThunk;
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$22: (com.sparkutils.quality.ExpressionLookup, com.sparkutils.quality.VariablesLookup.Identifiers, com.sparkutils.quality.VariablesLookup.Identifiers) = (com.sparkutils.quality.VariablesLookup.fieldsFromExpression(expr, lambdaLookups): com.sparkutils.quality.ExpressionLookup @unchecked) match {
    case (exl @ (attributesUsed: com.sparkutils.quality.VariablesLookup.Identifiers, unknownSparkFunctions: com.sparkutils.quality.VariablesLookup.Identifiers, lambdas: Set[com.sparkutils.quality.Id], sparkFunctions: Set[String])com.sparkutils.quality.ExpressionLookup((exprFields @ _), (unknownSparkFunctions @ _), _, _)) =&gt; scala.Tuple3.apply[com.sparkutils.quality.ExpressionLookup, com.sparkutils.quality.VariablesLookup.Identifiers, com.sparkutils.quality.VariablesLookup.Identifiers](exl, exprFields, unknownSparkFunctions)
  };
  val exl: com.sparkutils.quality.ExpressionLookup = x$22._1;
  val exprFields: com.sparkutils.quality.VariablesLookup.Identifiers = x$22._2;
  val unknownSparkFunctions: com.sparkutils.quality.VariablesLookup.Identifiers = x$22._3;
  val rules: scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError] = exprFields.flatMap[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((field: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (names.contains(field))
  scala.this.Option.option2Iterable[Nothing](scala.None)
else
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
    RuleNameError.apply(field, id)
  else
    OutputRuleNameError.apply(field, id)))))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]).toSet[com.sparkutils.quality.impl.RuleError];
  val viewErrors: Set[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable] = Validation.this.subQueryErrors[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable](viewLookup, exprThunk, if (outputRule)
    ((x$23: String) =&gt; OutputRuleViewError.apply(x$23, id))
  else
    ((x$24: String) =&gt; RuleViewError.apply(x$24, id)));
  val unknown: scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable] = unknownSparkFunctions.map[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((name: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (outputRule.unary_!)
    SparkFunctionNameError.apply(name, id)
  else
    OuputSparkFunctionNameError.apply(name, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]);
  scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](rules.++(unknown).++(viewErrors), exl)
}
        </td>
      </tr><tr>
        <td>
          457
        </td>
        <td>
          2978
        </td>
        <td>
          22600
          -
          22600
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$22._3
        </td>
      </tr><tr>
        <td>
          457
        </td>
        <td>
          2977
        </td>
        <td>
          22588
          -
          22588
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$22._2
        </td>
      </tr><tr>
        <td>
          457
        </td>
        <td>
          2976
        </td>
        <td>
          22565
          -
          22565
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$22._1
        </td>
      </tr><tr>
        <td>
          458
        </td>
        <td>
          2991
        </td>
        <td>
          22725
          -
          22725
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]
        </td>
      </tr><tr>
        <td>
          460
        </td>
        <td>
          2979
        </td>
        <td>
          22758
          -
          22779
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          names.contains(field)
        </td>
      </tr><tr>
        <td>
          461
        </td>
        <td>
          2981
        </td>
        <td>
          22793
          -
          22797
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          461
        </td>
        <td>
          2980
        </td>
        <td>
          22793
          -
          22797
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          461
        </td>
        <td>
          2982
        </td>
        <td>
          22793
          -
          22797
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          463
        </td>
        <td>
          2990
        </td>
        <td>
          22825
          -
          22982
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id)))
        </td>
      </tr><tr>
        <td>
          463
        </td>
        <td>
          2989
        </td>
        <td>
          22825
          -
          22982
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id)))
        </td>
      </tr><tr>
        <td>
          463
        </td>
        <td>
          2988
        </td>
        <td>
          22825
          -
          22982
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id))
        </td>
      </tr><tr>
        <td>
          464
        </td>
        <td>
          2983
        </td>
        <td>
          22849
          -
          22860
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          465
        </td>
        <td>
          2984
        </td>
        <td>
          22878
          -
          22902
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          465
        </td>
        <td>
          2985
        </td>
        <td>
          22878
          -
          22902
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          467
        </td>
        <td>
          2987
        </td>
        <td>
          22938
          -
          22968
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          467
        </td>
        <td>
          2986
        </td>
        <td>
          22938
          -
          22968
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          469
        </td>
        <td>
          2992
        </td>
        <td>
          22707
          -
          23007
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprFields.flatMap[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((field: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (names.contains(field))
  scala.this.Option.option2Iterable[Nothing](scala.None)
else
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
    RuleNameError.apply(field, id)
  else
    OutputRuleNameError.apply(field, id)))))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]).toSet[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          471
        </td>
        <td>
          2993
        </td>
        <td>
          23086
          -
          23112
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleViewError.apply(x$23, id)
        </td>
      </tr><tr>
        <td>
          471
        </td>
        <td>
          2996
        </td>
        <td>
          23118
          -
          23138
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((x$24: String) =&gt; RuleViewError.apply(x$24, id))
        </td>
      </tr><tr>
        <td>
          471
        </td>
        <td>
          2995
        </td>
        <td>
          23118
          -
          23138
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleViewError.apply(x$24, id)
        </td>
      </tr><tr>
        <td>
          471
        </td>
        <td>
          2994
        </td>
        <td>
          23086
          -
          23112
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((x$23: String) =&gt; OutputRuleViewError.apply(x$23, id))
        </td>
      </tr><tr>
        <td>
          471
        </td>
        <td>
          2997
        </td>
        <td>
          23032
          -
          23139
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable](viewLookup, exprThunk, if (outputRule)
  ((x$23: String) =&gt; OutputRuleViewError.apply(x$23, id))
else
  ((x$24: String) =&gt; RuleViewError.apply(x$24, id)))
        </td>
      </tr><tr>
        <td>
          473
        </td>
        <td>
          3004
        </td>
        <td>
          23161
          -
          23332
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownSparkFunctions.map[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((name: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (outputRule.unary_!)
  SparkFunctionNameError.apply(name, id)
else
  OuputSparkFunctionNameError.apply(name, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable])
        </td>
      </tr><tr>
        <td>
          473
        </td>
        <td>
          3003
        </td>
        <td>
          23186
          -
          23186
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]
        </td>
      </tr><tr>
        <td>
          474
        </td>
        <td>
          2998
        </td>
        <td>
          23208
          -
          23219
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          475
        </td>
        <td>
          2999
        </td>
        <td>
          23231
          -
          23263
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.SparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          SparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          475
        </td>
        <td>
          3000
        </td>
        <td>
          23231
          -
          23263
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.SparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          SparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          477
        </td>
        <td>
          3002
        </td>
        <td>
          23287
          -
          23324
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OuputSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OuputSparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          477
        </td>
        <td>
          3001
        </td>
        <td>
          23287
          -
          23324
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OuputSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OuputSparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          3005
        </td>
        <td>
          23341
          -
          23371
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rules.++(unknown).++(viewErrors)
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          3006
        </td>
        <td>
          23340
          -
          23377
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](rules.++(unknown).++(viewErrors), exl)
        </td>
      </tr><tr>
        <td>
          482
        </td>
        <td>
          3021
        </td>
        <td>
          23419
          -
          23585
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleError](if (outputRule.unary_!)
  RuleSyntaxError.apply(id, e.getMessage())
else
  OutputRuleSyntaxError.apply(id, e.getMessage())), com.sparkutils.quality.ExpressionLookup.apply(com.sparkutils.quality.ExpressionLookup.apply$default$1, com.sparkutils.quality.ExpressionLookup.apply$default$2, com.sparkutils.quality.ExpressionLookup.apply$default$3, com.sparkutils.quality.ExpressionLookup.apply$default$4))
        </td>
      </tr><tr>
        <td>
          482
        </td>
        <td>
          3015
        </td>
        <td>
          23420
          -
          23564
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleError](if (outputRule.unary_!)
  RuleSyntaxError.apply(id, e.getMessage())
else
  OutputRuleSyntaxError.apply(id, e.getMessage()))
        </td>
      </tr><tr>
        <td>
          483
        </td>
        <td>
          3008
        </td>
        <td>
          23437
          -
          23448
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          484
        </td>
        <td>
          3011
        </td>
        <td>
          23460
          -
          23493
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          484
        </td>
        <td>
          3010
        </td>
        <td>
          23460
          -
          23493
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          484
        </td>
        <td>
          3009
        </td>
        <td>
          23480
          -
          23492
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Throwable.getMessage
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.getMessage()
        </td>
      </tr><tr>
        <td>
          486
        </td>
        <td>
          3013
        </td>
        <td>
          23517
          -
          23556
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          486
        </td>
        <td>
          3012
        </td>
        <td>
          23543
          -
          23555
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Throwable.getMessage
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.getMessage()
        </td>
      </tr><tr>
        <td>
          486
        </td>
        <td>
          3014
        </td>
        <td>
          23517
          -
          23556
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          487
        </td>
        <td>
          3017
        </td>
        <td>
          23566
          -
          23566
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$2
        </td>
      </tr><tr>
        <td>
          487
        </td>
        <td>
          3020
        </td>
        <td>
          23566
          -
          23584
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply(com.sparkutils.quality.ExpressionLookup.apply$default$1, com.sparkutils.quality.ExpressionLookup.apply$default$2, com.sparkutils.quality.ExpressionLookup.apply$default$3, com.sparkutils.quality.ExpressionLookup.apply$default$4)
        </td>
      </tr><tr>
        <td>
          487
        </td>
        <td>
          3016
        </td>
        <td>
          23566
          -
          23566
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$1
        </td>
      </tr><tr>
        <td>
          487
        </td>
        <td>
          3019
        </td>
        <td>
          23566
          -
          23566
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$4
        </td>
      </tr><tr>
        <td>
          487
        </td>
        <td>
          3018
        </td>
        <td>
          23566
          -
          23566
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$3
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>