<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/impl/util/VariablesLookup.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality.impl.util
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality.Id
</span>4 <span style=''>import com.sparkutils.quality.impl.util
</span>5 <span style=''>import com.sparkutils.shim.expressions.Names.toName
</span>6 <span style=''>import com.sparkutils.shim.expressions.UnresolvedFunction4
</span>7 <span style=''>import org.apache.spark.sql.SparkSession
</span>8 <span style=''>import org.apache.spark.sql.catalyst.analysis.{UnresolvedAttribute, UnresolvedFunction}
</span>9 <span style=''>import org.apache.spark.sql.catalyst.expressions.{Expression, LeafExpression, UnresolvedNamedLambdaVariable, LambdaFunction =&gt; SparkLambdaFunction}
</span>10 <span style=''>import org.slf4j.LoggerFactory
</span>11 <span style=''>
</span>12 <span style=''>// Used to pull in |+| to deep merge the maps as SemiGroups - https://typelevel.org/cats/typeclasses/semigroup.html#example-usage-merging-maps
</span>13 <span style=''>import cats.implicits._
</span>14 <span style=''>
</span>15 <span style=''>/**
</span>16 <span style=''> * For a given expression it breaks down information useful for documentation and validation for a non-resolved expression.
</span>17 <span style=''> *
</span>18 <span style=''> * All names may include optional scope (e.g. database)
</span>19 <span style=''> *
</span>20 <span style=''> * @param attributesUsed Which attributes are used in the expression
</span>21 <span style=''> * @param unknownSparkFunctions Which functions are used but are neither known lambdas nor registered spark expressions
</span>22 <span style=''> * @param lambdas Which known lambdas are used
</span>23 <span style=''> * @param sparkFunctions Which known spark functions are used
</span>24 <span style=''> */
</span>25 <span style=''>case class ExpressionLookup(attributesUsed: VariablesLookup.Identifiers = Set.empty, unknownSparkFunctions: VariablesLookup.Identifiers = Set.empty, lambdas: Set[Id] = Set.empty, sparkFunctions: Set[String] = Set.empty)
</span>26 <span style=''>
</span>27 <span style=''>/**
</span>28 <span style=''> * Provides a variable lookup function, after using the sql parser it will return all the fields used in an expression,
</span>29 <span style=''> * allowing sanity checks on rules to use only expected fields but also to attribute how much a rule does - does it check
</span>30 <span style=''> * just one field or use 20 of them.
</span>31 <span style=''> * It is also used to identify fields which are note provided by a lambda i.e. the ones bound at use.
</span>32 <span style=''> * Note: this cannot process nested lambdas in a simple expression unless the lambdas are also passed in, so process lambdas first.
</span>33 <span style=''> */
</span>34 <span style=''>object VariablesLookup {
</span>35 <span style=''>
</span>36 <span style=''>  val logger = </span><span style='background: #AEF1AE'>LoggerFactory.getLogger(&quot;VariablesLookup&quot;)</span><span style=''>
</span>37 <span style=''>
</span>38 <span style=''>  type Identifier = String
</span>39 <span style=''>  type Identifiers = Set[Identifier]
</span>40 <span style=''>  type ProcessedLambdas = Map[String, Map[Id, Identifiers]]
</span>41 <span style=''>  type PossibleOverflowIds = Set[Id]
</span>42 <span style=''>  type UnknownSparkFunctions = Map[Id, Set[String]]
</span>43 <span style=''>
</span>44 <span style=''>  def processLambdas(m: Map[String, Map[Id,Expression]]): (ProcessedLambdas, PossibleOverflowIds, UnknownSparkFunctions) =
</span>45 <span style=''>    </span><span style='background: #AEF1AE'>m.foldLeft((Map.empty[String, Map[Id, Identifiers]], Set.empty[Id], Map.empty[Id, Set[String]])){ (acc, p) =&gt;
</span>46 <span style=''></span><span style='background: #AEF1AE'>      if (acc._1.contains(p._1))
</span>47 <span style=''></span><span style='background: #AEF1AE'>        acc
</span>48 <span style=''></span><span style='background: #AEF1AE'>      else {
</span>49 <span style=''></span><span style='background: #AEF1AE'>        val (macc, s, us) = acc
</span>50 <span style=''></span><span style='background: #AEF1AE'>        val (res, ress, resus) = fieldsFromLambda( p._1, p._2, macc, m)
</span>51 <span style=''></span><span style='background: #AEF1AE'>        (macc |+| res, ress |+| s, resus |+| us)
</span>52 <span style=''></span><span style='background: #AEF1AE'>      }
</span>53 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>54 <span style=''>
</span>55 <span style=''>  def fieldsFromLambda(name: String, exprMap: Map[Id, Expression], m: ProcessedLambdas, lambdaExpressions: Map[String, Map[Id, Expression]]): (ProcessedLambdas, PossibleOverflowIds, UnknownSparkFunctions) = {
</span>56 <span style=''>    // allow communication across tree depths
</span>57 <span style=''>    val evaluatedLambdas = </span><span style='background: #AEF1AE'>scala.collection.mutable.Map.empty[String, Map[Id, Identifiers]] ++ m</span><span style=''>
</span>58 <span style=''>    val overflowIds = </span><span style='background: #AEF1AE'>scala.collection.mutable.Set.empty[Id]</span><span style=''>
</span>59 <span style=''>    val unknownSparkFunctionIds = </span><span style='background: #AEF1AE'>scala.collection.mutable.Map.empty[Id, Set[String]]</span><span style=''>
</span>60 <span style=''>
</span>61 <span style=''>    def children(res: Map[Id, Identifiers], children: Seq[(Id, Expression)], parent: UnresolvedFunction): Map[Id, Identifiers] =
</span>62 <span style=''>      </span><span style='background: #AEF1AE'>children.foldLeft(res){
</span>63 <span style=''></span><span style='background: #AEF1AE'>        (curRes, exp) =&gt;
</span>64 <span style=''></span><span style='background: #AEF1AE'>          curRes |+| accumulate(curRes, exp, parent)
</span>65 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>66 <span style=''>
</span>67 <span style=''>    def processFields(args: Set[String], expr: Expression, id: Id, parent: UnresolvedFunction, ids: Identifiers = Set.empty): Identifiers = {
</span>68 <span style=''>      def fieldChildren(res: Identifiers, children: Seq[Expression]): Identifiers =
</span>69 <span style=''>        </span><span style='background: #AEF1AE'>children.foldLeft(res) {
</span>70 <span style=''></span><span style='background: #AEF1AE'>          (curRes, exp) =&gt;
</span>71 <span style=''></span><span style='background: #AEF1AE'>            faccumulate(curRes, exp)
</span>72 <span style=''></span><span style='background: #AEF1AE'>        }</span><span style=''>
</span>73 <span style=''>
</span>74 <span style=''>      def faccumulate(identifiers: Identifiers, expression: Expression): Identifiers =
</span>75 <span style=''>        expression match {
</span>76 <span style=''>          case a : UnresolvedNamedLambdaVariable =&gt;
</span>77 <span style=''>            val full = </span><span style='background: #AEF1AE'>toName(a)</span><span style=''>
</span>78 <span style=''>            if (</span><span style='background: #AEF1AE'>!args.contains(full)</span><span style=''>) // don't accept args, so we should only be left with outer scopes, which may be from a nested..
</span>79 <span style=''>              </span><span style='background: #AEF1AE'>identifiers + full</span><span style=''>
</span>80 <span style=''>            else
</span>81 <span style=''>              </span><span style='background: #AEF1AE'>identifiers</span><span style=''>
</span>82 <span style=''>
</span>83 <span style=''>          case f @ UnresolvedFunction4(_, argumentExpressions, _, _) =&gt; // nested....
</span>84 <span style=''>            val name = </span><span style='background: #AEF1AE'>toName(f)</span><span style=''>
</span>85 <span style=''>            val nids =
</span>86 <span style=''>              if (</span><span style='background: #AEF1AE'>evaluatedLambdas.contains(name)</span><span style=''>)
</span>87 <span style=''>                </span><span style='background: #AEF1AE'>identifiers</span><span style=''>
</span>88 <span style=''>              else {
</span>89 <span style=''>                </span><span style='background: #AEF1AE'>if (lambdaExpressions.contains(name)) {
</span>90 <span style=''></span><span style='background: #AEF1AE'>                  // we haven't yet evaluated it, pass back up to the top and recurse down
</span>91 <span style=''></span><span style='background: #AEF1AE'>                  if ((parent ne null) &amp;&amp; name == toName(parent)) {
</span>92 <span style=''></span><span style='background: #AEF1AE'>                    // special case for recursion on the same identifier - are we calling the same id?
</span>93 <span style=''></span><span style='background: #AEF1AE'>                    // get the exact arity matching
</span>94 <span style=''></span><span style='background: #AEF1AE'>                    lambdaExpressions(name).find(_._2.children.size == argumentExpressions.size).fold{
</span>95 <span style=''></span><span style='background: #AEF1AE'>                      overflowIds += id
</span>96 <span style=''></span><span style='background: #AEF1AE'>                      logger.warn(s&quot;Function ${name} calls itself, this may StackOverflowError on evaluation&quot;)
</span>97 <span style=''></span><span style='background: #AEF1AE'>                    }{
</span>98 <span style=''></span><span style='background: #AEF1AE'>                      i =&gt;
</span>99 <span style=''></span><span style='background: #AEF1AE'>                        val r = children(Map.empty, Seq(i), f)
</span>100 <span style=''></span><span style='background: #AEF1AE'>                        evaluatedLambdas(name) = r
</span>101 <span style=''></span><span style='background: #AEF1AE'>                    }
</span>102 <span style=''></span><span style='background: #AEF1AE'>                  } else {
</span>103 <span style=''></span><span style='background: #AEF1AE'>                    val r = children(Map.empty, lambdaExpressions(name).toSeq, f)
</span>104 <span style=''></span><span style='background: #AEF1AE'>                    evaluatedLambdas(name) = r
</span>105 <span style=''></span><span style='background: #AEF1AE'>                  }
</span>106 <span style=''></span><span style='background: #AEF1AE'>                  identifiers
</span>107 <span style=''></span><span style='background: #AEF1AE'>                } else {
</span>108 <span style=''></span><span style='background: #AEF1AE'>                  // it's not a lambda function we know, is it inbuilt?
</span>109 <span style=''></span><span style='background: #AEF1AE'>                  // NB you would have to register UDFs etc. before calling validate etc.
</span>110 <span style=''></span><span style='background: #AEF1AE'>                  val exists =
</span>111 <span style=''></span><span style='background: #AEF1AE'>                    SparkSession.active.catalog.functionExists(name)
</span>112 <span style=''></span><span style='background: #AEF1AE'>
</span>113 <span style=''></span><span style='background: #AEF1AE'>                  if (!exists) {
</span>114 <span style=''></span><span style='background: #AEF1AE'>                    // add it in to the unknowns list
</span>115 <span style=''></span><span style='background: #AEF1AE'>                    val map = unknownSparkFunctionIds.getOrElse(id, Set.empty)
</span>116 <span style=''></span><span style='background: #AEF1AE'>                    unknownSparkFunctionIds(id) = map + name
</span>117 <span style=''></span><span style='background: #AEF1AE'>                  }
</span>118 <span style=''></span><span style='background: #AEF1AE'>                  identifiers
</span>119 <span style=''></span><span style='background: #AEF1AE'>                }</span><span style=''>
</span>120 <span style=''>              }
</span>121 <span style=''>            // params may be including nested children
</span>122 <span style=''>            </span><span style='background: #AEF1AE'>fieldChildren(nids, argumentExpressions)</span><span style=''>
</span>123 <span style=''>          case p : Expression =&gt; </span><span style='background: #AEF1AE'>fieldChildren(identifiers, p.children)</span><span style=''>
</span>124 <span style=''>          case _  =&gt; identifiers
</span>125 <span style=''>        }
</span>126 <span style=''>
</span>127 <span style=''>      </span><span style='background: #AEF1AE'>faccumulate(ids, expr)</span><span style=''>
</span>128 <span style=''>    }
</span>129 <span style=''>
</span>130 <span style=''>    def accumulate(res: Map[Id, Identifiers], exp: (Id, Expression), parent: UnresolvedFunction): Map[Id, Identifiers] =
</span>131 <span style=''>      exp match {
</span>132 <span style=''>        // unresolved case where we cannot see more unresolved functions
</span>133 <span style=''>        case (id, SparkLambdaFunction(functionExpr, arguments, _)) =&gt;
</span>134 <span style=''>          // remove the arguments from any unresolved bound variables
</span>135 <span style=''>          val names = </span><span style='background: #AEF1AE'>arguments.map(v =&gt; toName(v.asInstanceOf[UnresolvedNamedLambdaVariable])).toSet</span><span style=''>
</span>136 <span style=''>          // parse the functionExpr with the names
</span>137 <span style=''>          </span><span style='background: #AEF1AE'>Map( id -&gt; processFields(names, functionExpr, id, parent))</span><span style=''> //TODO is this parent?
</span>138 <span style=''>        case (id, a : UnresolvedAttribute) =&gt; // not as part of a lambda
</span>139 <span style=''>          val s = </span><span style='background: #AEF1AE'>res.getOrElse(id, Set.empty)</span><span style=''>
</span>140 <span style=''>          </span><span style='background: #AEF1AE'>res + ( id -&gt; (s + toName(a.nameParts)) )</span><span style=''>
</span>141 <span style=''>        case (id, _ : LeafExpression) =&gt; res
</span>142 <span style=''>        case (id, parent: UnresolvedFunction) =&gt; </span><span style='background: #AEF1AE'>res |+| children(res, parent.children.map((id,_)), parent)</span><span style=''> // override
</span>143 <span style=''>        case (id, newparent: Expression) =&gt; </span><span style='background: #AEF1AE'>res |+| children(res, newparent.children.map((id,_)), parent)</span><span style=''>
</span>144 <span style=''>      }
</span>145 <span style=''>
</span>146 <span style=''>    val ids = </span><span style='background: #AEF1AE'>children(Map.empty, exprMap.toSeq, null)</span><span style=''>
</span>147 <span style=''>
</span>148 <span style=''>    </span><span style='background: #AEF1AE'>(( m + (name -&gt; ids) ) ++ evaluatedLambdas, Set() ++ overflowIds, Map() ++ unknownSparkFunctionIds)</span><span style=''>
</span>149 <span style=''>  }
</span>150 <span style=''>
</span>151 <span style=''>  /**
</span>152 <span style=''>   * Identifies all variables from an expression tree, attempts to drill down into lambdas if the name is already known.
</span>153 <span style=''>   * @param expr The root expression to be evaluated
</span>154 <span style=''>   * @param knownLambdaLookups using a map of lambda functions to already identified late bind fields calls to this lambda will be expanded
</span>155 <span style=''>   * @return
</span>156 <span style=''>   */
</span>157 <span style=''>  def fieldsFromExpression(expr: Expression, knownLambdaLookups: ProcessedLambdas = Map.empty): ExpressionLookup = {
</span>158 <span style=''>    def children(res: ExpressionLookup, children: Seq[Expression]): ExpressionLookup =
</span>159 <span style=''>      </span><span style='background: #AEF1AE'>children.foldLeft(res){
</span>160 <span style=''></span><span style='background: #AEF1AE'>        (curRes, exp) =&gt;
</span>161 <span style=''></span><span style='background: #AEF1AE'>          accumulate(curRes, exp)
</span>162 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>163 <span style=''>
</span>164 <span style=''>    def accumulate(res: ExpressionLookup, exp: Expression): ExpressionLookup =
</span>165 <span style=''>      exp match {
</span>166 <span style=''>        // unresolved case where we cannot see more unresolved functions
</span>167 <span style=''>        case f @ UnresolvedFunction4(_, arguments, _, _) =&gt;
</span>168 <span style=''>          val name = </span><span style='background: #AEF1AE'>toName(f)</span><span style=''>
</span>169 <span style=''>          val r =
</span>170 <span style=''>            if (</span><span style='background: #AEF1AE'>knownLambdaLookups.contains(name)</span><span style=''>) </span><span style='background: #AEF1AE'>{
</span>171 <span style=''></span><span style='background: #AEF1AE'>              val lambdas = knownLambdaLookups(name)
</span>172 <span style=''></span><span style='background: #AEF1AE'>              res.copy(attributesUsed = res.attributesUsed ++ lambdas.flatMap(_._2), lambdas = res.lambdas ++ lambdas.keySet)  // merge the identifier set and lambdas
</span>173 <span style=''></span><span style='background: #AEF1AE'>            }</span><span style=''> else </span><span style='background: #AEF1AE'>{
</span>174 <span style=''></span><span style='background: #AEF1AE'>              // it's not a lambda function we know, is it inbuilt?
</span>175 <span style=''></span><span style='background: #AEF1AE'>              // NB you would have to register UDFs etc. before calling validate etc.
</span>176 <span style=''></span><span style='background: #AEF1AE'>              val exists =
</span>177 <span style=''></span><span style='background: #AEF1AE'>                SparkSession.active.catalog.functionExists(name)
</span>178 <span style=''></span><span style='background: #AEF1AE'>
</span>179 <span style=''></span><span style='background: #AEF1AE'>              if (!exists)
</span>180 <span style=''></span><span style='background: #AEF1AE'>                // add it in to the unknowns list
</span>181 <span style=''></span><span style='background: #AEF1AE'>                res.copy(unknownSparkFunctions = res.unknownSparkFunctions + name)
</span>182 <span style=''></span><span style='background: #AEF1AE'>              else
</span>183 <span style=''></span><span style='background: #AEF1AE'>                res.copy(sparkFunctions = res.sparkFunctions + name)
</span>184 <span style=''></span><span style='background: #AEF1AE'>            }</span><span style=''>
</span>185 <span style=''>
</span>186 <span style=''>          // we still need to do the args
</span>187 <span style=''>          </span><span style='background: #AEF1AE'>children(r, arguments)</span><span style=''>
</span>188 <span style=''>        case a : UnresolvedAttribute =&gt;
</span>189 <span style=''>          </span><span style='background: #AEF1AE'>res.copy(attributesUsed = res.attributesUsed + a.name)</span><span style=''>
</span>190 <span style=''>        // typically handled by the lambda functions above, but for coalesce this doesn't work, we need sub expression handling
</span>191 <span style=''>        case a : UnresolvedNamedLambdaVariable =&gt;
</span>192 <span style=''>          </span><span style='background: #AEF1AE'>res.copy(attributesUsed = res.attributesUsed + a.name)</span><span style=''>
</span>193 <span style=''>        case _ : LeafExpression =&gt; res
</span>194 <span style=''>        case parent: Expression =&gt; </span><span style='background: #AEF1AE'>children(res, parent.children)</span><span style=''>
</span>195 <span style=''>      }
</span>196 <span style=''>
</span>197 <span style=''>    val ids = </span><span style='background: #AEF1AE'>accumulate(util.ExpressionLookup(), expr)</span><span style=''>
</span>198 <span style=''>
</span>199 <span style=''>    ids
</span>200 <span style=''>  }
</span>201 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          7625
        </td>
        <td>
          1978
          -
          2020
        </td>
        <td>
          Apply
        </td>
        <td>
          org.slf4j.LoggerFactory.getLogger
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.slf4j.LoggerFactory.getLogger(&quot;VariablesLookup&quot;)
        </td>
      </tr><tr>
        <td>
          45
        </td>
        <td>
          7628
        </td>
        <td>
          2431
          -
          2457
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, Set[String]]
        </td>
      </tr><tr>
        <td>
          45
        </td>
        <td>
          7627
        </td>
        <td>
          2416
          -
          2429
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[com.sparkutils.quality.Id]
        </td>
      </tr><tr>
        <td>
          45
        </td>
        <td>
          7629
        </td>
        <td>
          2374
          -
          2458
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple3.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple3.apply[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]]](scala.Predef.Map.empty[String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.Predef.Set.empty[com.sparkutils.quality.Id], scala.Predef.Map.empty[com.sparkutils.quality.Id, Set[String]])
        </td>
      </tr><tr>
        <td>
          45
        </td>
        <td>
          7644
        </td>
        <td>
          2363
          -
          2697
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.foldLeft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          m.foldLeft[(scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]])](scala.Tuple3.apply[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]]](scala.Predef.Map.empty[String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.Predef.Set.empty[com.sparkutils.quality.Id], scala.Predef.Map.empty[com.sparkutils.quality.Id, Set[String]]))(((acc: (scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]]), p: (String, Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; if (acc._1.contains(p._1))
  acc
else
  {
    &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$1: (scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]]) = (acc: (scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]]) @unchecked) match {
      case (_1: scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], _2: scala.collection.immutable.Set[com.sparkutils.quality.Id], _3: scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]])(scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]])((macc @ _), (s @ _), (us @ _)) =&gt; scala.Tuple3.apply[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]]](macc, s, us)
    };
    val macc: scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]] = x$1._1;
    val s: scala.collection.immutable.Set[com.sparkutils.quality.Id] = x$1._2;
    val us: scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]] = x$1._3;
    &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$2: (com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions) = (VariablesLookup.this.fieldsFromLambda(p._1, p._2, macc, m): (com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions) @unchecked) match {
      case (_1: com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, _2: com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, _3: com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions)(com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions)((res @ _), (ress @ _), (resus @ _)) =&gt; scala.Tuple3.apply[com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions](res, ress, resus)
    };
    val res: com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas = x$2._1;
    val ress: com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds = x$2._2;
    val resus: com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions = x$2._3;
    scala.Tuple3.apply[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions](cats.implicits.catsSyntaxSemigroup[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]]](macc)(cats.implicits.catsKernelStdCommutativeMonoidForMap[String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]))).|+|(res), cats.implicits.catsSyntaxSemigroup[com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds](ress)(cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.Id]).|+|(s), cats.implicits.catsSyntaxSemigroup[com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions](resus)(cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, Set[String]](cats.implicits.catsKernelStdSemilatticeForSet[String])).|+|(us))
  }))
        </td>
      </tr><tr>
        <td>
          45
        </td>
        <td>
          7626
        </td>
        <td>
          2375
          -
          2414
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]]
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          7631
        </td>
        <td>
          2483
          -
          2504
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          acc._1.contains(p._1)
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          7630
        </td>
        <td>
          2499
          -
          2503
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          7632
        </td>
        <td>
          2514
          -
          2517
        </td>
        <td>
          Ident
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.acc
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          acc
        </td>
      </tr><tr>
        <td>
          48
        </td>
        <td>
          7643
        </td>
        <td>
          2529
          -
          2691
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$1: (scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]]) = (acc: (scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]]) @unchecked) match {
    case (_1: scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], _2: scala.collection.immutable.Set[com.sparkutils.quality.Id], _3: scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]])(scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]])((macc @ _), (s @ _), (us @ _)) =&gt; scala.Tuple3.apply[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]]](macc, s, us)
  };
  val macc: scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]] = x$1._1;
  val s: scala.collection.immutable.Set[com.sparkutils.quality.Id] = x$1._2;
  val us: scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]] = x$1._3;
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$2: (com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions) = (VariablesLookup.this.fieldsFromLambda(p._1, p._2, macc, m): (com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions) @unchecked) match {
    case (_1: com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, _2: com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, _3: com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions)(com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions)((res @ _), (ress @ _), (resus @ _)) =&gt; scala.Tuple3.apply[com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions](res, ress, resus)
  };
  val res: com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas = x$2._1;
  val ress: com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds = x$2._2;
  val resus: com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions = x$2._3;
  scala.Tuple3.apply[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions](cats.implicits.catsSyntaxSemigroup[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]]](macc)(cats.implicits.catsKernelStdCommutativeMonoidForMap[String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]))).|+|(res), cats.implicits.catsSyntaxSemigroup[com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds](ress)(cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.Id]).|+|(s), cats.implicits.catsSyntaxSemigroup[com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions](resus)(cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, Set[String]](cats.implicits.catsKernelStdSemilatticeForSet[String])).|+|(us))
}
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          7634
        </td>
        <td>
          2550
          -
          2550
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$1._2
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          7633
        </td>
        <td>
          2544
          -
          2544
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$1._1
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          7635
        </td>
        <td>
          2553
          -
          2553
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$1._3
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          7637
        </td>
        <td>
          2581
          -
          2581
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._2
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          7636
        </td>
        <td>
          2576
          -
          2576
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._1
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          7638
        </td>
        <td>
          2587
          -
          2587
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._3
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          7640
        </td>
        <td>
          2658
          -
          2668
        </td>
        <td>
          Apply
        </td>
        <td>
          cats.syntax.SemigroupOps.|+|
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsSyntaxSemigroup[com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds](ress)(cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.Id]).|+|(s)
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          7639
        </td>
        <td>
          2644
          -
          2656
        </td>
        <td>
          Apply
        </td>
        <td>
          cats.syntax.SemigroupOps.|+|
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsSyntaxSemigroup[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]]](macc)(cats.implicits.catsKernelStdCommutativeMonoidForMap[String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]))).|+|(res)
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          7642
        </td>
        <td>
          2643
          -
          2683
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple3.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple3.apply[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions](cats.implicits.catsSyntaxSemigroup[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]]](macc)(cats.implicits.catsKernelStdCommutativeMonoidForMap[String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]))).|+|(res), cats.implicits.catsSyntaxSemigroup[com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds](ress)(cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.Id]).|+|(s), cats.implicits.catsSyntaxSemigroup[com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions](resus)(cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, Set[String]](cats.implicits.catsKernelStdSemilatticeForSet[String])).|+|(us))
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          7641
        </td>
        <td>
          2670
          -
          2682
        </td>
        <td>
          Apply
        </td>
        <td>
          cats.syntax.SemigroupOps.|+|
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsSyntaxSemigroup[com.sparkutils.quality.impl.util.VariablesLookup.UnknownSparkFunctions](resus)(cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, Set[String]](cats.implicits.catsKernelStdSemilatticeForSet[String])).|+|(us)
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          7645
        </td>
        <td>
          2981
          -
          3050
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Map.empty[String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]].++[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](m)
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          7646
        </td>
        <td>
          3073
          -
          3111
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.mutable.Set.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.empty[com.sparkutils.quality.Id]
        </td>
      </tr><tr>
        <td>
          59
        </td>
        <td>
          7647
        </td>
        <td>
          3146
          -
          3197
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.mutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Map.empty[com.sparkutils.quality.Id, Set[String]]
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          7652
        </td>
        <td>
          3334
          -
          3443
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.foldLeft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          children.foldLeft[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](res)(((curRes: Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers], exp: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; cats.implicits.catsSyntaxSemigroup[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](curRes)(cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier])).|+|(accumulate(curRes, exp, parent))))
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          7649
        </td>
        <td>
          3393
          -
          3393
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          cats.kernel.instances.MapInstances.catsKernelStdCommutativeMonoidForMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier])
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          7648
        </td>
        <td>
          3393
          -
          3393
        </td>
        <td>
          TypeApply
        </td>
        <td>
          cats.kernel.instances.SetInstances1.catsKernelStdSemilatticeForSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          7651
        </td>
        <td>
          3393
          -
          3435
        </td>
        <td>
          Apply
        </td>
        <td>
          cats.syntax.SemigroupOps.|+|
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsSyntaxSemigroup[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](curRes)(cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier])).|+|(accumulate(curRes, exp, parent))
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          7650
        </td>
        <td>
          3404
          -
          3435
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.accumulate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          accumulate(curRes, exp, parent)
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          7654
        </td>
        <td>
          3679
          -
          3777
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.foldLeft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          children.foldLeft[com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](res)(((curRes: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers, exp: org.apache.spark.sql.catalyst.expressions.Expression) =&gt; faccumulate(curRes, exp)))
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          7653
        </td>
        <td>
          3743
          -
          3767
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.faccumulate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          faccumulate(curRes, exp)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          7655
        </td>
        <td>
          3968
          -
          3977
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.shim.expressions.Names.toName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.shim.expressions.Names.toName(a)
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          7656
        </td>
        <td>
          3994
          -
          4014
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          args.contains(full).unary_!
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          7658
        </td>
        <td>
          4126
          -
          4144
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.SetLike.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.+(full)
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          7657
        </td>
        <td>
          4126
          -
          4144
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.+(full)
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          7659
        </td>
        <td>
          4176
          -
          4187
        </td>
        <td>
          Ident
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.identifiers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          7660
        </td>
        <td>
          4298
          -
          4307
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.shim.expressions.Names.toName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.shim.expressions.Names.toName(f)
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          7661
        </td>
        <td>
          4349
          -
          4380
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          evaluatedLambdas.contains(name)
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          7662
        </td>
        <td>
          4398
          -
          4409
        </td>
        <td>
          Ident
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.identifiers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers
        </td>
      </tr><tr>
        <td>
          89
        </td>
        <td>
          7684
        </td>
        <td>
          4485
          -
          5464
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  if (parent.ne(null).&amp;&amp;(name.==(com.sparkutils.shim.expressions.Names.toName(parent))))
    lambdaExpressions.apply(name).find(((x$3: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$3._2.children.size.==(argumentExpressions.size))).fold[Unit]({
      overflowIds.+=(id);
      VariablesLookup.this.logger.warn(scala.StringContext.apply(&quot;Function &quot;, &quot; calls itself, this may StackOverflowError on evaluation&quot;).s(name))
    })(((i: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; {
      val r: Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers] = children(scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing], scala.collection.Seq.apply[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)](i), f);
      evaluatedLambdas.update(name, r)
    }))
  else
    {
      val r: Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers] = children(scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing], lambdaExpressions.apply(name).toSeq, f);
      evaluatedLambdas.update(name, r)
    };
  identifiers
}
        </td>
      </tr><tr>
        <td>
          89
        </td>
        <td>
          7663
        </td>
        <td>
          4451
          -
          4483
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaExpressions.contains(name)
        </td>
      </tr><tr>
        <td>
          89
        </td>
        <td>
          7695
        </td>
        <td>
          4447
          -
          6029
        </td>
        <td>
          If
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          if (lambdaExpressions.contains(name))
  {
    if (parent.ne(null).&amp;&amp;(name.==(com.sparkutils.shim.expressions.Names.toName(parent))))
      lambdaExpressions.apply(name).find(((x$3: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$3._2.children.size.==(argumentExpressions.size))).fold[Unit]({
        overflowIds.+=(id);
        VariablesLookup.this.logger.warn(scala.StringContext.apply(&quot;Function &quot;, &quot; calls itself, this may StackOverflowError on evaluation&quot;).s(name))
      })(((i: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; {
        val r: Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers] = children(scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing], scala.collection.Seq.apply[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)](i), f);
        evaluatedLambdas.update(name, r)
      }))
    else
      {
        val r: Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers] = children(scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing], lambdaExpressions.apply(name).toSeq, f);
        evaluatedLambdas.update(name, r)
      };
    identifiers
  }
else
  {
    val exists: Boolean = org.apache.spark.sql.SparkSession.active.catalog.functionExists(name);
    if (exists.unary_!)
      {
        val map: Set[String] = unknownSparkFunctionIds.getOrElse[Set[String]](id, scala.Predef.Set.empty[String]);
        unknownSparkFunctionIds.update(id, map.+(name))
      }
    else
      ();
    identifiers
  }
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          7667
        </td>
        <td>
          4600
          -
          4642
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Boolean.&amp;&amp;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parent.ne(null).&amp;&amp;(name.==(com.sparkutils.shim.expressions.Names.toName(parent)))
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          7664
        </td>
        <td>
          4611
          -
          4615
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          null
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          7666
        </td>
        <td>
          4620
          -
          4642
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          name.==(com.sparkutils.shim.expressions.Names.toName(parent))
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          7665
        </td>
        <td>
          4628
          -
          4642
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.shim.expressions.Names.toName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.shim.expressions.Names.toName(parent)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          7669
        </td>
        <td>
          4850
          -
          4896
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._2.children.size.==(argumentExpressions.size)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          7668
        </td>
        <td>
          4872
          -
          4896
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SeqLike.size
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          argumentExpressions.size
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          7670
        </td>
        <td>
          4926
          -
          4943
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          overflowIds.+=(id)
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          7672
        </td>
        <td>
          4966
          -
          5054
        </td>
        <td>
          Apply
        </td>
        <td>
          org.slf4j.Logger.warn
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          VariablesLookup.this.logger.warn(scala.StringContext.apply(&quot;Function &quot;, &quot; calls itself, this may StackOverflowError on evaluation&quot;).s(name))
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          7671
        </td>
        <td>
          4978
          -
          5053
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Function &quot;, &quot; calls itself, this may StackOverflowError on evaluation&quot;).s(name)
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          7678
        </td>
        <td>
          4821
          -
          5240
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.fold
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaExpressions.apply(name).find(((x$3: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$3._2.children.size.==(argumentExpressions.size))).fold[Unit]({
  overflowIds.+=(id);
  VariablesLookup.this.logger.warn(scala.StringContext.apply(&quot;Function &quot;, &quot; calls itself, this may StackOverflowError on evaluation&quot;).s(name))
})(((i: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; {
  val r: Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers] = children(scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing], scala.collection.Seq.apply[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)](i), f);
  evaluatedLambdas.update(name, r)
}))
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          7677
        </td>
        <td>
          4821
          -
          5240
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.fold
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaExpressions.apply(name).find(((x$3: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$3._2.children.size.==(argumentExpressions.size))).fold[Unit]({
  overflowIds.+=(id);
  VariablesLookup.this.logger.warn(scala.StringContext.apply(&quot;Function &quot;, &quot; calls itself, this may StackOverflowError on evaluation&quot;).s(name))
})(((i: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; {
  val r: Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers] = children(scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing], scala.collection.Seq.apply[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)](i), f);
  evaluatedLambdas.update(name, r)
}))
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          7673
        </td>
        <td>
          5146
          -
          5155
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing]
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          7675
        </td>
        <td>
          5137
          -
          5167
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.children
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          children(scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing], scala.collection.Seq.apply[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)](i), f)
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          7674
        </td>
        <td>
          5157
          -
          5163
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.apply[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)](i)
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          7676
        </td>
        <td>
          5192
          -
          5218
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.MapLike.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          evaluatedLambdas.update(name, r)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          7683
        </td>
        <td>
          5266
          -
          5416
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val r: Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers] = children(scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing], lambdaExpressions.apply(name).toSeq, f);
  evaluatedLambdas.update(name, r)
}
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          7679
        </td>
        <td>
          5305
          -
          5314
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing]
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          7681
        </td>
        <td>
          5296
          -
          5349
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.children
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          children(scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing], lambdaExpressions.apply(name).toSeq, f)
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          7680
        </td>
        <td>
          5316
          -
          5345
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.MapLike.toSeq
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaExpressions.apply(name).toSeq
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          7682
        </td>
        <td>
          5370
          -
          5396
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.MapLike.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          evaluatedLambdas.update(name, r)
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          7694
        </td>
        <td>
          5470
          -
          6029
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val exists: Boolean = org.apache.spark.sql.SparkSession.active.catalog.functionExists(name);
  if (exists.unary_!)
    {
      val map: Set[String] = unknownSparkFunctionIds.getOrElse[Set[String]](id, scala.Predef.Set.empty[String]);
      unknownSparkFunctionIds.update(id, map.+(name))
    }
  else
    ();
  identifiers
}
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          7685
        </td>
        <td>
          5685
          -
          5733
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalog.Catalog.functionExists
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active.catalog.functionExists(name)
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          7691
        </td>
        <td>
          5766
          -
          5981
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val map: Set[String] = unknownSparkFunctionIds.getOrElse[Set[String]](id, scala.Predef.Set.empty[String]);
  unknownSparkFunctionIds.update(id, map.+(name))
}
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          7693
        </td>
        <td>
          5753
          -
          5753
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          7692
        </td>
        <td>
          5753
          -
          5753
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          7686
        </td>
        <td>
          5757
          -
          5764
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exists.unary_!
        </td>
      </tr><tr>
        <td>
          115
        </td>
        <td>
          7688
        </td>
        <td>
          5852
          -
          5900
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownSparkFunctionIds.getOrElse[Set[String]](id, scala.Predef.Set.empty[String])
        </td>
      </tr><tr>
        <td>
          115
        </td>
        <td>
          7687
        </td>
        <td>
          5890
          -
          5899
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[String]
        </td>
      </tr><tr>
        <td>
          116
        </td>
        <td>
          7690
        </td>
        <td>
          5921
          -
          5961
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.MapLike.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownSparkFunctionIds.update(id, map.+(name))
        </td>
      </tr><tr>
        <td>
          116
        </td>
        <td>
          7689
        </td>
        <td>
          5951
          -
          5961
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          map.+(name)
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          7696
        </td>
        <td>
          6113
          -
          6153
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.fieldChildren
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          fieldChildren(nids, argumentExpressions)
        </td>
      </tr><tr>
        <td>
          123
        </td>
        <td>
          7697
        </td>
        <td>
          6214
          -
          6224
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.trees.TreeNode.children
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p.children
        </td>
      </tr><tr>
        <td>
          123
        </td>
        <td>
          7698
        </td>
        <td>
          6187
          -
          6225
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.fieldChildren
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          fieldChildren(identifiers, p.children)
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          7699
        </td>
        <td>
          6276
          -
          6298
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.faccumulate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          faccumulate(ids, expr)
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          7703
        </td>
        <td>
          6680
          -
          6759
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          arguments.map[String, Seq[String]](((v: org.apache.spark.sql.catalyst.expressions.NamedExpression) =&gt; com.sparkutils.shim.expressions.Names.toName(v.asInstanceOf[org.apache.spark.sql.catalyst.expressions.UnresolvedNamedLambdaVariable])))(collection.this.Seq.canBuildFrom[String]).toSet[String]
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          7700
        </td>
        <td>
          6706
          -
          6751
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          v.asInstanceOf[org.apache.spark.sql.catalyst.expressions.UnresolvedNamedLambdaVariable]
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          7702
        </td>
        <td>
          6693
          -
          6693
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          7701
        </td>
        <td>
          6699
          -
          6752
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.shim.expressions.Names.toName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.shim.expressions.Names.toName(v.asInstanceOf[org.apache.spark.sql.catalyst.expressions.UnresolvedNamedLambdaVariable])
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          7706
        </td>
        <td>
          6821
          -
          6879
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenMapFactory.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](processFields(names, functionExpr, id, parent, processFields$default$5)))
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          7705
        </td>
        <td>
          6826
          -
          6878
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](processFields(names, functionExpr, id, parent, processFields$default$5))
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          7704
        </td>
        <td>
          6832
          -
          6878
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.processFields
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          processFields(names, functionExpr, id, parent, processFields$default$5)
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          7708
        </td>
        <td>
          6994
          -
          7022
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.getOrElse[com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](id, scala.Predef.Set.empty[com.sparkutils.quality.impl.util.VariablesLookup.Identifier])
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          7707
        </td>
        <td>
          7012
          -
          7021
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          7712
        </td>
        <td>
          7041
          -
          7072
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[scala.collection.immutable.Set[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]](s.+(com.sparkutils.shim.expressions.Names.toName(a.nameParts)))
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          7709
        </td>
        <td>
          7059
          -
          7070
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute.nameParts
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          a.nameParts
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          7711
        </td>
        <td>
          7048
          -
          7071
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          s.+(com.sparkutils.shim.expressions.Names.toName(a.nameParts))
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          7713
        </td>
        <td>
          7033
          -
          7074
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.+[com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[scala.collection.immutable.Set[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]](s.+(com.sparkutils.shim.expressions.Names.toName(a.nameParts))))
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          7710
        </td>
        <td>
          7052
          -
          7071
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.shim.expressions.Names.toName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.shim.expressions.Names.toName(a.nameParts)
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          7715
        </td>
        <td>
          7169
          -
          7169
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          cats.kernel.instances.MapInstances.catsKernelStdCommutativeMonoidForMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier])
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          7718
        </td>
        <td>
          7191
          -
          7218
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parent.children.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$4: org.apache.spark.sql.catalyst.expressions.Expression) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](id, x$4)))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          7717
        </td>
        <td>
          7210
          -
          7210
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          7720
        </td>
        <td>
          7169
          -
          7227
        </td>
        <td>
          Apply
        </td>
        <td>
          cats.syntax.SemigroupOps.|+|
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsSyntaxSemigroup[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](res)(cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier])).|+|(children(res, parent.children.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$4: org.apache.spark.sql.catalyst.expressions.Expression) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](id, x$4)))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]), parent))
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          7714
        </td>
        <td>
          7169
          -
          7169
        </td>
        <td>
          TypeApply
        </td>
        <td>
          cats.kernel.instances.SetInstances1.catsKernelStdSemilatticeForSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          7716
        </td>
        <td>
          7211
          -
          7217
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](id, x$4)
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          7719
        </td>
        <td>
          7177
          -
          7227
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.children
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          children(res, parent.children.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$4: org.apache.spark.sql.catalyst.expressions.Expression) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](id, x$4)))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]), parent)
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          7727
        </td>
        <td>
          7284
          -
          7345
        </td>
        <td>
          Apply
        </td>
        <td>
          cats.syntax.SemigroupOps.|+|
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsSyntaxSemigroup[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](res)(cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier])).|+|(children(res, newparent.children.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$5: org.apache.spark.sql.catalyst.expressions.Expression) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](id, x$5)))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]), parent))
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          7721
        </td>
        <td>
          7284
          -
          7284
        </td>
        <td>
          TypeApply
        </td>
        <td>
          cats.kernel.instances.SetInstances1.catsKernelStdSemilatticeForSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          7724
        </td>
        <td>
          7328
          -
          7328
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          7726
        </td>
        <td>
          7292
          -
          7345
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.children
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          children(res, newparent.children.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$5: org.apache.spark.sql.catalyst.expressions.Expression) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](id, x$5)))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]), parent)
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          7723
        </td>
        <td>
          7329
          -
          7335
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](id, x$5)
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          7722
        </td>
        <td>
          7284
          -
          7284
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          cats.kernel.instances.MapInstances.catsKernelStdCommutativeMonoidForMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cats.implicits.catsKernelStdCommutativeMonoidForMap[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](cats.implicits.catsKernelStdSemilatticeForSet[com.sparkutils.quality.impl.util.VariablesLookup.Identifier])
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          7725
        </td>
        <td>
          7306
          -
          7336
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          newparent.children.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$5: org.apache.spark.sql.catalyst.expressions.Expression) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](id, x$5)))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          7730
        </td>
        <td>
          7404
          -
          7408
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          null
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          7729
        </td>
        <td>
          7389
          -
          7402
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.MapLike.toSeq
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprMap.toSeq
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          7731
        </td>
        <td>
          7369
          -
          7409
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.children
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          children(scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing], exprMap.toSeq, null)
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          7728
        </td>
        <td>
          7378
          -
          7387
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, Nothing]
        </td>
      </tr><tr>
        <td>
          148
        </td>
        <td>
          7733
        </td>
        <td>
          7459
          -
          7479
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.Id]().++(overflowIds)
        </td>
      </tr><tr>
        <td>
          148
        </td>
        <td>
          7735
        </td>
        <td>
          7415
          -
          7514
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple3.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple3.apply[scala.collection.immutable.Map[String,Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]], scala.collection.immutable.Set[com.sparkutils.quality.Id], scala.collection.immutable.Map[com.sparkutils.quality.Id,Set[String]]](m.+[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](scala.Predef.ArrowAssoc[String](name).-&gt;[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](ids)).++[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](evaluatedLambdas), scala.Predef.Set.apply[com.sparkutils.quality.Id]().++(overflowIds), scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[Set[String]](unknownSparkFunctionIds))
        </td>
      </tr><tr>
        <td>
          148
        </td>
        <td>
          7732
        </td>
        <td>
          7416
          -
          7457
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          m.+[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](scala.Predef.ArrowAssoc[String](name).-&gt;[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](ids)).++[Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers]](evaluatedLambdas)
        </td>
      </tr><tr>
        <td>
          148
        </td>
        <td>
          7734
        </td>
        <td>
          7481
          -
          7513
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[Set[String]](unknownSparkFunctionIds)
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          7737
        </td>
        <td>
          8069
          -
          8159
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.foldLeft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          children.foldLeft[com.sparkutils.quality.impl.util.ExpressionLookup](res)(((curRes: com.sparkutils.quality.impl.util.ExpressionLookup, exp: org.apache.spark.sql.catalyst.expressions.Expression) =&gt; accumulate(curRes, exp)))
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          7736
        </td>
        <td>
          8128
          -
          8151
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.accumulate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          accumulate(curRes, exp)
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          7738
        </td>
        <td>
          8412
          -
          8421
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.shim.expressions.Names.toName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.shim.expressions.Names.toName(f)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          7739
        </td>
        <td>
          8456
          -
          8489
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          knownLambdaLookups.contains(name)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          7750
        </td>
        <td>
          8491
          -
          8726
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val lambdas: Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers] = knownLambdaLookups.apply(name);
  {
    &lt;artifact&gt; val x$1: scala.collection.immutable.Set[com.sparkutils.quality.impl.util.VariablesLookup.Identifier] @scala.reflect.internal.annotations.uncheckedBounds = res.attributesUsed.++(lambdas.flatMap[com.sparkutils.quality.impl.util.VariablesLookup.Identifier, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]](((x$6: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers)) =&gt; x$6._2))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]));
    &lt;artifact&gt; val x$2: scala.collection.immutable.Set[com.sparkutils.quality.Id] @scala.reflect.internal.annotations.uncheckedBounds = res.lambdas.++(lambdas.keySet);
    &lt;artifact&gt; val x$3: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = res.copy$default$2;
    &lt;artifact&gt; val x$4: Set[String] @scala.reflect.internal.annotations.uncheckedBounds = res.copy$default$4;
    res.copy(x$1, x$3, x$2, x$4)
  }
}
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          7740
        </td>
        <td>
          8521
          -
          8545
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          knownLambdaLookups.apply(name)
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          7745
        </td>
        <td>
          8656
          -
          8670
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.immutable.MapLike.keySet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdas.keySet
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          7748
        </td>
        <td>
          8564
          -
          8564
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$4
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          7742
        </td>
        <td>
          8623
          -
          8623
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          7744
        </td>
        <td>
          8586
          -
          8629
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.attributesUsed.++(lambdas.flatMap[com.sparkutils.quality.impl.util.VariablesLookup.Identifier, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]](((x$6: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers)) =&gt; x$6._2))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]))
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          7747
        </td>
        <td>
          8564
          -
          8564
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$2
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          7741
        </td>
        <td>
          8624
          -
          8628
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$6._2
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          7749
        </td>
        <td>
          8560
          -
          8671
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy(x$1, x$3, x$2, x$4)
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          7743
        </td>
        <td>
          8608
          -
          8629
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdas.flatMap[com.sparkutils.quality.impl.util.VariablesLookup.Identifier, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.util.VariablesLookup.Identifier]](((x$6: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers)) =&gt; x$6._2))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.util.VariablesLookup.Identifier])
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          7746
        </td>
        <td>
          8641
          -
          8670
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.lambdas.++(lambdas.keySet)
        </td>
      </tr><tr>
        <td>
          173
        </td>
        <td>
          7765
        </td>
        <td>
          8732
          -
          9242
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val exists: Boolean = org.apache.spark.sql.SparkSession.active.catalog.functionExists(name);
  if (exists.unary_!)
    {
      &lt;artifact&gt; val x$5: scala.collection.immutable.Set[com.sparkutils.quality.impl.util.VariablesLookup.Identifier] @scala.reflect.internal.annotations.uncheckedBounds = res.unknownSparkFunctions.+(name);
      &lt;artifact&gt; val x$6: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = res.copy$default$1;
      &lt;artifact&gt; val x$7: Set[com.sparkutils.quality.Id] @scala.reflect.internal.annotations.uncheckedBounds = res.copy$default$3;
      &lt;artifact&gt; val x$8: Set[String] @scala.reflect.internal.annotations.uncheckedBounds = res.copy$default$4;
      res.copy(x$6, x$5, x$7, x$8)
    }
  else
    {
      &lt;artifact&gt; val x$9: scala.collection.immutable.Set[String] @scala.reflect.internal.annotations.uncheckedBounds = res.sparkFunctions.+(name);
      &lt;artifact&gt; val x$10: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = res.copy$default$1;
      &lt;artifact&gt; val x$11: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = res.copy$default$2;
      &lt;artifact&gt; val x$12: Set[com.sparkutils.quality.Id] @scala.reflect.internal.annotations.uncheckedBounds = res.copy$default$3;
      res.copy(x$10, x$11, x$12, x$9)
    }
}
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          7751
        </td>
        <td>
          8931
          -
          8979
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalog.Catalog.functionExists
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active.catalog.functionExists(name)
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          7752
        </td>
        <td>
          8999
          -
          9006
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exists.unary_!
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          7754
        </td>
        <td>
          9078
          -
          9078
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$1
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          7757
        </td>
        <td>
          9074
          -
          9140
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy(x$6, x$5, x$7, x$8)
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          7753
        </td>
        <td>
          9107
          -
          9139
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.unknownSparkFunctions.+(name)
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          7756
        </td>
        <td>
          9078
          -
          9078
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$4
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          7758
        </td>
        <td>
          9074
          -
          9140
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  &lt;artifact&gt; val x$5: scala.collection.immutable.Set[com.sparkutils.quality.impl.util.VariablesLookup.Identifier] @scala.reflect.internal.annotations.uncheckedBounds = res.unknownSparkFunctions.+(name);
  &lt;artifact&gt; val x$6: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = res.copy$default$1;
  &lt;artifact&gt; val x$7: Set[com.sparkutils.quality.Id] @scala.reflect.internal.annotations.uncheckedBounds = res.copy$default$3;
  &lt;artifact&gt; val x$8: Set[String] @scala.reflect.internal.annotations.uncheckedBounds = res.copy$default$4;
  res.copy(x$6, x$5, x$7, x$8)
}
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          7755
        </td>
        <td>
          9078
          -
          9078
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$3
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          7763
        </td>
        <td>
          9176
          -
          9228
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy(x$10, x$11, x$12, x$9)
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          7760
        </td>
        <td>
          9180
          -
          9180
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$1
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          7759
        </td>
        <td>
          9202
          -
          9227
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.sparkFunctions.+(name)
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          7762
        </td>
        <td>
          9180
          -
          9180
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$3
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          7761
        </td>
        <td>
          9180
          -
          9180
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$2
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          7764
        </td>
        <td>
          9176
          -
          9228
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  &lt;artifact&gt; val x$9: scala.collection.immutable.Set[String] @scala.reflect.internal.annotations.uncheckedBounds = res.sparkFunctions.+(name);
  &lt;artifact&gt; val x$10: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = res.copy$default$1;
  &lt;artifact&gt; val x$11: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = res.copy$default$2;
  &lt;artifact&gt; val x$12: Set[com.sparkutils.quality.Id] @scala.reflect.internal.annotations.uncheckedBounds = res.copy$default$3;
  res.copy(x$10, x$11, x$12, x$9)
}
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          7766
        </td>
        <td>
          9296
          -
          9318
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.children
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          children(r, arguments)
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          7772
        </td>
        <td>
          9369
          -
          9423
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy(res.attributesUsed.+(a.name), res.copy$default$2, res.copy$default$3, res.copy$default$4)
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          7769
        </td>
        <td>
          9373
          -
          9373
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$2
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          7768
        </td>
        <td>
          9395
          -
          9422
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.attributesUsed.+(a.name)
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          7771
        </td>
        <td>
          9373
          -
          9373
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$4
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          7767
        </td>
        <td>
          9416
          -
          9422
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          a.name
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          7770
        </td>
        <td>
          9373
          -
          9373
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$3
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          7775
        </td>
        <td>
          9616
          -
          9616
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$2
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          7778
        </td>
        <td>
          9612
          -
          9666
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy(res.attributesUsed.+(a.name), res.copy$default$2, res.copy$default$3, res.copy$default$4)
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          7777
        </td>
        <td>
          9616
          -
          9616
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$4
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          7774
        </td>
        <td>
          9638
          -
          9665
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.attributesUsed.+(a.name)
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          7773
        </td>
        <td>
          9659
          -
          9665
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.UnresolvedNamedLambdaVariable.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          a.name
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          7776
        </td>
        <td>
          9616
          -
          9616
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.copy$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.copy$default$3
        </td>
      </tr><tr>
        <td>
          194
        </td>
        <td>
          7780
        </td>
        <td>
          9741
          -
          9771
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.children
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          children(res, parent.children)
        </td>
      </tr><tr>
        <td>
          194
        </td>
        <td>
          7779
        </td>
        <td>
          9755
          -
          9770
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.trees.TreeNode.children
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parent.children
        </td>
      </tr><tr>
        <td>
          197
        </td>
        <td>
          7781
        </td>
        <td>
          9811
          -
          9811
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$1
        </td>
      </tr><tr>
        <td>
          197
        </td>
        <td>
          7784
        </td>
        <td>
          9811
          -
          9811
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$4
        </td>
      </tr><tr>
        <td>
          197
        </td>
        <td>
          7786
        </td>
        <td>
          9795
          -
          9836
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.accumulate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          accumulate(com.sparkutils.quality.impl.util.ExpressionLookup.apply(com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$1, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$2, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$3, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$4), expr)
        </td>
      </tr><tr>
        <td>
          197
        </td>
        <td>
          7783
        </td>
        <td>
          9811
          -
          9811
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$3
        </td>
      </tr><tr>
        <td>
          197
        </td>
        <td>
          7782
        </td>
        <td>
          9811
          -
          9811
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$2
        </td>
      </tr><tr>
        <td>
          197
        </td>
        <td>
          7785
        </td>
        <td>
          9806
          -
          9829
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.ExpressionLookup.apply(com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$1, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$2, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$3, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$4)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>