<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>  <!-- rebuild -->

    <groupId>com.sparkutils</groupId>
    <artifactId>quality_${dbrCompatVersion}${sparkCompatVersion}_${scalaCompatVersion}</artifactId>

    <version>0.1.3.1-RC12-SNAPSHOT</version>
    <name>Quality</name>
    <description>A Spark library for managing in-process data quality rules via Spark SQL</description>
    <url>https://sparkutils.github.io/quality/</url>
    <licenses>
        <license>
            <name>The Apache Software License, Version 2.0</name>
            <url>https://github.com/sparkutils/quality/blob/main/LICENSE</url>
        </license>
    </licenses>
    <developers>
        <developer>
            <name>Chris Twiner</name>
        </developer>
    </developers>
    <scm>
        <connection>scm:git:git://github.com/sparkutils/quality.git</connection>
        <developerConnection>scm:git:ssh://github.com:sparkutils/quality.git</developerConnection>
        <url>http://github.com/sparkutils/quality/tree/master</url>
    </scm>
    <profiles>
        <profile>  
            <id>Spark2</id> 
            <properties>
                <shimRuntime>2.4.0.oss</shimRuntime>
                <shimCompilationRuntime>2.4.0.oss</shimCompilationRuntime>
                <dbrCompatVersion></dbrCompatVersion>
                <scalaVersion>2.11.12</scalaVersion>
                <scalaCompatVersion>2.11</scalaCompatVersion>
                <framelessVersion>0.8.0</framelessVersion>
                <sparkVersion>2.4.6</sparkVersion>
                <sparkCompatVersion>2.4</sparkCompatVersion>
                <profileDir>2.4</profileDir>
                <jacksonVersion>2.9.9</jacksonVersion>
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>1</elidebelow>
                <refinedVersion>0.9.12</refinedVersion>
                <deltaCoreVersion>0.6.1</deltaCoreVersion>
                <scalaMeterVersion>0.19</scalaMeterVersion>
                <scalaMeterGroup>com.storm-enroute</scalaMeterGroup>
                <scalaMeterArtifact>scalameter</scalaMeterArtifact>
            </properties>
        </profile>
        <profile>
            <id>Spark3</id> 
            <properties>
                <shimRuntime>3.0.0.oss</shimRuntime>
                <shimCompilationRuntime>3.0.0.oss</shimCompilationRuntime>
                <dbrCompatVersion></dbrCompatVersion>
                <scalaVersion>2.12.10</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.9.0</framelessVersion>
                <sparkVersion>3.0.3</sparkVersion>
                <sparkCompatVersion>3.0</sparkCompatVersion>
                <profileDir>3.0</profileDir>
                <jacksonVersion>2.12.1</jacksonVersion>
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version, actual spark is 16.0.1 -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>0</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <deltaCoreVersion>0.8.0</deltaCoreVersion>
            </properties>
        </profile>
        <profile>
            <id>9.1.dbr</id>
            <properties>
                <shimRuntime>9.1.dbr</shimRuntime>
                <shimCompilationRuntime>9.1.dbr</shimCompilationRuntime>
                <dbrCompatVersion>9.1.dbr_</dbrCompatVersion>
                <scalaVersion>2.12.10</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.10.1</framelessVersion>
                <sparkVersion>3.1.2</sparkVersion>
                <sparkCompatVersion>3.1</sparkCompatVersion>
                <profileDir>9.1.dbr</profileDir>
                <jacksonVersion>2.12.1</jacksonVersion>
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version, actual spark is downgraded to 11, sipHash24, crc32 and adler32 missing -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>1</elidebelow> <!-- dbr doesn't fail codegen -->
                <refinedVersion>0.9.28</refinedVersion>
                <snakeScope>provided</snakeScope>
            </properties>
        </profile>
        <profile>
            <id>Spark313</id>
            <properties>
                <shimRuntime>3.1.3.oss</shimRuntime>
                <shimCompilationRuntime>3.1.3.oss</shimCompilationRuntime>
                <dbrCompatVersion></dbrCompatVersion>
                <scalaVersion>2.12.10</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.10.1</framelessVersion>
                <sparkVersion>3.1.3</sparkVersion>
                <sparkCompatVersion>3.1</sparkCompatVersion>
                <profileDir>3.1</profileDir>
                <jacksonVersion>2.12.1</jacksonVersion>
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version, actual spark is downgraded to 11, sipHash24, crc32 and adler32 missing -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>0</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <deltaCoreVersion>1.0.1</deltaCoreVersion>
            </properties>
        </profile>
        <profile>
            <id>Spark32</id>
            <properties>
                <shimRuntime>3.2.0.oss</shimRuntime>
                <shimCompilationRuntime>3.2.0.oss</shimCompilationRuntime>
                <dbrCompatVersion></dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.11.1</framelessVersion>
                <sparkVersion>3.2.0</sparkVersion>
                <sparkCompatVersion>3.2</sparkCompatVersion>
                <profileDir>3.2</profileDir>
                <jacksonVersion>2.12.1</jacksonVersion>
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <deltaCoreVersion>2.0.0</deltaCoreVersion>
            </properties>
        </profile>
        <profile>
            <id>Spark321</id>
            <properties>
                <shimRuntime>3.2.1.oss</shimRuntime>
                <shimCompilationRuntime>3.2.1.oss</shimCompilationRuntime>
                <dbrCompatVersion>3.2.1.oss_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.12.0</framelessVersion>
                <sparkVersion>3.2.1</sparkVersion>
                <sparkCompatVersion>3.2</sparkCompatVersion>
                <profileDir>3.2.1</profileDir>
                <jacksonVersion>2.12.1</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <deltaCoreVersion>2.0.0</deltaCoreVersion>
            </properties>
        </profile>
        <profile>
            <id>10.4.dbr</id>
            <properties>
                <shimRuntime>10.4.dbr</shimRuntime>
                <shimCompilationRuntime>10.4.dbr</shimCompilationRuntime>
                <dbrCompatVersion>10.4.dbr_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.12.0</framelessVersion>
                <sparkVersion>3.2.1</sparkVersion>
                <sparkCompatVersion>3.2</sparkCompatVersion>
                <profileDir>10.4.dbr</profileDir>
                <jacksonVersion>2.12.1</jacksonVersion>
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <snakeVersion>1.24</snakeVersion>
                <snakeScope>provided</snakeScope>
            </properties>
        </profile>
        <profile>
            <id>Spark332</id>
            <properties>
                <shimRuntime>3.3.2.oss</shimRuntime>
                <shimCompilationRuntime>3.3.2.oss</shimCompilationRuntime>
                <dbrCompatVersion>3.3.2.oss_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.12.0</framelessVersion>
                <sparkVersion>3.3.2</sparkVersion>
                <sparkCompatVersion>3.3</sparkCompatVersion>
                <profileDir>3.3.2</profileDir>
                <jacksonVersion>2.13.5</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <deltaCoreVersion>2.3.0</deltaCoreVersion>
            </properties>
        </profile>
        <profile>
            <id>11.3.dbr</id>
            <properties> <!-- also contains backports of 3.4 functionality -->
                <shimRuntime>11.3.dbr</shimRuntime>
                <shimCompilationRuntime>11.3.dbr</shimCompilationRuntime>
                <dbrCompatVersion>11.3.dbr_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.12.0</framelessVersion>
                <sparkVersion>3.3.0</sparkVersion>
                <sparkCompatVersion>3.3</sparkCompatVersion>
                <profileDir>11.3.dbr</profileDir>
                <jacksonVersion>2.12.1</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <snakeVersion>1.24</snakeVersion>
                <snakeScope>provided</snakeScope>
            </properties>
        </profile>
        <profile>
            <id>Spark341</id>
            <properties>
                <shimRuntime>3.4.1.oss</shimRuntime>
                <shimCompilationRuntime>3.4.1.oss</shimCompilationRuntime>
                <dbrCompatVersion>3.4.1.oss_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.14.1</framelessVersion>
                <sparkVersion>3.4.3</sparkVersion>
                <sparkCompatVersion>3.4</sparkCompatVersion>
                <profileDir>3.4.1</profileDir>
                <jacksonVersion>2.14.2</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <deltaCoreVersion>2.4.0</deltaCoreVersion>
            </properties>
        </profile>
        <profile>
            <id>12.2.dbr</id>
            <properties> <!-- also contains backports of 3.4 functionality -->
                <shimRuntime>12.2.dbr</shimRuntime>
                <shimCompilationRuntime>12.2.dbr</shimCompilationRuntime>
                <dbrCompatVersion>12.2.dbr_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.14.1</framelessVersion>
                <sparkVersion>3.3.2</sparkVersion>
                <sparkCompatVersion>3.3</sparkCompatVersion>
                <profileDir>12.2.dbr</profileDir>
                <jacksonVersion>2.12.1</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <snakeVersion>1.24</snakeVersion>
                <snakeScope>provided</snakeScope>
            </properties>
        </profile>
        <profile>
            <id>13.1.dbr</id>
            <properties> <!-- also contains backports of 3.5 functionality -->
                <shimRuntime>13.1.dbr</shimRuntime>
                <shimCompilationRuntime>13.1.dbr</shimCompilationRuntime>
                <dbrCompatVersion>13.1.dbr_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.14.1</framelessVersion>
                <sparkVersion>3.4.1</sparkVersion>
                <sparkCompatVersion>3.4</sparkCompatVersion>
                <profileDir>13.1.dbr</profileDir>
                <jacksonVersion>2.14.2</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <snakeVersion>1.33</snakeVersion>
                <snakeScope>provided</snakeScope>
            </properties>
        </profile>
        <profile>
            <id>13.3.dbr</id>
            <properties> <!-- also contains backports of 3.5 functionality -->
                <shimRuntime>13.3.dbr</shimRuntime>
                <shimCompilationRuntime>13.3.dbr</shimCompilationRuntime>
                <dbrCompatVersion>13.3.dbr_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <sparkVersion>3.4.1</sparkVersion>
                <sparkCompatVersion>3.4</sparkCompatVersion>
                <profileDir>13.3.dbr</profileDir>
                <jacksonVersion>2.14.2</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <snakeVersion>1.33</snakeVersion>
                <snakeScope>provided</snakeScope>

                <framelessVersion>0.17.0</framelessVersion>
                <framelessCoreCompatVersion>_3.4</framelessCoreCompatVersion>
                <framelessCompatVersion>_3.4</framelessCompatVersion>
                <framelessOrg>com.sparkutils</framelessOrg>
            </properties>
        </profile>
        <profile>
            <id>Spark350</id>
            <properties>
                <shimRuntime>3.5.0.oss</shimRuntime>
                <shimCompilationRuntime>3.5.0.oss</shimCompilationRuntime>
                <dbrCompatVersion>3.5.0.oss_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.17.0</framelessVersion>
                <sparkVersion>3.5.5</sparkVersion>
                <sparkCompatVersion>3.5</sparkCompatVersion>
                <profileDir>3.5.0</profileDir>
                <jacksonVersion>2.15.2</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <deltaCoreVersion>3.0.0</deltaCoreVersion>
                <deltaArtifact>spark</deltaArtifact>
                <snakeVersion>2.0</snakeVersion>

                <!--<scalatestVersion>3.2.15</scalatestVersion>  databricks runtime version -->

                <framelessCoreCompatVersion>_3.5</framelessCoreCompatVersion>
                <framelessCompatVersion>_3.5</framelessCompatVersion>
                <framelessOrg>com.sparkutils</framelessOrg>
            </properties>
        </profile>
        <profile>
            <id>Spark4</id>
            <properties>
                <shimRuntime>4.0.0.oss</shimRuntime>
                <shimCompilationRuntime>4.0.0.oss</shimCompilationRuntime>
                <dbrCompatVersion>4.0.0.oss_</dbrCompatVersion>
                <scalaVersion>2.13.16</scalaVersion>
                <scalaCompatVersion>2.13</scalaCompatVersion>
                <sparkVersion>4.0.0</sparkVersion>
                <sparkCompatVersion>4.0</sparkCompatVersion>
                <profileDir>4.0.0</profileDir>
                <jacksonVersion>2.15.2</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <deltaCoreVersion>4.0.0rc1</deltaCoreVersion>
                <deltaArtifact>spark</deltaArtifact>
                <snakeVersion>2.0</snakeVersion>
                <shapelessVersion>2.3.10</shapelessVersion>
                <scalatestVersion>3.0.9</scalatestVersion>

                <framelessVersion>1.0.0-RC1</framelessVersion>
                <framelessCoreCompatVersion>_4.0</framelessCoreCompatVersion>
                <framelessCompatVersion>_4.0</framelessCompatVersion>
                <framelessOrg>com.sparkutils</framelessOrg>

                <scalaCollectionCompatVersion>2.13.0</scalaCollectionCompatVersion>
            </properties>
        </profile>
        <profile>
            <id>14.0.dbr</id>
            <properties>
                <shimRuntime>14.0.dbr</shimRuntime>
                <shimCompilationRuntime>14.0.dbr</shimCompilationRuntime>
                <dbrCompatVersion>14.0.dbr_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.17.0</framelessVersion>
                <sparkVersion>3.5.0</sparkVersion>
                <sparkCompatVersion>3.5</sparkCompatVersion>
                <profileDir>14.0.dbr</profileDir>
                <jacksonVersion>2.14.2</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <snakeVersion>2.0</snakeVersion>
                <snakeScope>provided</snakeScope>

                <framelessCoreCompatVersion>_3.5</framelessCoreCompatVersion>
                <framelessCompatVersion>_3.5</framelessCompatVersion>
                <framelessOrg>com.sparkutils</framelessOrg>
            </properties>
        </profile>
        <profile>
            <id>14.3.dbr</id>
            <properties>
                <shimRuntime>14.3.dbr</shimRuntime>
                <shimCompilationRuntime>14.3.dbr</shimCompilationRuntime>
                <dbrCompatVersion>14.3.dbr_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.17.0</framelessVersion>
                <sparkVersion>3.5.0</sparkVersion>
                <sparkCompatVersion>3.5</sparkCompatVersion>
                <profileDir>14.3.dbr</profileDir>
                <jacksonVersion>2.14.2</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <snakeVersion>2.0</snakeVersion>
                <snakeScope>provided</snakeScope>

                <framelessCoreCompatVersion>_3.5</framelessCoreCompatVersion>
                <framelessCompatVersion>_3.5</framelessCompatVersion>
                <framelessOrg>com.sparkutils</framelessOrg>
            </properties>
        </profile>
        <profile>
            <id>15.4.dbr</id>
            <properties>
                <shimRuntime>15.4.dbr</shimRuntime>
                <shimCompilationRuntime>15.4.dbr</shimCompilationRuntime>
                <dbrCompatVersion>15.4.dbr_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.17.0</framelessVersion>
                <sparkVersion>3.5.0</sparkVersion>
                <sparkCompatVersion>3.5</sparkCompatVersion>
                <profileDir>15.4.dbr</profileDir>
                <jacksonVersion>2.14.2</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <snakeVersion>2.0</snakeVersion>
                <snakeScope>provided</snakeScope>

                <framelessCoreCompatVersion>_3.5</framelessCoreCompatVersion>
                <framelessCompatVersion>_3.5</framelessCompatVersion>
                <framelessOrg>com.sparkutils</framelessOrg>
            </properties>
        </profile>
        <profile>
            <id>16.4.dbr</id>
            <properties>
                <shimRuntime>16.4.dbr</shimRuntime>
                <shimCompilationRuntime>16.4.dbr</shimCompilationRuntime>
                <dbrCompatVersion>16.4.dbr_</dbrCompatVersion>
                <scalaVersion>2.12.15</scalaVersion>
                <scalaCompatVersion>2.12</scalaCompatVersion>
                <framelessVersion>0.17.0</framelessVersion>
                <sparkVersion>3.5.0</sparkVersion>
                <sparkCompatVersion>3.5</sparkCompatVersion>
                <profileDir>16.4.dbr</profileDir>
                <jacksonVersion>2.14.2</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <snakeVersion>2.0</snakeVersion>
                <snakeScope>provided</snakeScope>

                <framelessCoreCompatVersion>_3.5</framelessCoreCompatVersion>
                <framelessCompatVersion>_3.5</framelessCompatVersion>
                <framelessOrg>com.sparkutils</framelessOrg>
            </properties>
        </profile>
        <profile>
            <id>17.0.dbr</id>
            <properties>
                <shimRuntime>17.0.dbr</shimRuntime>
                <shimCompilationRuntime>17.0.dbr</shimCompilationRuntime>
                <dbrCompatVersion>17.0.dbr_</dbrCompatVersion>
                <scalaVersion>2.13.16</scalaVersion>
                <scalaCompatVersion>2.13</scalaCompatVersion>
                <sparkVersion>4.0.0</sparkVersion>
                <sparkCompatVersion>4.0</sparkCompatVersion>
                <profileDir>17.0.dbr</profileDir>
                <jacksonVersion>2.14.2</jacksonVersion> <!-- scalameter dependency is 2.9.10 so perf tests runs need to change it -->
                <guavaVersion>15.0</guavaVersion> <!-- databricks runtime version -->
                <parserCombinatorVersion>1.1.2</parserCombinatorVersion> <!-- databricks runtime version -->
                <elidebelow>2</elidebelow>
                <refinedVersion>0.9.28</refinedVersion>
                <deltaCoreVersion>4.0.0rc1</deltaCoreVersion>
                <deltaArtifact>spark</deltaArtifact>
                <snakeVersion>2.0</snakeVersion>
                <shapelessVersion>2.3.10</shapelessVersion>
                <scalatestVersion>3.0.9</scalatestVersion>

                <framelessVersion>1.0.0-RC1</framelessVersion>
                <framelessCoreCompatVersion>_4.0</framelessCoreCompatVersion>
                <framelessCompatVersion>_4.0</framelessCompatVersion>
                <framelessOrg>com.sparkutils</framelessOrg>

                <scalaCollectionCompatVersion>2.13.0</scalaCollectionCompatVersion>
            </properties>
        </profile>
    </profiles>

    <properties>
        <framelessCompatVersion></framelessCompatVersion>
        <mavenFlattenPluginVersion>1.2.7</mavenFlattenPluginVersion>
        <mavenProjectInfoReportsPluginVersion>3.4.5</mavenProjectInfoReportsPluginVersion>
        <maven.compiler.source>1.8</maven.compiler.source>
        <maven.compiler.target>1.8</maven.compiler.target>
        <shapelessVersion>2.3.2</shapelessVersion>
        <scalaMeterVersion>0.0.2</scalaMeterVersion>
        <scalaMeterGroup>com.sparkutils</scalaMeterGroup>
        <scalaMeterArtifact>scalameter_shaded</scalaMeterArtifact>
        <httpClientVersion>4.5.8</httpClientVersion>
        <dbutilsVersion>0.0.3</dbutilsVersion>
        <scalatestVersion>3.0.7</scalatestVersion>
        <apacheCommons>3.5</apacheCommons>
        <junitVersion>4.12</junitVersion>
        <dependencyPluginVersion>3.6.1</dependencyPluginVersion>
        <scalaCompilerPluginVersion>4.8.0</scalaCompilerPluginVersion>
        <mavenCompilerPluginVersion>3.8.1</mavenCompilerPluginVersion>
        <mavenJarPluginVersion>3.2.0</mavenJarPluginVersion>
        <mavenShadePluginVersion>3.2.1</mavenShadePluginVersion>
        <mavenSitePluginVersion>3.7.1</mavenSitePluginVersion>
        <mavenProjectInfoReportsVersion>3.0.0</mavenProjectInfoReportsVersion>
        <surefirePluginVersion>2.22.2</surefirePluginVersion>
        <surefireReportPluginVersion>2.22.2</surefireReportPluginVersion>
        <scoverage.plugin.version>1.4.11</scoverage.plugin.version>
        <mavenAssemblyPluginVersion>2.5.3</mavenAssemblyPluginVersion>
        <deequ.version>1.0.2</deequ.version>
        <circeVersion>0.11.2</circeVersion>
        <rngVersion>1.3</rngVersion>
        <zeroAllocHashingVersion>0.15</zeroAllocHashingVersion>
        <scalaCrossPluginVersion>0.3.0</scalaCrossPluginVersion>
        <naked-local-fs-version>0.1.0</naked-local-fs-version>

        <deltaCoreVersion>0.6.1</deltaCoreVersion> <!-- for dbr builds -->
        <deltaArtifact>core</deltaArtifact>
        <!-- for oss builds -->
        <snakeVersion>1.33</snakeVersion>
        <snakeScope>compile</snakeScope>
        <shimCompilationVersion>0.2.0-RC5</shimCompilationVersion>
        <shimRuntimeVersion>0.2.0-RC5</shimRuntimeVersion>

        <framelessCoreCompatVersion></framelessCoreCompatVersion>
        <framelessOrg>org.typelevel</framelessOrg>

        <scalaCollectionCompatVersion>2.1.2</scalaCollectionCompatVersion>
    </properties>
<!--
    <repositories>
        <repository>
            <id>apache_snaps</id>
            <url>https://repository.apache.org/content/repositories/snapshots/</url>
        </repository>
        <repository>
            <id>s01_snaps</id>
            <url>https://s01.oss.sonatype.org/content/repositories/snapshots/</url>
        </repository>
    </repositories>
-->
    <distributionManagement>
        <repository>
            <id>ossrh</id>
            <name>Quality Release Repository</name>
            <url>https://s01.oss.sonatype.org/service/local/staging/deploy/maven2/</url>
        </repository>
        <snapshotRepository>
            <id>ossrh</id>
            <name>Quality Snapshot Repository</name>
            <url>https://s01.oss.sonatype.org/content/repositories/snapshots/</url>
        </snapshotRepository>
    </distributionManagement>

    <dependencies>
        <dependency>
            <groupId>com.sparkutils</groupId>
            <artifactId>shim_compilation_${shimCompilationRuntime}_${sparkCompatVersion}_${scalaCompatVersion}</artifactId>
            <version>${shimCompilationVersion}</version>
            <scope>provided</scope>
            <classifier>sources</classifier>
            <exclusions>
                <exclusion>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-sql_${scalaCompatVersion}</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>com.sparkutils</groupId>
            <artifactId>shim_runtime_${shimRuntime}_${sparkCompatVersion}_${scalaCompatVersion}</artifactId>
            <version>${shimRuntimeVersion}</version>
        </dependency>

        <!-- <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scalaCompatVersion}</artifactId>
            <version>${sparkVersion}</version>
            <scope>provided</scope>  
        </dependency> -->

        <dependency>
            <groupId>com.globalmentor</groupId>
            <artifactId>hadoop-bare-naked-local-fs</artifactId>
            <version>${naked-local-fs-version}</version>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>com.google.guava</groupId>
            <artifactId>guava</artifactId>
            <version>${guavaVersion}</version>
            <scope>provided</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scalaCompatVersion}</artifactId>
            <version>${sparkVersion}</version>
            <scope>provided</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_${scalaCompatVersion}</artifactId>
            <version>${sparkVersion}</version>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-avro_${scalaCompatVersion}</artifactId>
            <version>${sparkVersion}</version>
            <scope>test</scope>
        </dependency>

        <!-- not great, very slow
                <dependency>
                    <groupId>com.github.alexandrnikitin</groupId>
                    <artifactId>bloom-filter_${scalaCompatVersion}</artifactId>
                    <version>0.13.1</version>
                </dependency> -->

        <!-- added for parquets bloom -->
        <dependency>
            <groupId>net.openhft</groupId>
            <artifactId>zero-allocation-hashing</artifactId>
            <version>${zeroAllocHashingVersion}</version>
        </dependency>

        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-rng-client-api</artifactId>
            <version>${rngVersion}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-rng-core</artifactId>
            <version>${rngVersion}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-rng-simple</artifactId>
            <version>${rngVersion}</version>
        </dependency>
<!--
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scalaCompatVersion}</artifactId>
            <version>${sparkVersion}</version>
            <type>test-jar</type>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scalaCompatVersion}</artifactId>
            <version>${sparkVersion}</version>
            <type>test-jar</type>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-catalyst_${scalaCompatVersion}</artifactId>
            <version>${sparkVersion}</version>
            <type>test-jar</type>
            <scope>test</scope>
        </dependency>
-->
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <version>${scalaVersion}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.scalatest</groupId>
            <artifactId>scalatest_${scalaCompatVersion}</artifactId>
            <version>${scalatestVersion}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>${junitVersion}</version>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>${framelessOrg}</groupId>
            <artifactId>frameless-dataset${framelessCompatVersion}_${scalaCompatVersion}</artifactId>
            <version>${framelessVersion}</version>
            <exclusions>
                <exclusion>
                    <groupId>com.sparkutils</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>${framelessOrg}</groupId>
            <artifactId>frameless-core${framelessCoreCompatVersion}_${scalaCompatVersion}</artifactId>
            <version>${framelessVersion}</version>
            <exclusions>
                <exclusion>
                    <groupId>com.sparkutils</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>${framelessOrg}</groupId>
            <artifactId>frameless-ml${framelessCompatVersion}_${scalaCompatVersion}</artifactId>
            <version>${framelessVersion}</version>
            <exclusions>
                <exclusion>
                    <groupId>com.sparkutils</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>${framelessOrg}</groupId>
            <artifactId>frameless-cats${framelessCompatVersion}_${scalaCompatVersion}</artifactId>
            <version>${framelessVersion}</version>
            <exclusions>
                <exclusion>
                    <groupId>com.sparkutils</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <!-- only needed to compile frameless override in 10.4.dbr -->
        <dependency>
            <groupId>eu.timepit</groupId>
            <artifactId>refined_${scalaCompatVersion}</artifactId>
            <version>${refinedVersion}</version>
            <scope>provided</scope>
        </dependency>

        <!-- databricks runtime version is chosen to ease deployment there -->
        <dependency>
            <groupId>org.scala-lang.modules</groupId>
            <artifactId>scala-parser-combinators_${scalaCompatVersion}</artifactId>
            <version>${parserCombinatorVersion}</version>
        </dependency>

        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-compiler</artifactId>
            <version>${scalaVersion}</version>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>io.delta</groupId>
            <artifactId>delta-${deltaArtifact}_${scalaCompatVersion}</artifactId>
            <version>${deltaCoreVersion}</version>
            <scope>provided</scope> <!-- must be provided as there is no provided test, triggers antlr version issues -->
            <exclusions>
                <!-- let hive drive the version used, allows Spark 4 tests to run -->
                <exclusion>
                    <groupId>org.antlr</groupId>
                    <artifactId>antlr4-runtime</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>com.chuusai</groupId>
            <artifactId>shapeless_${scalaCompatVersion}</artifactId>
            <version>${shapelessVersion}</version>
        </dependency>

        <dependency>
            <groupId>${scalaMeterGroup}</groupId>
            <artifactId>${scalaMeterArtifact}_${scalaCompatVersion}</artifactId>
            <version>${scalaMeterVersion}</version>
            <scope>test</scope>
            <exclusions>
                <exclusion>
                    <groupId>org.mongodb</groupId>
                    <artifactId>casbah_${scalaCompatVersion}</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <!--
        <dependency>
            <groupId>com.storm-enroute</groupId>
            <artifactId>scalameter_${scalaCompatVersion}</artifactId>
            <version>${scalaMeterVersion}</version>
            <scope>test</scope>
            <exclusions>
                <exclusion>
                    <groupId>org.mongodb</groupId>
                    <artifactId>casbah_${scalaCompatVersion}</artifactId>
                </exclusion>
            </exclusions>
        </dependency> -->

        <!-- needed for scalameter to run, no idea why it doesn't include it, also the version must be locked down -->
        <dependency>
            <groupId>com.fasterxml.jackson.module</groupId>
            <artifactId>jackson-module-scala_${scalaCompatVersion}</artifactId>
            <version>${jacksonVersion}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
            <version>${jacksonVersion}</version>
            <scope>provided</scope>
        </dependency>

        <!-- Databricks packages this, oss does not -->
        <dependency>
            <groupId>org.yaml</groupId>
            <artifactId>snakeyaml</artifactId>
            <version>${snakeVersion}</version>
            <scope>${snakeScope}</scope>
        </dependency>

        <dependency>
            <groupId>org.scala-lang.modules</groupId>
            <artifactId>scala-collection-compat_${scalaCompatVersion}</artifactId>
            <version>${scalaCollectionCompatVersion}</version>
        </dependency>

    </dependencies>

    <build>

        <testResources>
            <testResource>
                <directory>src/test/resources</directory>
                <filtering>true</filtering>
            </testResource>
        </testResources>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>${mavenCompilerPluginVersion}</version>
                <configuration>
                    <source>8</source>
                    <target>8</target>
                </configuration>
            </plugin>

            <plugin>
                <groupId>org.codehaus.mojo</groupId>
                <artifactId>build-helper-maven-plugin</artifactId>
                <version>3.2.0</version>
                <executions>
                    <execution>
                        <id>add-source</id>
                        <phase>generate-sources</phase>
                        <goals>
                            <goal>add-source</goal>
                        </goals>
                        <configuration>
                            <sources>
                                <source>src/main/scala</source>
                                <source>src/main/${profileDir}-scala</source>
                                <source>${project.build.directory}/shim_compilation_${shimCompilationRuntime}_${sparkCompatVersion}_${scalaCompatVersion}</source>
                            </sources>
                        </configuration>
                    </execution>
                    <execution>
                        <id>for-scaladocs-etc</id>
                        <phase>pre-site</phase>
                        <goals>
                            <goal>add-source</goal>
                        </goals>
                        <configuration>
                            <sources>
                                <source>src/main/scala</source>
                                <source>src/main/${profileDir}-scala</source>
                            </sources>
                        </configuration>
                    </execution>
                    <execution>
                        <id>add-test-source</id>
                        <phase>generate-test-sources</phase>
                        <goals>
                            <goal>add-test-source</goal>
                        </goals>
                        <configuration>
                            <sources>
                                <source>src/test/scala</source>
                                <source>src/test/${profileDir}-scala</source>
                            </sources>
                        </configuration>
                    </execution>
                </executions>
            </plugin>

            <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
                <version>${scalaCompilerPluginVersion}</version>
                <executions>
                    <execution>
                        <id>scala-compile</id>
                        <goals>
                            <goal>compile</goal>
                            <goal>testCompile</goal>
                        </goals>
                        <configuration>
                            <args>
                                <arg>-feature</arg>
                                <arg>-deprecation</arg>
                                <arg>-Xelide-below</arg>
                                <arg>${elidebelow}</arg>
                                <arg>-dependencyfile</arg>
                                <arg>${project.build.directory}/.scala_dependencies</arg>
                                <arg>-g:vars</arg>
                                <!-- <arg>-Ylog-classpath</arg> -->
							</args>
                            <recompileMode>all</recompileMode>
                            <scalaCompatVersion>${scalaCompatVersion}</scalaCompatVersion>
                        </configuration>
                    </execution>
                    <execution>
                        <id>attach-javadocs</id>
                        <goals>
                            <goal>doc-jar</goal>
                        </goals>
                    </execution>
                    <execution>
                        <id>attach-sources</id>
                        <goals>
                            <goal>add-source</goal>
                        </goals>
                    </execution>
                    <!-- <execution>
                        <id>scala-compile-first</id>
                        <phase>process-resources</phase>
                        <goals>
                            <goal>add-source</goal>
                            <goal>compile</goal>
                        </goals>
                    </execution>
                    <execution>
                        <id>scala-test-compile</id>
                        <phase>process-test-resources</phase>
                        <goals>
                            <goal>testCompile</goal>
                        </goals>
                    </execution> -->
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-site-plugin</artifactId>
                <version>${mavenSitePluginVersion}</version>
            </plugin>


            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-dependency-plugin</artifactId>
                <version>${dependencyPluginVersion}</version>
                <executions> <!-- maven scala plugin uses a set to store classpath, it doesn't follow maven's so we need to use the source -->
                    <execution>
                        <id>unpack</id>
                        <phase>initialize</phase>
                        <goals>
                            <goal>unpack</goal>
                        </goals>
                        <configuration>
                            <artifactItems>
                                <artifactItem>
                                    <groupId>com.sparkutils</groupId>
                                    <artifactId>shim_compilation_${shimCompilationRuntime}_${sparkCompatVersion}_${scalaCompatVersion}</artifactId>
                                    <version>${shimCompilationVersion}</version>

                                    <classifier>sources</classifier>
                                    <type>jar</type>

                                    <overWrite>true</overWrite>
                                    <outputDirectory>${project.build.directory}/shim_compilation_${shimCompilationRuntime}_${sparkCompatVersion}_${scalaCompatVersion}</outputDirectory>
                                </artifactItem>
                            </artifactItems>
                        </configuration>
                    </execution>
                </executions>
            </plugin>

            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <version>${surefirePluginVersion}</version>
                <configuration>
                    <forkCount>1</forkCount>
                    <reuseForks>false</reuseForks>
                    <argLine>-Xmx4g -ea -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED</argLine>
                    <systemPropertyVariables>
                        <org.xerial.snappy.tempdir>${java.io.tmpdir}/teamcity/megdp/extrajars</org.xerial.snappy.tempdir>
                        <buildDirectory>${project.build.directory}</buildDirectory>
                    </systemPropertyVariables>
                </configuration>
            </plugin>

            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-project-info-reports-plugin</artifactId>
                <version>${mavenProjectInfoReportsPluginVersion}</version>
            </plugin>

            <plugin>
                <groupId>org.scoverage</groupId>
                <artifactId>scoverage-maven-plugin</artifactId>
                <version>${scoverage.plugin.version}</version>
                <configuration>
                    <scalaVersion>${scalaVersion}</scalaVersion>
                    <!-- compat layer is tested via the normal code,
                         only pre-resolution plans are anywhere near test worthy -->
                    <excludedPackages>org.apache.spark.sql</excludedPackages>
                    <aggregate>true</aggregate>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-jar-plugin</artifactId>
                <version>${mavenJarPluginVersion}</version>
                <configuration>
                    <archive>
                        <manifestEntries>
                            <Build-Time>${maven.build.timestamp}</Build-Time>
                        </manifestEntries>
                        <manifestSections>
                            <manifestSection>
                                <name>Versions</name>
                                <manifestEntries>
                                    <Project-Version>${project.version}</Project-Version>
                                    <Project-Git-Hash>${GITHUB_SHA}</Project-Git-Hash>
                                    <Project-CI-Branch>${GITHUB_BASE_REF}</Project-CI-Branch>
                                    <Project-CI-Run-ID>${GITHUB_RUN_ID}</Project-CI-Run-ID>
                                    <Project-URL>${GITHUB_REPOSITORY}</Project-URL>
                                </manifestEntries>
                            </manifestSection>
                        </manifestSections>
                    </archive>
                    <includes>
                        <include>org/apache/spark/sql/catalyst/expressions/codegen/Quality**</include>
                        <include>org/apache/spark/sql/Quality**</include>
                        <include>org/apache/spark/sql/qualityFunctions/**</include>
                        <include>com/sparkutils/**</include>
                    </includes>
                    <excludes>
                        <!-- many dbr requires faking the source, we should not include the output
                        <exclude>org/apache/spark/sql/execution/**</exclude>
                        <exclude>org/apache/spark/sql/catalyst/**</exclude>
                        <exclude>org/apache/spark/sql/internal/**</exclude>-->
                        <!-- shouldn't be there, really bad for multi-module projects -->
                        <exclude>log4j2.xml</exclude>
                    </excludes>
                </configuration>
                <executions>
                    <execution>
                        <goals>
                            <goal>test-jar</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.codehaus.mojo</groupId>
                <artifactId>flatten-maven-plugin</artifactId>
                <version>${mavenFlattenPluginVersion}</version>
                <configuration>
                    <flattenMode>oss</flattenMode>
                </configuration>
                <executions>
                    <!-- enable flattening -->
                    <execution>
                        <id>flatten</id>
                        <phase>process-resources</phase>
                        <goals>
                            <goal>flatten</goal>
                        </goals>
                    </execution>
                    <!-- ensure proper cleanup -->
                    <execution>
                        <id>flatten.clean</id>
                        <phase>clean</phase>
                        <goals>
                            <goal>clean</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-gpg-plugin</artifactId>
                <version>3.0.1</version>
                <executions>
                    <execution>
                        <id>sign-artifacts</id>
                        <phase>verify</phase>
                        <goals>
                            <goal>sign</goal>
                        </goals>
                        <configuration>
                            <!-- Prevent gpg from using pinentry programs -->
                            <gpgArguments>
                                <arg>--pinentry-mode</arg>
                                <arg>loopback</arg>
                            </gpgArguments>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-source-plugin</artifactId>
                <version>2.2.1</version>
                <executions>
                    <execution>
                        <id>attach-sources</id>
                        <goals>
                            <goal>jar-no-fork</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.sonatype.plugins</groupId>
                <artifactId>nexus-staging-maven-plugin</artifactId>
                <version>1.6.13</version>
                <extensions>true</extensions>
                <configuration>
                    <serverId>ossrh</serverId>
                    <nexusUrl>https://s01.oss.sonatype.org/</nexusUrl>
                    <autoReleaseAfterClose>true</autoReleaseAfterClose>
                    <stagingProgressTimeoutMinutes>45</stagingProgressTimeoutMinutes>
                </configuration>
            </plugin>
        </plugins>

    </build>
    <reporting>
        <excludeDefaults>true</excludeDefaults>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-report-plugin</artifactId>
                <version>${surefireReportPluginVersion}</version>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-project-info-reports-plugin</artifactId>
                <version>${mavenProjectInfoReportsVersion}</version>
            </plugin>
            <plugin>
                <groupId>org.scoverage</groupId>
                <artifactId>scoverage-maven-plugin</artifactId>
                <version>${scoverage.plugin.version}</version>
                <reportSets>
                    <reportSet>
                        <reports>
                            <report>report-only</report>
                        </reports>
                    </reportSet>
                </reportSets>
                <configuration>
                    <!-- <aggregate>true</aggregate> -->
                    <aggregateOnly>true</aggregateOnly>
                </configuration>
             </plugin>
             <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
                <version>${scalaCompilerPluginVersion}</version>
				<configuration>
					<args>
						<arg>-diagrams</arg>
						<arg>-diagrams-debug</arg>
						<arg>-diagrams-dot-timeout</arg>
						<arg>40</arg> <!-- default is 10s and it may not be enough, the basic things which have issue _ARE_ rendering -->
						<arg>-diagrams-dot-path</arg>
						<arg>./dott</arg>
						<!-- <arg>-diagrams-dot-restart</arg>
						<arg>40</arg> default is 5 the error is not stopped it just makes the build last for ever -->
					</args>
				</configuration>
            </plugin>
        </plugins>
    </reporting>
</project>
