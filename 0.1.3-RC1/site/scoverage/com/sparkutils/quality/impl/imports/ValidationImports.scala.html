<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/impl/imports/ValidationImports.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality.impl.imports
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality.impl.{ExpressionLookup, RuleError, RuleWarning, ShowParams, Validation}
</span>4 <span style=''>import com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither
</span>5 <span style=''>import com.sparkutils.quality.RuleSuite
</span>6 <span style=''>import com.sparkutils.quality.impl.util.RuleSuiteDocs
</span>7 <span style=''>import org.apache.spark.sql.types.StructType
</span>8 <span style=''>import org.apache.spark.sql.{Column, DataFrame}
</span>9 <span style=''>
</span>10 <span style=''>trait ValidationImports {
</span>11 <span style=''>
</span>12 <span style=''>  /**
</span>13 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>14 <span style=''>   *
</span>15 <span style=''>   * @param schema which fields should the dataframe have
</span>16 <span style=''>   * @param ruleSuite
</span>17 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>18 <span style=''>   */
</span>19 <span style=''>  def validate_Lookup(schema: StructType, ruleSuite: RuleSuite, viewLookup: String =&gt; Boolean): (Set[RuleError], Set[RuleWarning]) = {
</span>20 <span style=''>    val (err, warns, out, docs, exp) = validate(Left(schema), ruleSuite, viewLookup = viewLookup)
</span>21 <span style=''>    </span><span style='background: #AEF1AE'>(err, warns)</span><span style=''>
</span>22 <span style=''>  }
</span>23 <span style=''>
</span>24 <span style=''>  /**
</span>25 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>26 <span style=''>   *
</span>27 <span style=''>   * @param schema which fields should the dataframe have
</span>28 <span style=''>   * @param ruleSuite
</span>29 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>30 <span style=''>   */
</span>31 <span style=''>  def validate(schema: StructType, ruleSuite: RuleSuite): (Set[RuleError], Set[RuleWarning]) = {
</span>32 <span style=''>    val (err, warns, out, docs, exp) = validate(Left(schema), ruleSuite)
</span>33 <span style=''>    </span><span style='background: #AEF1AE'>(err, warns)</span><span style=''>
</span>34 <span style=''>  }
</span>35 <span style=''>
</span>36 <span style=''>  /**
</span>37 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>38 <span style=''>   *
</span>39 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>40 <span style=''>   * @param ruleSuite
</span>41 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>42 <span style=''>   */
</span>43 <span style=''>  def validate_Lookup(frame: DataFrame, ruleSuite: RuleSuite, viewLookup: String =&gt; Boolean = Validation.defaultViewLookup): (Set[RuleError], Set[RuleWarning]) = {
</span>44 <span style=''>    val (err, warns, out, docs, exp) = validate(Right(frame), ruleSuite, viewLookup = viewLookup)
</span>45 <span style=''>    </span><span style='background: #AEF1AE'>(err, warns)</span><span style=''>
</span>46 <span style=''>  }
</span>47 <span style=''>
</span>48 <span style=''>  /**
</span>49 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>50 <span style=''>   *
</span>51 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>52 <span style=''>   * @param ruleSuite
</span>53 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>54 <span style=''>   */
</span>55 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite): (Set[RuleError], Set[RuleWarning]) = {
</span>56 <span style=''>    val (err, warns, out, docs, exp) = validate(Right(frame), ruleSuite)
</span>57 <span style=''>    </span><span style='background: #AEF1AE'>(err, warns)</span><span style=''>
</span>58 <span style=''>  }
</span>59 <span style=''>
</span>60 <span style=''>  /**
</span>61 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>62 <span style=''>   *
</span>63 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>64 <span style=''>   * @param ruleSuite
</span>65 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>66 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>67 <span style=''>   *
</span>68 <span style=''>   */
</span>69 <span style=''>  def validate_Lookup(frame: DataFrame, ruleSuite: RuleSuite, runnerFunction: DataFrame =&gt; Column, viewLookup: String =&gt; Boolean): (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) =
</span>70 <span style=''>    </span><span style='background: #AEF1AE'>validate(</span><span style='background: #F0ADAD'>Right(frame)</span><span style='background: #AEF1AE'>, ruleSuite, runnerFunction = </span><span style='background: #F0ADAD'>Some(runnerFunction)</span><span style='background: #AEF1AE'>, viewLookup = viewLookup)</span><span style=''>
</span>71 <span style=''>
</span>72 <span style=''>
</span>73 <span style=''>  /**
</span>74 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>75 <span style=''>   *
</span>76 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>77 <span style=''>   * @param ruleSuite
</span>78 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>79 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>80 <span style=''>   */
</span>81 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite, runnerFunction: DataFrame =&gt; Column): (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) =
</span>82 <span style=''>    </span><span style='background: #AEF1AE'>validate(Right(frame), ruleSuite, runnerFunction = Some(runnerFunction))</span><span style=''>
</span>83 <span style=''>
</span>84 <span style=''>  /**
</span>85 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>86 <span style=''>   *
</span>87 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>88 <span style=''>   * @param ruleSuite
</span>89 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>90 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>91 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>92 <span style=''>   */
</span>93 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite, runnerFunction: DataFrame =&gt; Column, transformBeforeShow: DataFrame =&gt; DataFrame, viewLookup: String =&gt; Boolean): (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) =
</span>94 <span style=''>    </span><span style='background: #AEF1AE'>validate(</span><span style='background: #F0ADAD'>Right(frame)</span><span style='background: #AEF1AE'>, ruleSuite, runnerFunction = </span><span style='background: #F0ADAD'>Some(runnerFunction)</span><span style='background: #AEF1AE'>, transformBeforeShow = transformBeforeShow, viewLookup = viewLookup)</span><span style=''>
</span>95 <span style=''>
</span>96 <span style=''>  /**
</span>97 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>98 <span style=''>   *
</span>99 <span style=''>   * @param frame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>100 <span style=''>   * @param ruleSuite
</span>101 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>102 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>103 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>104 <span style=''>   */
</span>105 <span style=''>  def validate(frame: DataFrame, ruleSuite: RuleSuite, runnerFunction: DataFrame =&gt; Column, transformBeforeShow: DataFrame =&gt; DataFrame): (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) =
</span>106 <span style=''>    </span><span style='background: #AEF1AE'>validate(Right(frame), ruleSuite, runnerFunction = Some(runnerFunction), transformBeforeShow = transformBeforeShow)</span><span style=''>
</span>107 <span style=''>
</span>108 <span style=''>  /**
</span>109 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>110 <span style=''>   *
</span>111 <span style=''>   * @param schemaOrFrame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>112 <span style=''>   * @param ruleSuite
</span>113 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>114 <span style=''>   * @param showParams - configure how the output text is formatted using the same options and formatting as dataFrame.show
</span>115 <span style=''>   * @param qualityName - the column name to store the runnerFunction results in
</span>116 <span style=''>   * @param recursiveLambdasSOEIsOk - this signals that finding a recursive lambda SOE should not stop the evaluations - if true it will still try to run any runnerFunction but may not give the correct results
</span>117 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>118 <span style=''>   * @param viewLookup - for any subquery used looks up the view name for being present (quoted and with schema), defaults to the current spark catalogue
</span>119 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>120 <span style=''>   */
</span>121 <span style=''>  def validate(schemaOrFrame: Either[StructType, DataFrame], ruleSuite: RuleSuite, showParams: ShowParams = ShowParams(),
</span>122 <span style=''>               runnerFunction: Option[DataFrame =&gt; Column] = None, qualityName: String = &quot;Quality&quot;,
</span>123 <span style=''>               recursiveLambdasSOEIsOk: Boolean = false, transformBeforeShow: DataFrame =&gt; DataFrame = identity, viewLookup: String =&gt; Boolean = Validation.defaultViewLookup):
</span>124 <span style=''>  (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) = </span><span style='background: #AEF1AE'>Validation.validate(
</span>125 <span style=''></span><span style='background: #AEF1AE'>    schemaOrFrame, ruleSuite, showParams, runnerFunction, qualityName,
</span>126 <span style=''></span><span style='background: #AEF1AE'>    recursiveLambdasSOEIsOk, transformBeforeShow, viewLookup
</span>127 <span style=''></span><span style='background: #AEF1AE'>  )</span><span style=''>
</span>128 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          5980
        </td>
        <td>
          860
          -
          860
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1._1
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          5983
        </td>
        <td>
          877
          -
          877
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1._4
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          5982
        </td>
        <td>
          872
          -
          872
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1._3
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          5981
        </td>
        <td>
          865
          -
          865
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1._2
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          5984
        </td>
        <td>
          883
          -
          883
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1._5
        </td>
      </tr><tr>
        <td>
          21
        </td>
        <td>
          5985
        </td>
        <td>
          953
          -
          965
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning]](err, warns)
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          5987
        </td>
        <td>
          1371
          -
          1371
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._2
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          5986
        </td>
        <td>
          1366
          -
          1366
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._1
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          5989
        </td>
        <td>
          1383
          -
          1383
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._4
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          5988
        </td>
        <td>
          1378
          -
          1378
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._3
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          5990
        </td>
        <td>
          1389
          -
          1389
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2._5
        </td>
      </tr><tr>
        <td>
          33
        </td>
        <td>
          5991
        </td>
        <td>
          1434
          -
          1446
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning]](err, warns)
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          5995
        </td>
        <td>
          2149
          -
          2149
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$3._4
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          5992
        </td>
        <td>
          2132
          -
          2132
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$3._1
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          5994
        </td>
        <td>
          2144
          -
          2144
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$3._3
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          5996
        </td>
        <td>
          2155
          -
          2155
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$3._5
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          5993
        </td>
        <td>
          2137
          -
          2137
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$3._2
        </td>
      </tr><tr>
        <td>
          45
        </td>
        <td>
          5997
        </td>
        <td>
          2225
          -
          2237
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning]](err, warns)
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          5998
        </td>
        <td>
          2854
          -
          2854
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._1
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          6001
        </td>
        <td>
          2871
          -
          2871
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._4
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          6000
        </td>
        <td>
          2866
          -
          2866
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._3
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          5999
        </td>
        <td>
          2859
          -
          2859
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._2
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          6002
        </td>
        <td>
          2877
          -
          2877
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._5
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          6003
        </td>
        <td>
          2922
          -
          2934
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning]](err, warns)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          6004
        </td>
        <td>
          3804
          -
          3816
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Right.apply[Nothing, org.apache.spark.sql.DataFrame](frame)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          6007
        </td>
        <td>
          3795
          -
          3795
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ValidationImports.this.validate$default$5
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          6010
        </td>
        <td>
          3795
          -
          3892
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate(x$1, x$2, x$5, x$3, x$6, x$7, x$8, x$4)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          6009
        </td>
        <td>
          3795
          -
          3795
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$7
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ValidationImports.this.validate$default$7
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          6006
        </td>
        <td>
          3795
          -
          3795
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ValidationImports.this.validate$default$3
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          6005
        </td>
        <td>
          3846
          -
          3866
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[org.apache.spark.sql.DataFrame =&gt; org.apache.spark.sql.Column](runnerFunction)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          6008
        </td>
        <td>
          3795
          -
          3795
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$6
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ValidationImports.this.validate$default$6
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          6013
        </td>
        <td>
          4707
          -
          4707
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate$default$3
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          6016
        </td>
        <td>
          4707
          -
          4707
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$7
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate$default$7
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          6018
        </td>
        <td>
          4707
          -
          4779
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate(x$1, x$2, x$4, x$3, x$5, x$6, x$7, x$8)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          6012
        </td>
        <td>
          4758
          -
          4778
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[org.apache.spark.sql.DataFrame =&gt; org.apache.spark.sql.Column](runnerFunction)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          6015
        </td>
        <td>
          4707
          -
          4707
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate$default$6
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          6014
        </td>
        <td>
          4707
          -
          4707
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate$default$5
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          6017
        </td>
        <td>
          4707
          -
          4707
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$8
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate$default$8
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          6011
        </td>
        <td>
          4716
          -
          4728
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, org.apache.spark.sql.DataFrame](frame)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          6019
        </td>
        <td>
          5794
          -
          5806
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Right.apply[Nothing, org.apache.spark.sql.DataFrame](frame)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          6022
        </td>
        <td>
          5785
          -
          5785
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ValidationImports.this.validate$default$5
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          6021
        </td>
        <td>
          5785
          -
          5785
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ValidationImports.this.validate$default$3
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          6024
        </td>
        <td>
          5785
          -
          5925
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate(x$1, x$2, x$6, x$3, x$7, x$8, x$4, x$5)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          6023
        </td>
        <td>
          5785
          -
          5785
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$6
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ValidationImports.this.validate$default$6
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          6020
        </td>
        <td>
          5836
          -
          5856
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[org.apache.spark.sql.DataFrame =&gt; org.apache.spark.sql.Column](runnerFunction)
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          6028
        </td>
        <td>
          6900
          -
          6900
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate$default$5
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          6031
        </td>
        <td>
          6900
          -
          7015
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate(x$1, x$2, x$5, x$3, x$6, x$7, x$4, x$8)
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          6025
        </td>
        <td>
          6909
          -
          6921
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, org.apache.spark.sql.DataFrame](frame)
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          6027
        </td>
        <td>
          6900
          -
          6900
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate$default$3
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          6030
        </td>
        <td>
          6900
          -
          6900
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$8
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate$default$8
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          6026
        </td>
        <td>
          6951
          -
          6971
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[org.apache.spark.sql.DataFrame =&gt; org.apache.spark.sql.Column](runnerFunction)
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          6029
        </td>
        <td>
          6900
          -
          6900
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.imports.ValidationImports.validate$default$6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ValidationImports.this.validate$default$6
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          6032
        </td>
        <td>
          8825
          -
          8981
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validate
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.Validation.validate(schemaOrFrame, ruleSuite, showParams, runnerFunction, qualityName, recursiveLambdasSOEIsOk, transformBeforeShow, viewLookup)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>