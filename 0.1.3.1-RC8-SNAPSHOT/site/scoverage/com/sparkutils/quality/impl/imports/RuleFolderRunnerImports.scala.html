<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/impl/imports/RuleFolderRunnerImports.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality.impl.imports
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality.RuleSuite
</span>4 <span style=''>import com.sparkutils.quality.impl.RuleEngineRunnerUtils.flattenExpressions
</span>5 <span style=''>import com.sparkutils.quality.impl.{RuleFolderRunner, RuleFolderRunnerEval, RuleLogicUtils}
</span>6 <span style=''>import com.sparkutils.quality.impl.util.{NonPassThrough, PassThroughCompileEvals, PassThroughEvalOnly}
</span>7 <span style=''>import org.apache.spark.sql.ShimUtils.{column, expression}
</span>8 <span style=''>import org.apache.spark.sql.catalyst.expressions.Expression
</span>9 <span style=''>import org.apache.spark.sql.qualityFunctions.{FunN, RefExpressionLazyType}
</span>10 <span style=''>import org.apache.spark.sql.types._
</span>11 <span style=''>import org.apache.spark.sql.{Column, DataFrame, QualitySparkUtils}
</span>12 <span style=''>
</span>13 <span style=''>import java.util.concurrent.atomic.AtomicReference
</span>14 <span style=''>
</span>15 <span style=''>trait RuleFolderRunnerImports {
</span>16 <span style=''>
</span>17 <span style=''>  /**
</span>18 <span style=''>   * Creates a column that runs the folding RuleSuite.  This also forces registering the lambda functions used by that RuleSuite.
</span>19 <span style=''>   *
</span>20 <span style=''>   * FolderRunner runs all output expressions for matching rules in order of salience, the startingStruct is passed ot the first
</span>21 <span style=''>   * matching, the result passed to the second etc.  In contrast to ruleEngineRunner OutputExpressions should be lambdas with one parameter, that of the structure
</span>22 <span style=''>   *
</span>23 <span style=''>   * @param ruleSuite The ruleSuite with runOnPassProcessors
</span>24 <span style=''>   * @param startingStruct This struct is passed to the first matching rule, ideally you would use the spark dsl struct function to refer to existing columns
</span>25 <span style=''>   * @param compileEvals Should the rules be compiled out to interim objects - by default false, allowing optimisations
</span>26 <span style=''>   * @param debugMode When debugMode is enabled the resultDataType is wrapped in Array of (salience, result) pairs to ease debugging
</span>27 <span style=''>   * @param resolveWith This experimental parameter can take the DataFrame these rules will be added to and pre-resolve and optimise the sql expressions, see the documentation for details on when to and not to use this.
</span>28 <span style=''>   * @param variablesPerFunc Defaulting to 40 allows, in combination with variableFuncGroup allows customisation of handling the 64k jvm method size limitation when performing WholeStageCodeGen
</span>29 <span style=''>   * @param variableFuncGroup Defaulting to 20
</span>30 <span style=''>   * @param forceRunnerEval Defaulting to false, passing true forces a simplified partially interpreted evaluation (compileEvals must be false to get fully interpreted)
</span>31 <span style=''>   * @param forceTriggerEval Defaulting to false, passing true forces each trigger expression to be compiled (compileEvals) and used in place, false instead expands the trigger in-line giving possible performance boosts based on JIT
</span>32 <span style=''>   * @param useType In the case you must use select and can't use withColumn you may provide a type directly to stop the NPE
</span>33 <span style=''>   * @return A Column representing the QualityRules expression built from this ruleSuite
</span>34 <span style=''>   */
</span>35 <span style=''>  def ruleFolderRunner(ruleSuite: RuleSuite, startingStruct: Column, compileEvals: Boolean = false,
</span>36 <span style=''>                       debugMode: Boolean = false, resolveWith: Option[DataFrame] = None, variablesPerFunc: Int = 40,
</span>37 <span style=''>                       variableFuncGroup: Int = 20, forceRunnerEval: Boolean = false, useType: Option[StructType] = None,
</span>38 <span style=''>                       forceTriggerEval: Boolean = false): Column = {
</span>39 <span style=''>    </span><span style='background: #AEF1AE'>com.sparkutils.quality.registerLambdaFunctions( ruleSuite.lambdaFunctions )</span><span style=''>
</span>40 <span style=''>
</span>41 <span style=''>    // needed to resolve variables
</span>42 <span style=''>    val dataRef = </span><span style='background: #AEF1AE'>new AtomicReference[DataType]()</span><span style=''>
</span>43 <span style=''>
</span>44 <span style=''>    val realType = () =&gt; {
</span>45 <span style=''>      val starter =
</span>46 <span style=''>        </span><span style='background: #AEF1AE'>useType.getOrElse(dataRef.get())</span><span style=''>
</span>47 <span style=''>      if (debugMode)
</span>48 <span style=''>      // wrap it in an array with the priority result
</span>49 <span style=''>        </span><span style='background: #AEF1AE'>ArrayType(StructType(Seq(StructField(&quot;salience&quot;, IntegerType), StructField(&quot;result&quot;, starter))))</span><span style=''>
</span>50 <span style=''>      else
</span>51 <span style=''>        </span><span style='background: #AEF1AE'>starter</span><span style=''>
</span>52 <span style=''>    }
</span>53 <span style=''>
</span>54 <span style=''>    val lazyRef = </span><span style='background: #AEF1AE'>RefExpressionLazyType(dataRef, true)</span><span style=''>
</span>55 <span style=''>
</span>56 <span style=''>    val liftLambda = (e: Expression) =&gt; </span><span style='background: #AEF1AE'>FunN(Seq(lazyRef), e, usedAsLambda = true)</span><span style=''>
</span>57 <span style=''>
</span>58 <span style=''>    val (expressions, indexes) = flattenExpressions(ruleSuite, liftLambda)
</span>59 <span style=''>
</span>60 <span style=''>    val cleaed = </span><span style='background: #AEF1AE'>RuleLogicUtils.cleanExprs(ruleSuite)</span><span style=''>
</span>61 <span style=''>    val starter = </span><span style='background: #AEF1AE'>expression(startingStruct)</span><span style=''>
</span>62 <span style=''>    val exprs =
</span>63 <span style=''>      // ExpressionProxy and SubExprEvaluationRuntime cannot be used with compileEvals
</span>64 <span style=''>      if (compileEvals)
</span>65 <span style=''>        </span><span style='background: #AEF1AE'>PassThroughCompileEvals(expressions)</span><span style=''>
</span>66 <span style=''>      else
</span>67 <span style=''>        </span><span style='background: #AEF1AE'>PassThroughEvalOnly(expressions)</span><span style=''>
</span>68 <span style=''>
</span>69 <span style=''>    val runner =
</span>70 <span style=''>      if (</span><span style='background: #AEF1AE'>forceRunnerEval || resolveWith.isDefined</span><span style=''>)
</span>71 <span style=''>        </span><span style='background: #AEF1AE'>new RuleFolderRunnerEval(cleaed, starter, exprs,
</span>72 <span style=''></span><span style='background: #AEF1AE'>          realType, compileEvals = compileEvals,
</span>73 <span style=''></span><span style='background: #AEF1AE'>          debugMode = debugMode, variablesPerFunc, variableFuncGroup,
</span>74 <span style=''></span><span style='background: #AEF1AE'>          expressionOffsets = indexes, dataRef, forceTriggerEval)</span><span style=''>
</span>75 <span style=''>      else
</span>76 <span style=''>        </span><span style='background: #AEF1AE'>new RuleFolderRunner(cleaed, starter, exprs,
</span>77 <span style=''></span><span style='background: #AEF1AE'>          realType, compileEvals = compileEvals,
</span>78 <span style=''></span><span style='background: #AEF1AE'>          debugMode = debugMode, variablesPerFunc, variableFuncGroup,
</span>79 <span style=''></span><span style='background: #AEF1AE'>          expressionOffsets = indexes, dataRef, forceTriggerEval)</span><span style=''>
</span>80 <span style=''>
</span>81 <span style=''>    </span><span style='background: #AEF1AE'>column(
</span>82 <span style=''></span><span style='background: #AEF1AE'>      QualitySparkUtils.resolveWithOverride(resolveWith).map { df =&gt;
</span>83 <span style=''></span><span style='background: #AEF1AE'>        val resolved = QualitySparkUtils.resolveExpression(df, runner)
</span>84 <span style=''></span><span style='background: #AEF1AE'>
</span>85 <span style=''></span><span style='background: #AEF1AE'>        resolved.withNewChildren(Seq(runner.left, resolved.children.head match {
</span>86 <span style=''></span><span style='background: #AEF1AE'>          // replace the expr
</span>87 <span style=''></span><span style='background: #AEF1AE'>          case PassThroughCompileEvals(children) =&gt; NonPassThrough(children)
</span>88 <span style=''></span><span style='background: #AEF1AE'>          case PassThroughEvalOnly(children) =&gt; NonPassThrough(children)
</span>89 <span style=''></span><span style='background: #AEF1AE'>        }))
</span>90 <span style=''></span><span style='background: #AEF1AE'>      } getOrElse runner
</span>91 <span style=''></span><span style='background: #AEF1AE'>    )</span><span style=''>
</span>92 <span style=''>  }
</span>93 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          6301
        </td>
        <td>
          3194
          -
          3219
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.RuleSuite.lambdaFunctions
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.lambdaFunctions
        </td>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          6302
        </td>
        <td>
          3146
          -
          3221
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.imports.LambdaFunctionsImports.registerLambdaFunctions
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.registerLambdaFunctions(ruleSuite.lambdaFunctions)
        </td>
      </tr><tr>
        <td>
          42
        </td>
        <td>
          6303
        </td>
        <td>
          3276
          -
          3307
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.concurrent.atomic.AtomicReference.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.concurrent.atomic.AtomicReference[org.apache.spark.sql.types.DataType]()
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          6305
        </td>
        <td>
          3364
          -
          3396
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          useType.getOrElse[org.apache.spark.sql.types.DataType](dataRef.get())
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          6304
        </td>
        <td>
          3382
          -
          3395
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.concurrent.atomic.AtomicReference.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          dataRef.get()
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6310
        </td>
        <td>
          3505
          -
          3541
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.types.StructField.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.StructField.apply(&quot;salience&quot;, org.apache.spark.sql.types.IntegerType, org.apache.spark.sql.types.StructField.apply$default$3, org.apache.spark.sql.types.StructField.apply$default$4)
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6318
        </td>
        <td>
          3480
          -
          3576
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.spark.sql.types.ArrayType.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.ArrayType.apply(org.apache.spark.sql.types.StructType.apply(scala.collection.Seq.apply[org.apache.spark.sql.types.StructField](org.apache.spark.sql.types.StructField.apply(&quot;salience&quot;, org.apache.spark.sql.types.IntegerType, org.apache.spark.sql.types.StructField.apply$default$3, org.apache.spark.sql.types.StructField.apply$default$4), org.apache.spark.sql.types.StructField.apply(&quot;result&quot;, starter, org.apache.spark.sql.types.StructField.apply$default$3, org.apache.spark.sql.types.StructField.apply$default$4))))
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6309
        </td>
        <td>
          3505
          -
          3505
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StructField.apply$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.StructField.apply$default$4
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6312
        </td>
        <td>
          3543
          -
          3543
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StructField.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.StructField.apply$default$3
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6306
        </td>
        <td>
          3517
          -
          3527
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;salience&quot;
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6315
        </td>
        <td>
          3501
          -
          3574
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.apply[org.apache.spark.sql.types.StructField](org.apache.spark.sql.types.StructField.apply(&quot;salience&quot;, org.apache.spark.sql.types.IntegerType, org.apache.spark.sql.types.StructField.apply$default$3, org.apache.spark.sql.types.StructField.apply$default$4), org.apache.spark.sql.types.StructField.apply(&quot;result&quot;, starter, org.apache.spark.sql.types.StructField.apply$default$3, org.apache.spark.sql.types.StructField.apply$default$4))
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6314
        </td>
        <td>
          3543
          -
          3573
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.types.StructField.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.StructField.apply(&quot;result&quot;, starter, org.apache.spark.sql.types.StructField.apply$default$3, org.apache.spark.sql.types.StructField.apply$default$4)
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6308
        </td>
        <td>
          3505
          -
          3505
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StructField.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.StructField.apply$default$3
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6317
        </td>
        <td>
          3480
          -
          3576
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.types.ArrayType.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.ArrayType.apply(org.apache.spark.sql.types.StructType.apply(scala.collection.Seq.apply[org.apache.spark.sql.types.StructField](org.apache.spark.sql.types.StructField.apply(&quot;salience&quot;, org.apache.spark.sql.types.IntegerType, org.apache.spark.sql.types.StructField.apply$default$3, org.apache.spark.sql.types.StructField.apply$default$4), org.apache.spark.sql.types.StructField.apply(&quot;result&quot;, starter, org.apache.spark.sql.types.StructField.apply$default$3, org.apache.spark.sql.types.StructField.apply$default$4))))
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6311
        </td>
        <td>
          3555
          -
          3563
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;result&quot;
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6313
        </td>
        <td>
          3543
          -
          3543
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StructField.apply$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.StructField.apply$default$4
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6307
        </td>
        <td>
          3529
          -
          3540
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.IntegerType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.IntegerType
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          6316
        </td>
        <td>
          3490
          -
          3575
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.types.StructType.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.StructType.apply(scala.collection.Seq.apply[org.apache.spark.sql.types.StructField](org.apache.spark.sql.types.StructField.apply(&quot;salience&quot;, org.apache.spark.sql.types.IntegerType, org.apache.spark.sql.types.StructField.apply$default$3, org.apache.spark.sql.types.StructField.apply$default$4), org.apache.spark.sql.types.StructField.apply(&quot;result&quot;, starter, org.apache.spark.sql.types.StructField.apply$default$3, org.apache.spark.sql.types.StructField.apply$default$4)))
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          6319
        </td>
        <td>
          3596
          -
          3603
        </td>
        <td>
          Ident
        </td>
        <td>
          com.sparkutils.quality.impl.imports.RuleFolderRunnerImports.starter
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          starter
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          6321
        </td>
        <td>
          3629
          -
          3629
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.qualityFunctions.RefExpressionLazyType.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.qualityFunctions.RefExpressionLazyType.apply$default$3
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          6320
        </td>
        <td>
          3660
          -
          3664
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          true
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          6322
        </td>
        <td>
          3629
          -
          3665
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.qualityFunctions.RefExpressionLazyType.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.qualityFunctions.RefExpressionLazyType.apply(dataRef, true, org.apache.spark.sql.qualityFunctions.RefExpressionLazyType.apply$default$3)
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          6327
        </td>
        <td>
          3707
          -
          3707
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.qualityFunctions.FunN.apply$default$5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.qualityFunctions.FunN.apply$default$5
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          6324
        </td>
        <td>
          3744
          -
          3748
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          true
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          6323
        </td>
        <td>
          3712
          -
          3724
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.apply[org.apache.spark.sql.qualityFunctions.RefExpressionLazyType](lazyRef)
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          6326
        </td>
        <td>
          3707
          -
          3707
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.qualityFunctions.FunN.apply$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.qualityFunctions.FunN.apply$default$4
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          6328
        </td>
        <td>
          3707
          -
          3749
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.qualityFunctions.FunN.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.qualityFunctions.FunN.apply(x$1, x$2, x$4, x$5, x$6, x$3)
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          6325
        </td>
        <td>
          3707
          -
          3707
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.qualityFunctions.FunN.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.qualityFunctions.FunN.apply$default$3
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          6330
        </td>
        <td>
          3773
          -
          3773
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$1._2
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          6329
        </td>
        <td>
          3760
          -
          3760
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$1._1
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          6331
        </td>
        <td>
          3844
          -
          3880
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleLogicUtils.cleanExprs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.RuleLogicUtils.cleanExprs(ruleSuite)
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          6332
        </td>
        <td>
          3899
          -
          3925
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.ShimUtils.expression
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.ShimUtils.expression(startingStruct)
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          6333
        </td>
        <td>
          4061
          -
          4097
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.PassThroughCompileEvals.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.PassThroughCompileEvals.apply(expressions)
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          6334
        </td>
        <td>
          4061
          -
          4097
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.util.PassThroughCompileEvals.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.PassThroughCompileEvals.apply(expressions)
        </td>
      </tr><tr>
        <td>
          67
        </td>
        <td>
          6336
        </td>
        <td>
          4117
          -
          4149
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.util.PassThroughEvalOnly.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.PassThroughEvalOnly.apply(expressions)
        </td>
      </tr><tr>
        <td>
          67
        </td>
        <td>
          6335
        </td>
        <td>
          4117
          -
          4149
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.PassThroughEvalOnly.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.PassThroughEvalOnly.apply(expressions)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          6338
        </td>
        <td>
          4178
          -
          4218
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Boolean.||
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          forceRunnerEval.||(resolveWith.isDefined)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          6337
        </td>
        <td>
          4197
          -
          4218
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Option.isDefined
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          resolveWith.isDefined
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          6339
        </td>
        <td>
          4228
          -
          4461
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleFolderRunnerEval.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new com.sparkutils.quality.impl.RuleFolderRunnerEval(cleaed, starter, exprs, realType, compileEvals, debugMode, variablesPerFunc, variableFuncGroup, indexes, dataRef, forceTriggerEval)
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          6340
        </td>
        <td>
          4228
          -
          4461
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleFolderRunnerEval.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new com.sparkutils.quality.impl.RuleFolderRunnerEval(cleaed, starter, exprs, realType, compileEvals, debugMode, variablesPerFunc, variableFuncGroup, indexes, dataRef, forceTriggerEval)
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          6342
        </td>
        <td>
          4481
          -
          4710
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleFolderRunner.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new com.sparkutils.quality.impl.RuleFolderRunner(cleaed, starter, exprs, realType, compileEvals, debugMode, variablesPerFunc, variableFuncGroup, indexes, dataRef, forceTriggerEval)
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          6341
        </td>
        <td>
          4481
          -
          4710
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleFolderRunner.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new com.sparkutils.quality.impl.RuleFolderRunner(cleaed, starter, exprs, realType, compileEvals, debugMode, variablesPerFunc, variableFuncGroup, indexes, dataRef, forceTriggerEval)
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          6344
        </td>
        <td>
          4716
          -
          5168
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.ShimUtils.column
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.ShimUtils.column(org.apache.spark.sql.QualitySparkUtils.resolveWithOverride(resolveWith).map[org.apache.spark.sql.catalyst.expressions.Expression](((df: org.apache.spark.sql.DataFrame) =&gt; {
  val resolved: org.apache.spark.sql.catalyst.expressions.Expression = org.apache.spark.sql.QualitySparkUtils.resolveExpression(df, runner);
  resolved.withNewChildren(scala.collection.Seq.apply[org.apache.spark.sql.catalyst.expressions.Expression](runner.left, resolved.children.head match {
    case (children: Seq[org.apache.spark.sql.catalyst.expressions.Expression])com.sparkutils.quality.impl.util.PassThroughCompileEvals((children @ _)) =&gt; com.sparkutils.quality.impl.util.NonPassThrough.apply(children)
    case (children: Seq[org.apache.spark.sql.catalyst.expressions.Expression])com.sparkutils.quality.impl.util.PassThroughEvalOnly((children @ _)) =&gt; com.sparkutils.quality.impl.util.NonPassThrough.apply(children)
  }))
})).getOrElse[org.apache.spark.sql.catalyst.expressions.Expression](runner))
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          6343
        </td>
        <td>
          4730
          -
          5162
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.QualitySparkUtils.resolveWithOverride(resolveWith).map[org.apache.spark.sql.catalyst.expressions.Expression](((df: org.apache.spark.sql.DataFrame) =&gt; {
  val resolved: org.apache.spark.sql.catalyst.expressions.Expression = org.apache.spark.sql.QualitySparkUtils.resolveExpression(df, runner);
  resolved.withNewChildren(scala.collection.Seq.apply[org.apache.spark.sql.catalyst.expressions.Expression](runner.left, resolved.children.head match {
    case (children: Seq[org.apache.spark.sql.catalyst.expressions.Expression])com.sparkutils.quality.impl.util.PassThroughCompileEvals((children @ _)) =&gt; com.sparkutils.quality.impl.util.NonPassThrough.apply(children)
    case (children: Seq[org.apache.spark.sql.catalyst.expressions.Expression])com.sparkutils.quality.impl.util.PassThroughEvalOnly((children @ _)) =&gt; com.sparkutils.quality.impl.util.NonPassThrough.apply(children)
  }))
})).getOrElse[org.apache.spark.sql.catalyst.expressions.Expression](runner)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>