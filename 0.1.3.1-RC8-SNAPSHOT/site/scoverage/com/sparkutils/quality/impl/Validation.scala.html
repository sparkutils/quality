<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/impl/Validation.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality.impl
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality.impl.util.VariablesLookup.Identifiers
</span>4 <span style=''>import com.sparkutils.quality.impl.util.RuleSuiteDocs.{IdTrEither, LambdaId, OutputExpressionId, RuleId}
</span>5 <span style=''>import com.sparkutils.quality.impl.util.{Docs, DocsParser, ExpressionLookup, RuleSuiteDocs, VariablesLookup, WithDocs}
</span>6 <span style=''>import com.sparkutils.quality._
</span>7 <span style=''>import com.sparkutils.shim.ShowParams
</span>8 <span style=''>import com.sparkutils.shim.expressions.Names.toName
</span>9 <span style=''>import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation
</span>10 <span style=''>import org.apache.spark.sql.catalyst.expressions.{Expression, SubqueryExpression, LambdaFunction =&gt; SLambdaFunction}
</span>11 <span style=''>import org.apache.spark.sql.types.StructType
</span>12 <span style=''>import org.apache.spark.sql._
</span>13 <span style=''>
</span>14 <span style=''>import scala.collection.mutable
</span>15 <span style=''>
</span>16 <span style=''>sealed trait RuleRelevant
</span>17 <span style=''>sealed trait LambdaRelevant
</span>18 <span style=''>sealed trait OutputExpressionRelevant
</span>19 <span style=''>
</span>20 <span style=''>sealed trait HasId {
</span>21 <span style=''>  def id: Id
</span>22 <span style=''>}
</span>23 <span style=''>
</span>24 <span style=''>sealed trait HasOutputText {
</span>25 <span style=''>  def outputText: String
</span>26 <span style=''>}
</span>27 <span style=''>
</span>28 <span style=''>sealed trait HasNonIdText {
</span>29 <span style=''>  def nonIdText: String
</span>30 <span style=''>}
</span>31 <span style=''>
</span>32 <span style=''>/**
</span>33 <span style=''> * Base for RuleWarnings
</span>34 <span style=''> */
</span>35 <span style=''>sealed trait RuleWarning extends HasId with HasOutputText with HasNonIdText {
</span>36 <span style=''>  def warning: String
</span>37 <span style=''>
</span>38 <span style=''>  override def nonIdText: String = </span><span style='background: #AEF1AE'>warning</span><span style=''>
</span>39 <span style=''>
</span>40 <span style=''>  /**
</span>41 <span style=''>   * If the error is syntax based - defined by parsing, rather than any later stage
</span>42 <span style=''>   * @return
</span>43 <span style=''>   */
</span>44 <span style=''>  def syntax: Boolean = </span><span style='background: #AEF1AE'>false</span><span style=''>
</span>45 <span style=''>
</span>46 <span style=''>  def warningText = </span><span style='background: #AEF1AE'>s&quot;$warning, occurred when processing id $id&quot;</span><span style=''>
</span>47 <span style=''>
</span>48 <span style=''>  override def outputText: String = </span><span style='background: #AEF1AE'>warningText</span><span style=''>
</span>49 <span style=''>}
</span>50 <span style=''>
</span>51 <span style=''>sealed trait SyntaxWarning extends RuleWarning {
</span>52 <span style=''>  final override def syntax: Boolean = </span><span style='background: #AEF1AE'>true</span><span style=''>
</span>53 <span style=''>}
</span>54 <span style=''>
</span>55 <span style=''>sealed trait SyntaxNameWarning extends SyntaxWarning {
</span>56 <span style=''>  def name: String
</span>57 <span style=''>}
</span>58 <span style=''>
</span>59 <span style=''>case class LambdaPossibleSOE(id: Id) extends RuleWarning with LambdaRelevant {
</span>60 <span style=''>  val warning = </span><span style='background: #AEF1AE'>&quot;Possible SOE detected&quot;</span><span style=''>
</span>61 <span style=''>}
</span>62 <span style=''>
</span>63 <span style=''>case class NonLambdaDocParameters(id: Id) extends SyntaxWarning {
</span>64 <span style=''>  val warning = </span><span style='background: #AEF1AE'>&quot;Parameter documentation is present on a non lambda expression&quot;</span><span style=''>
</span>65 <span style=''>}
</span>66 <span style=''>
</span>67 <span style=''>case class ExtraDocParameter(id: Id, name: String) extends SyntaxNameWarning with LambdaRelevant {
</span>68 <span style=''>  val warning = </span><span style='background: #AEF1AE'>s&quot;Parameter $name is not found in the lambda expression&quot;</span><span style=''>
</span>69 <span style=''>}
</span>70 <span style=''>
</span>71 <span style=''>/**
</span>72 <span style=''> * Base for RuleErrors
</span>73 <span style=''> */
</span>74 <span style=''>sealed trait RuleError extends HasId with HasOutputText with HasNonIdText {
</span>75 <span style=''>  def error: String
</span>76 <span style=''>
</span>77 <span style=''>  override def nonIdText: String = </span><span style='background: #AEF1AE'>error</span><span style=''>
</span>78 <span style=''>  /**
</span>79 <span style=''>   * If the error is syntax based - defined by parsing, rather than any later stage
</span>80 <span style=''>   * @return
</span>81 <span style=''>   */
</span>82 <span style=''>  def syntax: Boolean = </span><span style='background: #AEF1AE'>false</span><span style=''>
</span>83 <span style=''>
</span>84 <span style=''>  def errorText = </span><span style='background: #AEF1AE'>s&quot;$error occurred when processing id $id&quot;</span><span style=''>
</span>85 <span style=''>
</span>86 <span style=''>  override def outputText: String = </span><span style='background: #AEF1AE'>errorText</span><span style=''>
</span>87 <span style=''>}
</span>88 <span style=''>
</span>89 <span style=''>sealed trait SyntaxError extends RuleError {
</span>90 <span style=''>  final override def syntax: Boolean = </span><span style='background: #AEF1AE'>true</span><span style=''>
</span>91 <span style=''>}
</span>92 <span style=''>
</span>93 <span style=''>sealed trait NameMissingError extends RuleError {
</span>94 <span style=''>  def name: String
</span>95 <span style=''>  final override def error = </span><span style='background: #AEF1AE'>s&quot;Name $name is missing&quot;</span><span style=''>
</span>96 <span style=''>}
</span>97 <span style=''>
</span>98 <span style=''>sealed trait ViewMissingError extends RuleError {
</span>99 <span style=''>  def name: String
</span>100 <span style=''>  final override def error = </span><span style='background: #AEF1AE'>s&quot;View $name is missing&quot;</span><span style=''>
</span>101 <span style=''>}
</span>102 <span style=''>
</span>103 <span style=''>case class LambdaSyntaxError(id: Id, error: String) extends SyntaxError with LambdaRelevant
</span>104 <span style=''>case class LambdaStackOverflowError(id: Id) extends SyntaxError with LambdaRelevant {
</span>105 <span style=''>  val error = </span><span style='background: #AEF1AE'>&quot;A lambda function seems to infinitely recurse&quot;</span><span style=''>
</span>106 <span style=''>}
</span>107 <span style=''>case class LambdaNameError(name: String, id: Id) extends NameMissingError with LambdaRelevant
</span>108 <span style=''>case class LambdaMultipleImplementationWithSameArityError(name: String, count: Int, argLength: Int, ids: Set[Id]) extends SyntaxError with LambdaRelevant {
</span>109 <span style=''>  val error = </span><span style='background: #AEF1AE'>s&quot;Lambda function $name has $count implementations with $argLength arguments&quot;</span><span style=''>
</span>110 <span style=''>  val id = </span><span style='background: #AEF1AE'>ids.head</span><span style=''>
</span>111 <span style=''>}
</span>112 <span style=''>case class LambdaViewError(name: String, id: Id) extends ViewMissingError with LambdaRelevant
</span>113 <span style=''>
</span>114 <span style=''>case class RuleSyntaxError(id: Id, error: String) extends SyntaxError with RuleRelevant
</span>115 <span style=''>case class RuleNameError(name: String, id: Id) extends NameMissingError with RuleRelevant
</span>116 <span style=''>case class RuleViewError(name: String, id: Id) extends ViewMissingError with RuleRelevant
</span>117 <span style=''>
</span>118 <span style=''>case class OutputRuleSyntaxError(id: Id, error: String) extends SyntaxError with OutputExpressionRelevant
</span>119 <span style=''>case class OutputRuleNameError(name: String, id: Id) extends NameMissingError with OutputExpressionRelevant
</span>120 <span style=''>case class OutputRuleViewError(name: String, id: Id) extends ViewMissingError with OutputExpressionRelevant
</span>121 <span style=''>
</span>122 <span style=''>case class LambdaSparkFunctionNameError(name: String, id: Id) extends NameMissingError with LambdaRelevant
</span>123 <span style=''>case class SparkFunctionNameError(name: String, id: Id) extends NameMissingError with RuleRelevant
</span>124 <span style=''>case class OuputSparkFunctionNameError(name: String, id: Id) extends NameMissingError with OutputExpressionRelevant
</span>125 <span style=''>
</span>126 <span style=''>case class DataFrameSyntaxError(error: String) extends SyntaxError {
</span>127 <span style=''>  val id = </span><span style='background: #AEF1AE'>Validation.dataFrameSyntaxErrorId</span><span style=''>
</span>128 <span style=''>}
</span>129 <span style=''>
</span>130 <span style=''>object Validation {
</span>131 <span style=''>  val unknownSOEId = </span><span style='background: #AEF1AE'>Id(Int.MinValue,Int.MinValue)</span><span style=''>
</span>132 <span style=''>  val dataFrameSyntaxErrorId = </span><span style='background: #AEF1AE'>Id(Int.MinValue+1,Int.MinValue+1)</span><span style=''>
</span>133 <span style=''>
</span>134 <span style=''>  protected[quality] val defaultViewLookup: String =&gt; Boolean =
</span>135 <span style=''>    </span><span style='background: #AEF1AE'>SparkSession.active.catalog.tableExists(_)</span><span style=''>
</span>136 <span style=''>
</span>137 <span style=''>  protected[sparkutils] val emptyDocs = </span><span style='background: #AEF1AE'>Docs()</span><span style=''>
</span>138 <span style=''>
</span>139 <span style=''>  /**
</span>140 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>141 <span style=''>   *
</span>142 <span style=''>   * @param schemaOrFrame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>143 <span style=''>   * @param ruleSuite
</span>144 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>145 <span style=''>   * @param showParams - configure how the output text is formatted using the same options and formatting as dataFrame.show
</span>146 <span style=''>   * @param qualityName - the column name to store the runnerFunction results in
</span>147 <span style=''>   * @param recursiveLambdasSOEIsOk - this signals that finding a recursive lambda SOE should not stop the evaluations - if true it will still try to run any runnerFunction but may not give the correct results
</span>148 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>149 <span style=''>   * @param viewLookup - for any subquery used looks up the view name for being present (quoted and with schema), defaults to the current spark catalogue
</span>150 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>151 <span style=''>   */
</span>152 <span style=''>  def validate(schemaOrFrame: Either[StructType, DataFrame], ruleSuite: RuleSuite, showParams: ShowParams = ShowParams(),
</span>153 <span style=''>               runnerFunction: Option[DataFrame =&gt; Column] = None, qualityName: String = &quot;Quality&quot;,
</span>154 <span style=''>               recursiveLambdasSOEIsOk: Boolean = false, transformBeforeShow: DataFrame =&gt; DataFrame = identity, viewLookup: String =&gt; Boolean = Validation.defaultViewLookup):
</span>155 <span style=''>                (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) = {
</span>156 <span style=''>    val schema = </span><span style='background: #AEF1AE'>schemaOrFrame.fold(identity, _.schema)</span><span style=''>
</span>157 <span style=''>
</span>158 <span style=''>    val names = </span><span style='background: #AEF1AE'>namesFromSchema(schema)</span><span style=''>
</span>159 <span style=''>
</span>160 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>161 <span style=''>
</span>162 <span style=''>    val ((lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, lambdas, lambdaDocWarnings, lambadaExpressionLookups, lambdaViewErrors)) =
</span>163 <span style=''>      validateLambdas(ruleSuite, recursiveLambdasSOEIsOk, names, viewLookup) match {
</span>164 <span style=''>        case Left(toReturn) =&gt; return toReturn
</span>165 <span style=''>        case Right(result) =&gt; result
</span>166 <span style=''>      }
</span>167 <span style=''>
</span>168 <span style=''>    </span><span style='background: #AEF1AE'>docsWarnings ++= lambdaDocWarnings</span><span style=''>
</span>169 <span style=''>
</span>170 <span style=''>    val (ruleErrors, ruleDocWarnings, rules, outputExpressions, ruleExpressionLookups) = validateRules(ruleSuite, lambdaLookups, names, viewLookup)
</span>171 <span style=''>
</span>172 <span style=''>    </span><span style='background: #AEF1AE'>docsWarnings ++= ruleDocWarnings</span><span style=''>
</span>173 <span style=''>
</span>174 <span style=''>    val (showOut, dfErrors) =
</span>175 <span style=''>      validateAgainstDataFrame(schemaOrFrame, showParams, runnerFunction, qualityName, transformBeforeShow, schema, viewLookup)
</span>176 <span style=''>
</span>177 <span style=''>    </span><span style='background: #AEF1AE'>(unknownLambdaSparkFunctionErrors ++ lambdaArityErrors ++ dfErrors ++ ruleErrors ++ lambdaNameErrors ++ lambdaSyntaxErrors.map(_._2.right.get).toSet ++ lambdaViewErrors,
</span>178 <span style=''></span><span style='background: #AEF1AE'>      potentialOverflows.map( LambdaPossibleSOE ) ++ (Set() ++ docsWarnings)
</span>179 <span style=''></span><span style='background: #AEF1AE'>      , showOut, RuleSuiteDocs(rules, outputExpressions, lambdas), lambadaExpressionLookups ++ ruleExpressionLookups)</span><span style=''>
</span>180 <span style=''>  }
</span>181 <span style=''>
</span>182 <span style=''>  protected def validateAgainstDataFrame(schemaOrFrame: Either[StructType, DataFrame], showParams: ShowParams, runnerFunction: Option[DataFrame =&gt; Column], qualityName: String, transformBeforeShow: DataFrame =&gt; DataFrame, schema: StructType, viewLookup: String =&gt; Boolean) = {
</span>183 <span style=''>    val basedf = </span><span style='background: #AEF1AE'>schemaOrFrame.right.getOrElse {
</span>184 <span style=''></span><span style='background: #AEF1AE'>      val session = SparkSession.active
</span>185 <span style=''></span><span style='background: #AEF1AE'>      val empty = session.sparkContext.emptyRDD[Row]
</span>186 <span style=''></span><span style='background: #AEF1AE'>      session.createDataFrame(empty, schema)
</span>187 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>188 <span style=''>
</span>189 <span style=''>    val (showOut, dfErrors) =
</span>190 <span style=''>      runnerFunction.fold((&quot;&quot;, Set.empty[RuleError]))(rf =&gt; {
</span>191 <span style=''>        val runner = rf(basedf)
</span>192 <span style=''>        try {
</span>193 <span style=''>          val withRules = basedf.withColumn(qualityName, runner)
</span>194 <span style=''>          val transformed = transformBeforeShow(withRules)
</span>195 <span style=''>          (shim.utils.toString(transformed, showParams), Set.empty)
</span>196 <span style=''>        } catch {
</span>197 <span style=''>          case e: Throwable =&gt; (&quot;&quot;, Set(DataFrameSyntaxError(e.getMessage)))
</span>198 <span style=''>        }
</span>199 <span style=''>      })
</span>200 <span style=''>    </span><span style='background: #AEF1AE'>(showOut, dfErrors)</span><span style=''>
</span>201 <span style=''>  }
</span>202 <span style=''>
</span>203 <span style=''>  protected def validateRules(ruleSuite: RuleSuite, lambdaLookups: Map[String, Map[Id, Set[String]]], names: Set[String], viewLookup: String =&gt; Boolean)= {
</span>204 <span style=''>    val doRule = </span><span style='background: #AEF1AE'>validateRule(lambdaLookups, names)</span><span style=''> _
</span>205 <span style=''>
</span>206 <span style=''>    var rules = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[Rule]]</span><span style=''>
</span>207 <span style=''>    var outputExpressions = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[RunOnPassProcessor]]</span><span style=''>
</span>208 <span style=''>    var exprLookups = </span><span style='background: #AEF1AE'>Map.empty[IdTrEither, ExpressionLookup]</span><span style=''>
</span>209 <span style=''>
</span>210 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>211 <span style=''>
</span>212 <span style=''>    def addDocs[T](id: Id, rule: T, expressionRule: HasRuleText): (Id, WithDocs[T]) =
</span>213 <span style=''>      </span><span style='background: #AEF1AE'>DocsParser.parse(expressionRule.rule).map { parseddocs =&gt;
</span>214 <span style=''></span><span style='background: #AEF1AE'>        val res = id -&gt; WithDocs(rule, parseddocs)
</span>215 <span style=''></span><span style='background: #AEF1AE'>        if (parseddocs.params.nonEmpty) {
</span>216 <span style=''></span><span style='background: #AEF1AE'>          docsWarnings += NonLambdaDocParameters(id)
</span>217 <span style=''></span><span style='background: #AEF1AE'>        }
</span>218 <span style=''></span><span style='background: #AEF1AE'>        res
</span>219 <span style=''></span><span style='background: #AEF1AE'>      }.getOrElse(id -&gt; WithDocs(rule, emptyDocs))</span><span style=''>
</span>220 <span style=''>
</span>221 <span style=''>    // do the rules
</span>222 <span style=''>    val ruleErrors =
</span>223 <span style=''>      </span><span style='background: #AEF1AE'>ruleSuite.ruleSets.flatMap { rs =&gt;
</span>224 <span style=''></span><span style='background: #AEF1AE'>        rs.rules.flatMap { r =&gt;
</span>225 <span style=''></span><span style='background: #AEF1AE'>          rules += addDocs(r.id, r, r.expression.asInstanceOf[HasRuleText])
</span>226 <span style=''></span><span style='background: #AEF1AE'>
</span>227 <span style=''></span><span style='background: #AEF1AE'>          val (ruleErrors, exprLookup) = doRule(r.id, r.expression.asInstanceOf[HasExpr].expr, false, viewLookup)
</span>228 <span style=''></span><span style='background: #AEF1AE'>          exprLookups += RuleId(r.id) -&gt; exprLookup
</span>229 <span style=''></span><span style='background: #AEF1AE'>
</span>230 <span style=''></span><span style='background: #AEF1AE'>          val outputErrors =
</span>231 <span style=''></span><span style='background: #AEF1AE'>            if (r.runOnPassProcessor != NoOpRunOnPassProcessor.noOp) {
</span>232 <span style=''></span><span style='background: #AEF1AE'>              outputExpressions += addDocs(r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[OutputExpression])
</span>233 <span style=''></span><span style='background: #AEF1AE'>
</span>234 <span style=''></span><span style='background: #AEF1AE'>              val (oErrors, oExprLookup) = doRule(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup)
</span>235 <span style=''></span><span style='background: #AEF1AE'>              exprLookups += OutputExpressionId(r.runOnPassProcessor.id) -&gt; oExprLookup
</span>236 <span style=''></span><span style='background: #AEF1AE'>              oErrors
</span>237 <span style=''></span><span style='background: #AEF1AE'>            } else
</span>238 <span style=''></span><span style='background: #AEF1AE'>              Set.empty
</span>239 <span style=''></span><span style='background: #AEF1AE'>
</span>240 <span style=''></span><span style='background: #AEF1AE'>          ruleErrors ++ outputErrors
</span>241 <span style=''></span><span style='background: #AEF1AE'>        }
</span>242 <span style=''></span><span style='background: #AEF1AE'>      }.toSet</span><span style=''>
</span>243 <span style=''>
</span>244 <span style=''>    </span><span style='background: #AEF1AE'>(ruleErrors, Set() ++ docsWarnings, Map() ++ rules, outputExpressions, Map() ++ exprLookups)</span><span style=''>
</span>245 <span style=''>  }
</span>246 <span style=''>
</span>247 <span style=''>  protected def validateLambdas(ruleSuite: RuleSuite, recursiveLambdasSOEIsOk: Boolean, names: Set[String], viewLookup: String =&gt; Boolean): Either[(Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]),
</span>248 <span style=''>    (Seq[(String, Either[(Id, Expression), LambdaSyntaxError])], Map[String, Map[Id, Set[String]]],
</span>249 <span style=''>      Set[Id], Set[LambdaSparkFunctionNameError], Set[LambdaMultipleImplementationWithSameArityError], Set[LambdaNameError], Map[Id, WithDocs[LambdaFunction]], Set[RuleWarning], Map[IdTrEither, ExpressionLookup], Set[LambdaViewError])] = {
</span>250 <span style=''>
</span>251 <span style=''>    var lambdas = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[LambdaFunction]]</span><span style=''>
</span>252 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>253 <span style=''>
</span>254 <span style=''>    val viewErrors = </span><span style='background: #AEF1AE'>ruleSuite.lambdaFunctions.flatMap { f =&gt;
</span>255 <span style=''></span><span style='background: #AEF1AE'>      try {
</span>256 <span style=''></span><span style='background: #AEF1AE'>        subQueryErrors(viewLookup, f.expr, LambdaViewError(_, f.id))
</span>257 <span style=''></span><span style='background: #AEF1AE'>      } catch {
</span>258 <span style=''></span><span style='background: #AEF1AE'>        // Might be a parser error, skip to let the below code pick it up
</span>259 <span style=''></span><span style='background: #AEF1AE'>        case _: Throwable =&gt; Set.empty[LambdaViewError]
</span>260 <span style=''></span><span style='background: #AEF1AE'>      }
</span>261 <span style=''></span><span style='background: #AEF1AE'>    }.toSet</span><span style=''>
</span>262 <span style=''>
</span>263 <span style=''>    val (lambdaLeftExpressions, lambdaSyntaxErrors) = ruleSuite.lambdaFunctions.map { f =&gt;
</span>264 <span style=''>      (f.name,
</span>265 <span style=''>        try {
</span>266 <span style=''>          val expr = f.expr
</span>267 <span style=''>          val ret = Left((f.id, expr))
</span>268 <span style=''>
</span>269 <span style=''>          val args =
</span>270 <span style=''>            expr match {
</span>271 <span style=''>              case lambda: SLambdaFunction =&gt; lambda.arguments.map(toName).toSet
</span>272 <span style=''>              case _ =&gt; Set.empty[String]
</span>273 <span style=''>            }
</span>274 <span style=''>
</span>275 <span style=''>          DocsParser.parse(f.rule).map { parseddocs =&gt;
</span>276 <span style=''>            lambdas += f.id -&gt; WithDocs(f, parseddocs)
</span>277 <span style=''>
</span>278 <span style=''>            parseddocs.params.keySet.foreach { name =&gt;
</span>279 <span style=''>              if (!args.contains(name)) {
</span>280 <span style=''>                docsWarnings += ExtraDocParameter(f.id, name)
</span>281 <span style=''>              }
</span>282 <span style=''>            }
</span>283 <span style=''>          }.getOrElse {
</span>284 <span style=''>            lambdas += f.id -&gt; WithDocs(f, emptyDocs)
</span>285 <span style=''>          }
</span>286 <span style=''>
</span>287 <span style=''>          ret
</span>288 <span style=''>        } catch {
</span>289 <span style=''>          case e: Throwable =&gt; Right(LambdaSyntaxError(f.id, e.getMessage))
</span>290 <span style=''>        })
</span>291 <span style=''>    }.partition {
</span>292 <span style=''>      _._2.isLeft
</span>293 <span style=''>    }
</span>294 <span style=''>
</span>295 <span style=''>    val lambdaNameToExpressions = </span><span style='background: #AEF1AE'>lambdaLeftExpressions.groupBy(p =&gt; p._1).mapValues(e =&gt; e.map(_._2.left.get).toMap).toMap</span><span style=''>
</span>296 <span style=''>
</span>297 <span style=''>    val (lambdaLookups, potentialOverflows, unknownLambdaSparkFunctions) = try {
</span>298 <span style=''>      VariablesLookup.processLambdas(lambdaNameToExpressions)
</span>299 <span style=''>    } catch {
</span>300 <span style=''>      // SOE is possible with lambdas calling lambdas, capture that as a distinct issue
</span>301 <span style=''>      case soe: StackOverflowError =&gt;
</span>302 <span style=''>        if (recursiveLambdasSOEIsOk)
</span>303 <span style=''>        // type needed otherwise it gets stuck with the first param type derivation _1 &lt;: String instead of String
</span>304 <span style=''>          (Map.empty[String, Map[Id, Identifiers]], Set.empty[Id], Map.empty[Id, Set[String]])
</span>305 <span style=''>        else
</span>306 <span style=''>          return Left((Set(LambdaStackOverflowError(Validation.unknownSOEId)), Set.empty[RuleWarning], &quot;&quot;, RuleSuiteDocs(), Map.empty[IdTrEither, ExpressionLookup]))
</span>307 <span style=''>    }
</span>308 <span style=''>
</span>309 <span style=''>    // now that they are looked up, a bit duplicative but...
</span>310 <span style=''>    val exprLookups = </span><span style='background: #AEF1AE'>lambdaNameToExpressions.values.flatMap( m =&gt; m.map(pair =&gt; LambdaId(pair._1) -&gt; VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))).toMap</span><span style=''>
</span>311 <span style=''>
</span>312 <span style=''>    val unknownLambdaSparkFunctionErrors = </span><span style='background: #AEF1AE'>unknownLambdaSparkFunctions.flatMap(p =&gt; p._2.map(name =&gt;
</span>313 <span style=''></span><span style='background: #AEF1AE'>      LambdaSparkFunctionNameError(name, p._1))).toSet</span><span style=''>
</span>314 <span style=''>
</span>315 <span style=''>    val lambdaArityErrors = </span><span style='background: #AEF1AE'>lambdaNameToExpressions.filter(p =&gt; p._2.size &gt; 1).flatMap {
</span>316 <span style=''></span><span style='background: #AEF1AE'>      pairs =&gt;
</span>317 <span style=''></span><span style='background: #AEF1AE'>        val map = pairs._2
</span>318 <span style=''></span><span style='background: #AEF1AE'>
</span>319 <span style=''></span><span style='background: #AEF1AE'>        val counts = map.groupBy(_._2.children.size - 1) // one child is the return
</span>320 <span style=''></span><span style='background: #AEF1AE'>        val moreThan1 = counts.collectFirst { case f if f._2.size &gt; 1 =&gt; f }
</span>321 <span style=''></span><span style='background: #AEF1AE'>        moreThan1.map { f =&gt;
</span>322 <span style=''></span><span style='background: #AEF1AE'>          LambdaMultipleImplementationWithSameArityError(pairs._1, f._2.size, f._1, f._2.keySet)
</span>323 <span style=''></span><span style='background: #AEF1AE'>        }
</span>324 <span style=''></span><span style='background: #AEF1AE'>    }.toSet</span><span style=''>
</span>325 <span style=''>
</span>326 <span style=''>    // do we have variables used in the lambdas which are not in the schema?
</span>327 <span style=''>    val lambdaNameErrors: Set[LambdaNameError] =
</span>328 <span style=''>      </span><span style='background: #AEF1AE'>lambdaLookups.flatMap { p =&gt;
</span>329 <span style=''></span><span style='background: #AEF1AE'>        p._2.flatMap { pair =&gt;
</span>330 <span style=''></span><span style='background: #AEF1AE'>          val (id, identifiers) = pair
</span>331 <span style=''></span><span style='background: #AEF1AE'>          if (identifiers.diff(names).isEmpty)
</span>332 <span style=''></span><span style='background: #AEF1AE'>            None
</span>333 <span style=''></span><span style='background: #AEF1AE'>          else
</span>334 <span style=''></span><span style='background: #AEF1AE'>            Some(identifiers.diff(names).map(LambdaNameError(_, id)))
</span>335 <span style=''></span><span style='background: #AEF1AE'>        }
</span>336 <span style=''></span><span style='background: #AEF1AE'>      }.flatten.toSet</span><span style=''>
</span>337 <span style=''>    </span><span style='background: #AEF1AE'>Right((lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, Map() ++ lambdas, Set() ++ docsWarnings, exprLookups, viewErrors))</span><span style=''>
</span>338 <span style=''>  }
</span>339 <span style=''>
</span>340 <span style=''>  protected def subQueryErrors[T](lookup: String =&gt; Boolean, expression: Expression, f: String =&gt; T): Set[T] = (</span><span style='background: #AEF1AE'>expression collect {
</span>341 <span style=''></span><span style='background: #AEF1AE'>    case s: SubqueryExpression =&gt; s.plan.collect{
</span>342 <span style=''></span><span style='background: #AEF1AE'>      case rel: UnresolvedRelation if !lookup(rel.tableName) =&gt;
</span>343 <span style=''></span><span style='background: #AEF1AE'>        f(rel.tableName)
</span>344 <span style=''></span><span style='background: #AEF1AE'>    }
</span>345 <span style=''></span><span style='background: #AEF1AE'>  }).flatten.toSet</span><span style=''>
</span>346 <span style=''>
</span>347 <span style=''>  protected def validateRule(lambdaLookups: Map[String, Map[Id, Set[String]]], names: Set[String])(id: Id, exprThunk: =&gt; Expression, outputRule: Boolean, viewLookup: String =&gt; Boolean): (Set[RuleError], ExpressionLookup) =
</span>348 <span style=''>    try {
</span>349 <span style=''>      </span><span style='background: #AEF1AE'>val expr = exprThunk
</span>350 <span style=''></span><span style='background: #AEF1AE'>      val exl @ ExpressionLookup(exprFields, unknownSparkFunctions, _, _) = VariablesLookup.fieldsFromExpression(expr, lambdaLookups)
</span>351 <span style=''></span><span style='background: #AEF1AE'>      val rules = exprFields.flatMap{
</span>352 <span style=''></span><span style='background: #AEF1AE'>        field =&gt;
</span>353 <span style=''></span><span style='background: #AEF1AE'>          if (names.contains(field))
</span>354 <span style=''></span><span style='background: #AEF1AE'>            None
</span>355 <span style=''></span><span style='background: #AEF1AE'>          else
</span>356 <span style=''></span><span style='background: #AEF1AE'>            Some(
</span>357 <span style=''></span><span style='background: #AEF1AE'>              if (!outputRule)
</span>358 <span style=''></span><span style='background: #AEF1AE'>                RuleNameError(field, id)
</span>359 <span style=''></span><span style='background: #AEF1AE'>              else
</span>360 <span style=''></span><span style='background: #AEF1AE'>                OutputRuleNameError(field, id)
</span>361 <span style=''></span><span style='background: #AEF1AE'>            )
</span>362 <span style=''></span><span style='background: #AEF1AE'>      }.toSet[RuleError]
</span>363 <span style=''></span><span style='background: #AEF1AE'>
</span>364 <span style=''></span><span style='background: #AEF1AE'>      val viewErrors = subQueryErrors(viewLookup, exprThunk, if (outputRule) OutputRuleViewError(_, id) else RuleViewError(_, id))
</span>365 <span style=''></span><span style='background: #AEF1AE'>
</span>366 <span style=''></span><span style='background: #AEF1AE'>      val unknown = unknownSparkFunctions.map{ name =&gt;
</span>367 <span style=''></span><span style='background: #AEF1AE'>        if (!outputRule)
</span>368 <span style=''></span><span style='background: #AEF1AE'>          SparkFunctionNameError(name, id)
</span>369 <span style=''></span><span style='background: #AEF1AE'>        else
</span>370 <span style=''></span><span style='background: #AEF1AE'>          OuputSparkFunctionNameError(name, id)
</span>371 <span style=''></span><span style='background: #AEF1AE'>      }
</span>372 <span style=''></span><span style='background: #AEF1AE'>
</span>373 <span style=''></span><span style='background: #AEF1AE'>      (rules ++ unknown ++ viewErrors, exl)</span><span style=''>
</span>374 <span style=''>    } catch {
</span>375 <span style=''>      case e: Throwable =&gt; </span><span style='background: #AEF1AE'>(Set(
</span>376 <span style=''></span><span style='background: #AEF1AE'>        if (!outputRule)
</span>377 <span style=''></span><span style='background: #AEF1AE'>          RuleSyntaxError(id, e.getMessage)
</span>378 <span style=''></span><span style='background: #AEF1AE'>        else
</span>379 <span style=''></span><span style='background: #AEF1AE'>          OutputRuleSyntaxError(id, e.getMessage)
</span>380 <span style=''></span><span style='background: #AEF1AE'>      ), impl.util.ExpressionLookup())</span><span style=''>
</span>381 <span style=''>    }
</span>382 <span style=''>
</span>383 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          38
        </td>
        <td>
          3715
        </td>
        <td>
          1153
          -
          1160
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warning
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          3716
        </td>
        <td>
          1295
          -
          1300
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          false
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          3717
        </td>
        <td>
          1324
          -
          1325
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          3719
        </td>
        <td>
          1365
          -
          1366
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          3722
        </td>
        <td>
          1322
          -
          1366
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;, occurred when processing id &quot;, &quot;&quot;).s(RuleWarning.this.warning, RuleWarning.this.id)
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          3718
        </td>
        <td>
          1332
          -
          1363
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;, occurred when processing id &quot;
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          3721
        </td>
        <td>
          1363
          -
          1365
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasId.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.id
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          3720
        </td>
        <td>
          1325
          -
          1332
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warning
        </td>
      </tr><tr>
        <td>
          48
        </td>
        <td>
          3723
        </td>
        <td>
          1404
          -
          1415
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warningText
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warningText
        </td>
      </tr><tr>
        <td>
          52
        </td>
        <td>
          3724
        </td>
        <td>
          1507
          -
          1511
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          true
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          3725
        </td>
        <td>
          1687
          -
          1710
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Possible SOE detected&quot;
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          3726
        </td>
        <td>
          1796
          -
          1859
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter documentation is present on a non lambda expression&quot;
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          3728
        </td>
        <td>
          1995
          -
          2034
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is not found in the lambda expression&quot;
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          3727
        </td>
        <td>
          1980
          -
          1991
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter &quot;
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          3730
        </td>
        <td>
          1978
          -
          2034
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Parameter &quot;, &quot; is not found in the lambda expression&quot;).s(ExtraDocParameter.this.name)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          3729
        </td>
        <td>
          1991
          -
          1995
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ExtraDocParameter.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExtraDocParameter.this.name
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          3731
        </td>
        <td>
          2201
          -
          2206
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.error
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.error
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          3732
        </td>
        <td>
          2340
          -
          2345
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          false
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          3735
        </td>
        <td>
          2405
          -
          2406
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          3734
        </td>
        <td>
          2373
          -
          2403
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; occurred when processing id &quot;
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          3737
        </td>
        <td>
          2403
          -
          2405
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasId.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.id
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          3733
        </td>
        <td>
          2367
          -
          2368
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          3736
        </td>
        <td>
          2368
          -
          2373
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.error
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.error
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          3738
        </td>
        <td>
          2365
          -
          2406
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot; occurred when processing id &quot;, &quot;&quot;).s(RuleError.this.error, RuleError.this.id)
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          3739
        </td>
        <td>
          2444
          -
          2453
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.errorText
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.errorText
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          3740
        </td>
        <td>
          2541
          -
          2545
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          true
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          3744
        </td>
        <td>
          2647
          -
          2671
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Name &quot;, &quot; is missing&quot;).s(NameMissingError.this.name)
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          3743
        </td>
        <td>
          2655
          -
          2659
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.NameMissingError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NameMissingError.this.name
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          3742
        </td>
        <td>
          2659
          -
          2671
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is missing&quot;
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          3741
        </td>
        <td>
          2649
          -
          2655
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Name &quot;
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          3746
        </td>
        <td>
          2785
          -
          2797
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is missing&quot;
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          3748
        </td>
        <td>
          2773
          -
          2797
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;View &quot;, &quot; is missing&quot;).s(ViewMissingError.this.name)
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          3745
        </td>
        <td>
          2775
          -
          2781
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;View &quot;
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          3747
        </td>
        <td>
          2781
          -
          2785
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ViewMissingError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ViewMissingError.this.name
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          3749
        </td>
        <td>
          2993
          -
          3040
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;A lambda function seems to infinitely recurse&quot;
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          3753
        </td>
        <td>
          3373
          -
          3384
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; arguments&quot;
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          3752
        </td>
        <td>
          3341
          -
          3364
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; implementations with &quot;
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          3755
        </td>
        <td>
          3336
          -
          3341
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.count
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.count
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          3757
        </td>
        <td>
          3307
          -
          3384
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Lambda function &quot;, &quot; has &quot;, &quot; implementations with &quot;, &quot; arguments&quot;).s(LambdaMultipleImplementationWithSameArityError.this.name, LambdaMultipleImplementationWithSameArityError.this.count, LambdaMultipleImplementationWithSameArityError.this.argLength)
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          3751
        </td>
        <td>
          3330
          -
          3336
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; has &quot;
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          3754
        </td>
        <td>
          3326
          -
          3330
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.name
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          3756
        </td>
        <td>
          3364
          -
          3373
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.argLength
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.argLength
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          3750
        </td>
        <td>
          3309
          -
          3326
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Lambda function &quot;
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          3758
        </td>
        <td>
          3396
          -
          3404
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.IterableLike.head
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.ids.head
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          3759
        </td>
        <td>
          4497
          -
          4530
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.dataFrameSyntaxErrorId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.dataFrameSyntaxErrorId
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          3760
        </td>
        <td>
          4575
          -
          4604
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.Id.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.Id.apply(-2147483648, -2147483648)
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          3761
        </td>
        <td>
          4636
          -
          4669
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.Id.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.Id.apply(-2147483647, -2147483647)
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          3762
        </td>
        <td>
          4739
          -
          4781
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalog.Catalog.tableExists
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active.catalog.tableExists(x$1)
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          3764
        </td>
        <td>
          4823
          -
          4823
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.Docs.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.Docs.apply$default$2
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          3766
        </td>
        <td>
          4823
          -
          4829
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.Docs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.Docs.apply(com.sparkutils.quality.impl.util.Docs.apply$default$1, com.sparkutils.quality.impl.util.Docs.apply$default$2, com.sparkutils.quality.impl.util.Docs.apply$default$3)
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          3763
        </td>
        <td>
          4823
          -
          4823
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.Docs.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.Docs.apply$default$1
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          3765
        </td>
        <td>
          4823
          -
          4823
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.Docs.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.Docs.apply$default$3
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          3767
        </td>
        <td>
          6691
          -
          6699
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.identity
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.identity[org.apache.spark.sql.types.StructType](x)
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          3769
        </td>
        <td>
          6672
          -
          6710
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.fold
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          schemaOrFrame.fold[org.apache.spark.sql.types.StructType]({
  ((x: org.apache.spark.sql.types.StructType) =&gt; scala.Predef.identity[org.apache.spark.sql.types.StructType](x))
}, ((x$2: org.apache.spark.sql.DataFrame) =&gt; x$2.schema))
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          3768
        </td>
        <td>
          6701
          -
          6709
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.Dataset.schema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2.schema
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          3770
        </td>
        <td>
          6728
          -
          6751
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.LookupIdFunctionsImports.namesFromSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.namesFromSchema(schema)
        </td>
      </tr><tr>
        <td>
          160
        </td>
        <td>
          3771
        </td>
        <td>
          6776
          -
          6802
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3779
        </td>
        <td>
          6949
          -
          6949
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._8
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._8
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3773
        </td>
        <td>
          6834
          -
          6834
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._2
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3776
        </td>
        <td>
          6903
          -
          6903
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._5
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3775
        </td>
        <td>
          6869
          -
          6869
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._4
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3778
        </td>
        <td>
          6940
          -
          6940
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._7
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._7
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3781
        </td>
        <td>
          6994
          -
          6994
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._10
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._10
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3772
        </td>
        <td>
          6814
          -
          6814
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._1
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3780
        </td>
        <td>
          6968
          -
          6968
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._9
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._9
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3774
        </td>
        <td>
          6849
          -
          6849
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._3
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3777
        </td>
        <td>
          6922
          -
          6922
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._6
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3782
        </td>
        <td>
          7197
          -
          7231
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.Growable.++=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.++=(lambdaDocWarnings)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          3785
        </td>
        <td>
          7271
          -
          7271
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._3
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          3784
        </td>
        <td>
          7254
          -
          7254
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._2
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          3787
        </td>
        <td>
          7297
          -
          7297
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._5
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          3783
        </td>
        <td>
          7242
          -
          7242
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._1
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          3786
        </td>
        <td>
          7278
          -
          7278
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._4
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          3788
        </td>
        <td>
          7386
          -
          7418
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.Growable.++=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.++=(ruleDocWarnings)
        </td>
      </tr><tr>
        <td>
          174
        </td>
        <td>
          3790
        </td>
        <td>
          7438
          -
          7438
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._2
        </td>
      </tr><tr>
        <td>
          174
        </td>
        <td>
          3789
        </td>
        <td>
          7429
          -
          7429
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._1
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          3791
        </td>
        <td>
          7584
          -
          7751
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownLambdaSparkFunctionErrors.++[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]](lambdaArityErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]).++[com.sparkutils.quality.impl.RuleError, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](dfErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]).++(ruleErrors).++(lambdaNameErrors).++(lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$6: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$6._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError]).++(lambdaViewErrors)
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          3798
        </td>
        <td>
          7583
          -
          7947
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple5.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple5.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning], String, com.sparkutils.quality.impl.util.RuleSuiteDocs, scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.util.ExpressionLookup]](unknownLambdaSparkFunctionErrors.++[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]](lambdaArityErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]).++[com.sparkutils.quality.impl.RuleError, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](dfErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]).++(ruleErrors).++(lambdaNameErrors).++(lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$6: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$6._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError]).++(lambdaViewErrors), potentialOverflows.map[com.sparkutils.quality.impl.LambdaPossibleSOE, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaPossibleSOE]](LambdaPossibleSOE)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]).++[com.sparkutils.quality.impl.RuleWarning, Set[com.sparkutils.quality.impl.RuleWarning]](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning]), showOut, com.sparkutils.quality.impl.util.RuleSuiteDocs.apply(rules, outputExpressions, lambdas), lambadaExpressionLookups.++[com.sparkutils.quality.impl.util.ExpressionLookup](ruleExpressionLookups))
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          3794
        </td>
        <td>
          7803
          -
          7803
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning]
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          3793
        </td>
        <td>
          7807
          -
          7828
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          3792
        </td>
        <td>
          7781
          -
          7781
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          3795
        </td>
        <td>
          7759
          -
          7829
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          potentialOverflows.map[com.sparkutils.quality.impl.LambdaPossibleSOE, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaPossibleSOE]](LambdaPossibleSOE)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]).++[com.sparkutils.quality.impl.RuleWarning, Set[com.sparkutils.quality.impl.RuleWarning]](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning])
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          3797
        </td>
        <td>
          7897
          -
          7946
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambadaExpressionLookups.++[com.sparkutils.quality.impl.util.ExpressionLookup](ruleExpressionLookups)
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          3796
        </td>
        <td>
          7847
          -
          7895
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.RuleSuiteDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.RuleSuiteDocs.apply(rules, outputExpressions, lambdas)
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          3802
        </td>
        <td>
          8247
          -
          8422
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.RightProjection.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          schemaOrFrame.right.getOrElse[org.apache.spark.sql.DataFrame]({
  val session: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession.active;
  val empty: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = session.sparkContext.emptyRDD[org.apache.spark.sql.Row]((ClassTag.apply[org.apache.spark.sql.Row](classOf[org.apache.spark.sql.Row]): scala.reflect.ClassTag[org.apache.spark.sql.Row]));
  session.createDataFrame(empty, schema)
})
        </td>
      </tr><tr>
        <td>
          184
        </td>
        <td>
          3799
        </td>
        <td>
          8299
          -
          8318
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.SparkSession.active
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active
        </td>
      </tr><tr>
        <td>
          185
        </td>
        <td>
          3800
        </td>
        <td>
          8337
          -
          8371
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.SparkContext.emptyRDD
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          session.sparkContext.emptyRDD[org.apache.spark.sql.Row]((ClassTag.apply[org.apache.spark.sql.Row](classOf[org.apache.spark.sql.Row]): scala.reflect.ClassTag[org.apache.spark.sql.Row]))
        </td>
      </tr><tr>
        <td>
          186
        </td>
        <td>
          3801
        </td>
        <td>
          8378
          -
          8416
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.SparkSession.createDataFrame
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          session.createDataFrame(empty, schema)
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          3803
        </td>
        <td>
          8433
          -
          8433
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._1
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          3804
        </td>
        <td>
          8442
          -
          8442
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._2
        </td>
      </tr><tr>
        <td>
          200
        </td>
        <td>
          3805
        </td>
        <td>
          8872
          -
          8891
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[String, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](showOut, dfErrors)
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          3806
        </td>
        <td>
          9070
          -
          9104
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validateRule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validateRule(lambdaLookups, names)(id, exprThunk, outputRule, viewLookup)
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          3807
        </td>
        <td>
          9124
          -
          9153
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]]
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          3808
        </td>
        <td>
          9182
          -
          9225
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]]
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          3809
        </td>
        <td>
          9248
          -
          9287
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup]
        </td>
      </tr><tr>
        <td>
          210
        </td>
        <td>
          3810
        </td>
        <td>
          9312
          -
          9338
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          3811
        </td>
        <td>
          9449
          -
          9468
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasRuleText.rule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expressionRule.rule
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          3812
        </td>
        <td>
          9514
          -
          9540
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.WithDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, parseddocs)
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          3813
        </td>
        <td>
          9508
          -
          9540
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.impl.util.WithDocs[T]](com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, parseddocs))
        </td>
      </tr><tr>
        <td>
          215
        </td>
        <td>
          3818
        </td>
        <td>
          9549
          -
          9549
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          215
        </td>
        <td>
          3814
        </td>
        <td>
          9553
          -
          9579
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.nonEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parseddocs.params.nonEmpty
        </td>
      </tr><tr>
        <td>
          215
        </td>
        <td>
          3819
        </td>
        <td>
          9549
          -
          9549
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          216
        </td>
        <td>
          3815
        </td>
        <td>
          9609
          -
          9635
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.NonLambdaDocParameters.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NonLambdaDocParameters.apply(id)
        </td>
      </tr><tr>
        <td>
          216
        </td>
        <td>
          3817
        </td>
        <td>
          9593
          -
          9635
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.+=(NonLambdaDocParameters.apply(id))
        </td>
      </tr><tr>
        <td>
          216
        </td>
        <td>
          3816
        </td>
        <td>
          9593
          -
          9635
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.+=(NonLambdaDocParameters.apply(id))
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          3821
        </td>
        <td>
          9682
          -
          9707
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.WithDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, Validation.this.emptyDocs)
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          3820
        </td>
        <td>
          9697
          -
          9706
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.emptyDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.emptyDocs
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          3823
        </td>
        <td>
          9432
          -
          9708
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.DocsParser.parse(expressionRule.rule).map[(com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[T])](((parseddocs: com.sparkutils.quality.impl.util.Docs) =&gt; {
  val res: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[T]) = scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.impl.util.WithDocs[T]](com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, parseddocs));
  if (parseddocs.params.nonEmpty)
    docsWarnings.+=(NonLambdaDocParameters.apply(id))
  else
    ();
  res
})).getOrElse[(com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[T])](scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.impl.util.WithDocs[T]](com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, Validation.this.emptyDocs)))
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          3822
        </td>
        <td>
          9676
          -
          9707
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.impl.util.WithDocs[T]](com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, Validation.this.emptyDocs))
        </td>
      </tr><tr>
        <td>
          223
        </td>
        <td>
          3849
        </td>
        <td>
          9784
          -
          9784
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          224
        </td>
        <td>
          3848
        </td>
        <td>
          9800
          -
          10662
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rs.rules.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((r: com.sparkutils.quality.Rule) =&gt; {
  rules = rules.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasRuleText]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$8: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup) = (doRule.apply(r.id, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasExpr].expr, false, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.impl.util.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup)((ruleErrors @ _), (exprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup](ruleErrors, exprLookup)
  };
  val ruleErrors: Set[com.sparkutils.quality.impl.RuleError] = x$8._1;
  val exprLookup: com.sparkutils.quality.impl.util.ExpressionLookup = x$8._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.impl.util.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](exprLookup));
  val outputErrors: scala.collection.immutable.Set[_ &lt;: com.sparkutils.quality.impl.RuleError] = if (r.runOnPassProcessor.!=(NoOpRunOnPassProcessor.noOp))
    {
      outputExpressions = outputExpressions.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]](addDocs[com.sparkutils.quality.impl.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup) @unchecked) match {
        case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.impl.util.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup](oErrors, oExprLookup)
      };
      val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
      val oExprLookup: com.sparkutils.quality.impl.util.ExpressionLookup = x$9._2;
      exprLookups = exprLookups.+[com.sparkutils.quality.impl.util.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](oExprLookup));
      oErrors
    }
  else
    scala.Predef.Set.empty[Nothing];
  ruleErrors.++(outputErrors)
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError])
        </td>
      </tr><tr>
        <td>
          224
        </td>
        <td>
          3847
        </td>
        <td>
          9817
          -
          9817
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3824
        </td>
        <td>
          9851
          -
          9855
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.Rule.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.id
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3827
        </td>
        <td>
          9834
          -
          9899
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rules.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasRuleText]))
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3826
        </td>
        <td>
          9843
          -
          9899
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.addDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasRuleText])
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3825
        </td>
        <td>
          9860
          -
          9898
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.expression.asInstanceOf[com.sparkutils.quality.impl.HasRuleText]
        </td>
      </tr><tr>
        <td>
          227
        </td>
        <td>
          3829
        </td>
        <td>
          9928
          -
          9928
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._2
        </td>
      </tr><tr>
        <td>
          227
        </td>
        <td>
          3828
        </td>
        <td>
          9916
          -
          9916
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._1
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          3830
        </td>
        <td>
          10040
          -
          10066
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](exprLookup)
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          3831
        </td>
        <td>
          10025
          -
          10066
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprLookups.+[com.sparkutils.quality.impl.util.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](exprLookup))
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          3833
        </td>
        <td>
          10113
          -
          10164
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.!=(NoOpRunOnPassProcessor.noOp)
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          3832
        </td>
        <td>
          10137
          -
          10164
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.NoOpRunOnPassProcessor.noOp
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NoOpRunOnPassProcessor.noOp
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          3843
        </td>
        <td>
          10166
          -
          10585
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  outputExpressions = outputExpressions.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]](addDocs[com.sparkutils.quality.impl.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.impl.util.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup](oErrors, oExprLookup)
  };
  val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
  val oExprLookup: com.sparkutils.quality.impl.util.ExpressionLookup = x$9._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.impl.util.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](oExprLookup));
  oErrors
}
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          3836
        </td>
        <td>
          10258
          -
          10324
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          3835
        </td>
        <td>
          10236
          -
          10256
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.Rule.runOnPassProcessor
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          3838
        </td>
        <td>
          10182
          -
          10325
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputExpressions.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]](addDocs[com.sparkutils.quality.impl.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]))
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          3834
        </td>
        <td>
          10211
          -
          10234
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RunOnPassProcessor.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.id
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          3837
        </td>
        <td>
          10203
          -
          10325
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.addDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          addDocs[com.sparkutils.quality.impl.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression])
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          3839
        </td>
        <td>
          10346
          -
          10346
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$9._1
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          3840
        </td>
        <td>
          10355
          -
          10355
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$9._2
        </td>
      </tr><tr>
        <td>
          235
        </td>
        <td>
          3842
        </td>
        <td>
          10476
          -
          10549
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprLookups.+[com.sparkutils.quality.impl.util.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](oExprLookup))
        </td>
      </tr><tr>
        <td>
          235
        </td>
        <td>
          3841
        </td>
        <td>
          10491
          -
          10549
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](oExprLookup)
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          3845
        </td>
        <td>
          10605
          -
          10614
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          3844
        </td>
        <td>
          10605
          -
          10614
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          3846
        </td>
        <td>
          10626
          -
          10652
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleErrors.++(outputErrors)
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          3850
        </td>
        <td>
          9757
          -
          10676
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.ruleSets.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((rs: com.sparkutils.quality.RuleSet) =&gt; rs.rules.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((r: com.sparkutils.quality.Rule) =&gt; {
  rules = rules.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasRuleText]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$8: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup) = (doRule.apply(r.id, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasExpr].expr, false, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.impl.util.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup)((ruleErrors @ _), (exprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup](ruleErrors, exprLookup)
  };
  val ruleErrors: Set[com.sparkutils.quality.impl.RuleError] = x$8._1;
  val exprLookup: com.sparkutils.quality.impl.util.ExpressionLookup = x$8._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.impl.util.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](exprLookup));
  val outputErrors: scala.collection.immutable.Set[_ &lt;: com.sparkutils.quality.impl.RuleError] = if (r.runOnPassProcessor.!=(NoOpRunOnPassProcessor.noOp))
    {
      outputExpressions = outputExpressions.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]](addDocs[com.sparkutils.quality.impl.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup) @unchecked) match {
        case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.impl.util.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup](oErrors, oExprLookup)
      };
      val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
      val oExprLookup: com.sparkutils.quality.impl.util.ExpressionLookup = x$9._2;
      exprLookups = exprLookups.+[com.sparkutils.quality.impl.util.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](oExprLookup));
      oErrors
    }
  else
    scala.Predef.Set.empty[Nothing];
  ruleErrors.++(outputErrors)
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError])))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]).toSet[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          3854
        </td>
        <td>
          10682
          -
          10774
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple5.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple5.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]], scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.util.ExpressionLookup]](ruleErrors, scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]](rules), outputExpressions, scala.Predef.Map.apply[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, Nothing]().++[com.sparkutils.quality.impl.util.ExpressionLookup](exprLookups))
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          3851
        </td>
        <td>
          10695
          -
          10716
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          3853
        </td>
        <td>
          10753
          -
          10773
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, Nothing]().++[com.sparkutils.quality.impl.util.ExpressionLookup](exprLookups)
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          3852
        </td>
        <td>
          10718
          -
          10732
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]](rules)
        </td>
      </tr><tr>
        <td>
          251
        </td>
        <td>
          3855
        </td>
        <td>
          11380
          -
          11419
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]]
        </td>
      </tr><tr>
        <td>
          252
        </td>
        <td>
          3856
        </td>
        <td>
          11443
          -
          11469
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          254
        </td>
        <td>
          3863
        </td>
        <td>
          11526
          -
          11526
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          256
        </td>
        <td>
          3857
        </td>
        <td>
          11580
          -
          11586
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasRuleText.expr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.expr
        </td>
      </tr><tr>
        <td>
          256
        </td>
        <td>
          3860
        </td>
        <td>
          11553
          -
          11613
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$10: String) =&gt; LambdaViewError.apply(x$10, f.id)))
        </td>
      </tr><tr>
        <td>
          256
        </td>
        <td>
          3859
        </td>
        <td>
          11588
          -
          11612
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaViewError.apply(x$10, f.id)
        </td>
      </tr><tr>
        <td>
          256
        </td>
        <td>
          3858
        </td>
        <td>
          11607
          -
          11611
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaFunction.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.id
        </td>
      </tr><tr>
        <td>
          256
        </td>
        <td>
          3861
        </td>
        <td>
          11553
          -
          11613
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$10: String) =&gt; LambdaViewError.apply(x$10, f.id)))
        </td>
      </tr><tr>
        <td>
          259
        </td>
        <td>
          3862
        </td>
        <td>
          11733
          -
          11759
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          3864
        </td>
        <td>
          11492
          -
          11779
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.lambdaFunctions.flatMap[com.sparkutils.quality.impl.LambdaViewError, Seq[com.sparkutils.quality.impl.LambdaViewError]](((f: com.sparkutils.quality.impl.LambdaFunction) =&gt; try {
  Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$10: String) =&gt; LambdaViewError.apply(x$10, f.id)))
} catch {
  case (_: Throwable) =&gt; scala.Predef.Set.empty[com.sparkutils.quality.impl.LambdaViewError]
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaViewError]).toSet[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          3866
        </td>
        <td>
          11813
          -
          11813
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$12._2
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          3865
        </td>
        <td>
          11790
          -
          11790
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$12._1
        </td>
      </tr><tr>
        <td>
          295
        </td>
        <td>
          3872
        </td>
        <td>
          12824
          -
          12824
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]
        </td>
      </tr><tr>
        <td>
          295
        </td>
        <td>
          3869
        </td>
        <td>
          12801
          -
          12801
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          295
        </td>
        <td>
          3868
        </td>
        <td>
          12802
          -
          12815
        </td>
        <td>
          Select
        </td>
        <td>
          scala.util.Either.LeftProjection.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$13._2.left.get
        </td>
      </tr><tr>
        <td>
          295
        </td>
        <td>
          3871
        </td>
        <td>
          12796
          -
          12822
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$13: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$13._2.left.get))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]).toMap[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])
        </td>
      </tr><tr>
        <td>
          295
        </td>
        <td>
          3867
        </td>
        <td>
          12775
          -
          12779
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          295
        </td>
        <td>
          3870
        </td>
        <td>
          12817
          -
          12817
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          295
        </td>
        <td>
          3873
        </td>
        <td>
          12740
          -
          12829
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.immutable.Map.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaLeftExpressions.groupBy[String](((p: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; p._1)).mapValues[scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]](((e: Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])]) =&gt; e.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$13: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$13._2.left.get))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]).toMap[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]))).toMap[String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]](scala.Predef.$conforms[(String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])])
        </td>
      </tr><tr>
        <td>
          297
        </td>
        <td>
          3875
        </td>
        <td>
          12855
          -
          12855
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._2
        </td>
      </tr><tr>
        <td>
          297
        </td>
        <td>
          3874
        </td>
        <td>
          12840
          -
          12840
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._1
        </td>
      </tr><tr>
        <td>
          297
        </td>
        <td>
          3876
        </td>
        <td>
          12875
          -
          12875
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._3
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          3881
        </td>
        <td>
          13689
          -
          13770
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](com.sparkutils.quality.impl.util.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          3884
        </td>
        <td>
          13668
          -
          13668
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Iterable.canBuildFrom[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup)]
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          3878
        </td>
        <td>
          13689
          -
          13706
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.RuleSuiteDocs.LambdaId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.RuleSuiteDocs.LambdaId(pair._1)
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          3877
        </td>
        <td>
          13698
          -
          13705
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pair._1
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          3886
        </td>
        <td>
          13630
          -
          13778
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaNameToExpressions.values.flatMap[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup), Iterable[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup)]](((m: scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) =&gt; m.map[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup), scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.util.ExpressionLookup]](((pair: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](com.sparkutils.quality.impl.util.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))))(immutable.this.Map.canBuildFrom[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup])))(collection.this.Iterable.canBuildFrom[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup)]).toMap[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup](scala.Predef.$conforms[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup)])
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          3880
        </td>
        <td>
          13710
          -
          13770
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.VariablesLookup.fieldsFromExpression
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups)
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          3883
        </td>
        <td>
          13675
          -
          13771
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          m.map[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup), scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.util.ExpressionLookup]](((pair: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.impl.util.ExpressionLookup](com.sparkutils.quality.impl.util.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))))(immutable.this.Map.canBuildFrom[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup])
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          3885
        </td>
        <td>
          13773
          -
          13773
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup)]
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          3879
        </td>
        <td>
          13747
          -
          13754
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pair._2
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          3882
        </td>
        <td>
          13680
          -
          13680
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Map.canBuildFrom[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.util.ExpressionLookup]
        </td>
      </tr><tr>
        <td>
          312
        </td>
        <td>
          3890
        </td>
        <td>
          13864
          -
          13928
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.map[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((name: String) =&gt; LambdaSparkFunctionNameError.apply(name, p._1)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError])
        </td>
      </tr><tr>
        <td>
          312
        </td>
        <td>
          3889
        </td>
        <td>
          13872
          -
          13872
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          312
        </td>
        <td>
          3891
        </td>
        <td>
          13858
          -
          13858
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          313
        </td>
        <td>
          3887
        </td>
        <td>
          13922
          -
          13926
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          313
        </td>
        <td>
          3892
        </td>
        <td>
          13823
          -
          13935
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownLambdaSparkFunctions.flatMap[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((p: (com.sparkutils.quality.Id, Set[String])) =&gt; p._2.map[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((name: String) =&gt; LambdaSparkFunctionNameError.apply(name, p._1)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError])))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]).toSet[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          313
        </td>
        <td>
          3888
        </td>
        <td>
          13887
          -
          13927
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaSparkFunctionNameError.apply(name, p._1)
        </td>
      </tr><tr>
        <td>
          315
        </td>
        <td>
          3893
        </td>
        <td>
          14001
          -
          14014
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.size.&gt;(1)
        </td>
      </tr><tr>
        <td>
          315
        </td>
        <td>
          3907
        </td>
        <td>
          14024
          -
          14024
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]
        </td>
      </tr><tr>
        <td>
          317
        </td>
        <td>
          3894
        </td>
        <td>
          14059
          -
          14067
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pairs._2
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3896
        </td>
        <td>
          14090
          -
          14125
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableLike.groupBy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          map.groupBy[Int](((x$15: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$15._2.children.size.-(1)))
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3895
        </td>
        <td>
          14102
          -
          14124
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.-
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$15._2.children.size.-(1)
        </td>
      </tr><tr>
        <td>
          320
        </td>
        <td>
          3899
        </td>
        <td>
          14177
          -
          14229
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.collectFirst
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          counts.collectFirst[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] with Serializable {
    def &lt;init&gt;(): &lt;$anon: ((Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]), B1 &gt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
      case (f @ _) if f._2.size.&gt;(1) =&gt; f
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): Boolean = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
      case (f @ _) if f._2.size.&gt;(1) =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]))
        </td>
      </tr><tr>
        <td>
          320
        </td>
        <td>
          3898
        </td>
        <td>
          14197
          -
          14197
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          320
        </td>
        <td>
          3897
        </td>
        <td>
          14209
          -
          14222
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.size.&gt;(1)
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          3905
        </td>
        <td>
          14238
          -
          14365
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet)))
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          3906
        </td>
        <td>
          14238
          -
          14365
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet))))
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          3902
        </td>
        <td>
          14337
          -
          14341
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._1
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          3904
        </td>
        <td>
          14269
          -
          14355
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet)
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          3901
        </td>
        <td>
          14326
          -
          14335
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.size
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.size
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          3900
        </td>
        <td>
          14316
          -
          14324
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pairs._1
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          3903
        </td>
        <td>
          14343
          -
          14354
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.immutable.MapLike.keySet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.keySet
        </td>
      </tr><tr>
        <td>
          324
        </td>
        <td>
          3908
        </td>
        <td>
          13965
          -
          14377
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaNameToExpressions.filter(((p: (String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; p._2.size.&gt;(1))).flatMap[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]](((pairs: (String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; {
  val map: scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression] = pairs._2;
  val counts: scala.collection.immutable.Map[Int,scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]] = map.groupBy[Int](((x$15: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$15._2.children.size.-(1)));
  val moreThan1: Option[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] = counts.collectFirst[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](({
    @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] with Serializable {
      def &lt;init&gt;(): &lt;$anon: ((Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])&gt; = {
        $anonfun.super.&lt;init&gt;();
        ()
      };
      final override def applyOrElse[A1 &lt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]), B1 &gt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
        case (f @ _) if f._2.size.&gt;(1) =&gt; f
        case (defaultCase$ @ _) =&gt; default.apply(x1)
      };
      final def isDefinedAt(x1: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): Boolean = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
        case (f @ _) if f._2.size.&gt;(1) =&gt; true
        case (defaultCase$ @ _) =&gt; false
      }
    };
    new $anonfun()
  }: PartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]));
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet))))
}))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]).toSet[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          3923
        </td>
        <td>
          14533
          -
          14533
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          329
        </td>
        <td>
          3922
        </td>
        <td>
          14548
          -
          14768
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((pair: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers)) =&gt; {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$16: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers) = (pair: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers) @unchecked) match {
    case (_1: com.sparkutils.quality.Id, _2: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers)(com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers)((id @ _), (identifiers @ _)) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](id, identifiers)
  };
  val id: com.sparkutils.quality.Id = x$16._1;
  val identifiers: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = x$16._2;
  if (identifiers.diff(names).isEmpty)
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.util.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
}))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]])
        </td>
      </tr><tr>
        <td>
          329
        </td>
        <td>
          3921
        </td>
        <td>
          14561
          -
          14561
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          3910
        </td>
        <td>
          14590
          -
          14590
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$16._2
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          3909
        </td>
        <td>
          14586
          -
          14586
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$16._1
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          3911
        </td>
        <td>
          14624
          -
          14655
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SetLike.isEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.diff(names).isEmpty
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          3914
        </td>
        <td>
          14669
          -
          14673
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          3913
        </td>
        <td>
          14669
          -
          14673
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          3912
        </td>
        <td>
          14669
          -
          14673
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          3917
        </td>
        <td>
          14706
          -
          14757
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.util.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          3920
        </td>
        <td>
          14701
          -
          14758
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.util.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          3916
        </td>
        <td>
          14733
          -
          14733
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError]
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          3919
        </td>
        <td>
          14701
          -
          14758
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.util.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          3918
        </td>
        <td>
          14701
          -
          14758
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.util.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError]))
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          3915
        </td>
        <td>
          14734
          -
          14756
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaNameError.apply(x$17, id)
        </td>
      </tr><tr>
        <td>
          336
        </td>
        <td>
          3925
        </td>
        <td>
          14511
          -
          14790
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaLookups.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((p: (String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.VariablesLookup.Identifiers])) =&gt; p._2.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((pair: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers)) =&gt; {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$16: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers) = (pair: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers) @unchecked) match {
    case (_1: com.sparkutils.quality.Id, _2: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers)(com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers)((id @ _), (identifiers @ _)) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](id, identifiers)
  };
  val id: com.sparkutils.quality.Id = x$16._1;
  val identifiers: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = x$16._2;
  if (identifiers.diff(names).isEmpty)
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.util.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
}))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]])))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]).flatten[com.sparkutils.quality.impl.LambdaNameError](scala.Predef.$conforms[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]).toSet[com.sparkutils.quality.impl.LambdaNameError]
        </td>
      </tr><tr>
        <td>
          336
        </td>
        <td>
          3924
        </td>
        <td>
          14777
          -
          14777
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          337
        </td>
        <td>
          3926
        </td>
        <td>
          14928
          -
          14944
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]](lambdas)
        </td>
      </tr><tr>
        <td>
          337
        </td>
        <td>
          3929
        </td>
        <td>
          14795
          -
          14994
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, (Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.util.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError])](scala.Tuple10.apply[Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.util.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError]](lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]](lambdas), scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), exprLookups, viewErrors))
        </td>
      </tr><tr>
        <td>
          337
        </td>
        <td>
          3928
        </td>
        <td>
          14801
          -
          14993
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple10.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple10.apply[Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.impl.util.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.util.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.util.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError]](lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]](lambdas), scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), exprLookups, viewErrors)
        </td>
      </tr><tr>
        <td>
          337
        </td>
        <td>
          3927
        </td>
        <td>
          14946
          -
          14967
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          3936
        </td>
        <td>
          15131
          -
          15131
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          341
        </td>
        <td>
          3935
        </td>
        <td>
          15167
          -
          15277
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.trees.TreeNode.collect
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          s.plan.collect[T](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T] with Serializable {
    def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =&gt; T&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, B1 &gt;: T](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
      case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; f.apply(rel.tableName)
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
      case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T]))
        </td>
      </tr><tr>
        <td>
          341
        </td>
        <td>
          3934
        </td>
        <td>
          15181
          -
          15181
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          342
        </td>
        <td>
          3931
        </td>
        <td>
          15221
          -
          15243
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lookup.apply(rel.tableName).unary_!
        </td>
      </tr><tr>
        <td>
          342
        </td>
        <td>
          3930
        </td>
        <td>
          15229
          -
          15242
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedRelation.tableName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rel.tableName
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3932
        </td>
        <td>
          15257
          -
          15270
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedRelation.tableName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rel.tableName
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3933
        </td>
        <td>
          15255
          -
          15271
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Function1.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.apply(rel.tableName)
        </td>
      </tr><tr>
        <td>
          345
        </td>
        <td>
          3938
        </td>
        <td>
          15112
          -
          15296
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expression.collect[Seq[T]](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.expressions.Expression,Seq[T]] with Serializable {
    def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.expressions.Expression =&gt; Seq[T]&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.expressions.Expression, B1 &gt;: Seq[T]](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.expressions.Expression]: org.apache.spark.sql.catalyst.expressions.Expression): org.apache.spark.sql.catalyst.expressions.Expression @unchecked) match {
      case (s @ (_: org.apache.spark.sql.catalyst.expressions.SubqueryExpression)) =&gt; s.plan.collect[T](({
        @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T] with Serializable {
          def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =&gt; T&gt; = {
            $anonfun.super.&lt;init&gt;();
            ()
          };
          final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, B1 &gt;: T](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
            case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; f.apply(rel.tableName)
            case (defaultCase$ @ _) =&gt; default.apply(x1)
          };
          final def isDefinedAt(x1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
            case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; true
            case (defaultCase$ @ _) =&gt; false
          }
        };
        new $anonfun()
      }: PartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T]))
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: org.apache.spark.sql.catalyst.expressions.Expression): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.expressions.Expression]: org.apache.spark.sql.catalyst.expressions.Expression): org.apache.spark.sql.catalyst.expressions.Expression @unchecked) match {
      case (s @ (_: org.apache.spark.sql.catalyst.expressions.SubqueryExpression)) =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[org.apache.spark.sql.catalyst.expressions.Expression,Seq[T]])).flatten[T](scala.Predef.$conforms[Seq[T]]).toSet[T]
        </td>
      </tr><tr>
        <td>
          345
        </td>
        <td>
          3937
        </td>
        <td>
          15283
          -
          15283
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[Seq[T]]
        </td>
      </tr><tr>
        <td>
          348
        </td>
        <td>
          3970
        </td>
        <td>
          15537
          -
          16380
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val expr: org.apache.spark.sql.catalyst.expressions.Expression = exprThunk;
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$18: (com.sparkutils.quality.impl.util.ExpressionLookup, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers) = (com.sparkutils.quality.impl.util.VariablesLookup.fieldsFromExpression(expr, lambdaLookups): com.sparkutils.quality.impl.util.ExpressionLookup @unchecked) match {
    case (exl @ (attributesUsed: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers, unknownSparkFunctions: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers, lambdas: Set[com.sparkutils.quality.Id], sparkFunctions: Set[String])com.sparkutils.quality.impl.util.ExpressionLookup((exprFields @ _), (unknownSparkFunctions @ _), _, _)) =&gt; scala.Tuple3.apply[com.sparkutils.quality.impl.util.ExpressionLookup, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers, com.sparkutils.quality.impl.util.VariablesLookup.Identifiers](exl, exprFields, unknownSparkFunctions)
  };
  val exl: com.sparkutils.quality.impl.util.ExpressionLookup = x$18._1;
  val exprFields: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = x$18._2;
  val unknownSparkFunctions: com.sparkutils.quality.impl.util.VariablesLookup.Identifiers = x$18._3;
  val rules: scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError] = exprFields.flatMap[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((field: com.sparkutils.quality.impl.util.VariablesLookup.Identifier) =&gt; if (names.contains(field))
  scala.this.Option.option2Iterable[Nothing](scala.None)
else
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
    RuleNameError.apply(field, id)
  else
    OutputRuleNameError.apply(field, id)))))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]).toSet[com.sparkutils.quality.impl.RuleError];
  val viewErrors: Set[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable] = Validation.this.subQueryErrors[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable](viewLookup, exprThunk, if (outputRule)
    ((x$19: String) =&gt; OutputRuleViewError.apply(x$19, id))
  else
    ((x$20: String) =&gt; RuleViewError.apply(x$20, id)));
  val unknown: scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable] = unknownSparkFunctions.map[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((name: com.sparkutils.quality.impl.util.VariablesLookup.Identifier) =&gt; if (outputRule.unary_!)
    SparkFunctionNameError.apply(name, id)
  else
    OuputSparkFunctionNameError.apply(name, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]);
  scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup](rules.++(unknown).++(viewErrors), exl)
}
        </td>
      </tr><tr>
        <td>
          350
        </td>
        <td>
          3941
        </td>
        <td>
          15603
          -
          15603
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._3
        </td>
      </tr><tr>
        <td>
          350
        </td>
        <td>
          3940
        </td>
        <td>
          15591
          -
          15591
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._2
        </td>
      </tr><tr>
        <td>
          350
        </td>
        <td>
          3939
        </td>
        <td>
          15568
          -
          15568
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._1
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          3954
        </td>
        <td>
          15728
          -
          15728
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]
        </td>
      </tr><tr>
        <td>
          353
        </td>
        <td>
          3942
        </td>
        <td>
          15761
          -
          15782
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          names.contains(field)
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          3944
        </td>
        <td>
          15796
          -
          15800
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          3943
        </td>
        <td>
          15796
          -
          15800
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          3945
        </td>
        <td>
          15796
          -
          15800
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          356
        </td>
        <td>
          3953
        </td>
        <td>
          15828
          -
          15985
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id)))
        </td>
      </tr><tr>
        <td>
          356
        </td>
        <td>
          3952
        </td>
        <td>
          15828
          -
          15985
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id)))
        </td>
      </tr><tr>
        <td>
          356
        </td>
        <td>
          3951
        </td>
        <td>
          15828
          -
          15985
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id))
        </td>
      </tr><tr>
        <td>
          357
        </td>
        <td>
          3946
        </td>
        <td>
          15852
          -
          15863
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          358
        </td>
        <td>
          3947
        </td>
        <td>
          15881
          -
          15905
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          358
        </td>
        <td>
          3948
        </td>
        <td>
          15881
          -
          15905
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          360
        </td>
        <td>
          3950
        </td>
        <td>
          15941
          -
          15971
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          360
        </td>
        <td>
          3949
        </td>
        <td>
          15941
          -
          15971
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          3955
        </td>
        <td>
          15710
          -
          16010
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprFields.flatMap[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((field: com.sparkutils.quality.impl.util.VariablesLookup.Identifier) =&gt; if (names.contains(field))
  scala.this.Option.option2Iterable[Nothing](scala.None)
else
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
    RuleNameError.apply(field, id)
  else
    OutputRuleNameError.apply(field, id)))))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]).toSet[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          364
        </td>
        <td>
          3959
        </td>
        <td>
          16121
          -
          16141
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((x$20: String) =&gt; RuleViewError.apply(x$20, id))
        </td>
      </tr><tr>
        <td>
          364
        </td>
        <td>
          3956
        </td>
        <td>
          16089
          -
          16115
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleViewError.apply(x$19, id)
        </td>
      </tr><tr>
        <td>
          364
        </td>
        <td>
          3958
        </td>
        <td>
          16121
          -
          16141
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleViewError.apply(x$20, id)
        </td>
      </tr><tr>
        <td>
          364
        </td>
        <td>
          3960
        </td>
        <td>
          16035
          -
          16142
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable](viewLookup, exprThunk, if (outputRule)
  ((x$19: String) =&gt; OutputRuleViewError.apply(x$19, id))
else
  ((x$20: String) =&gt; RuleViewError.apply(x$20, id)))
        </td>
      </tr><tr>
        <td>
          364
        </td>
        <td>
          3957
        </td>
        <td>
          16089
          -
          16115
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((x$19: String) =&gt; OutputRuleViewError.apply(x$19, id))
        </td>
      </tr><tr>
        <td>
          366
        </td>
        <td>
          3967
        </td>
        <td>
          16164
          -
          16335
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownSparkFunctions.map[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((name: com.sparkutils.quality.impl.util.VariablesLookup.Identifier) =&gt; if (outputRule.unary_!)
  SparkFunctionNameError.apply(name, id)
else
  OuputSparkFunctionNameError.apply(name, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable])
        </td>
      </tr><tr>
        <td>
          366
        </td>
        <td>
          3966
        </td>
        <td>
          16189
          -
          16189
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]
        </td>
      </tr><tr>
        <td>
          367
        </td>
        <td>
          3961
        </td>
        <td>
          16211
          -
          16222
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          368
        </td>
        <td>
          3962
        </td>
        <td>
          16234
          -
          16266
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.SparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          SparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          368
        </td>
        <td>
          3963
        </td>
        <td>
          16234
          -
          16266
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.SparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          SparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          3964
        </td>
        <td>
          16290
          -
          16327
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OuputSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OuputSparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          3965
        </td>
        <td>
          16290
          -
          16327
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OuputSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OuputSparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          373
        </td>
        <td>
          3968
        </td>
        <td>
          16344
          -
          16374
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rules.++(unknown).++(viewErrors)
        </td>
      </tr><tr>
        <td>
          373
        </td>
        <td>
          3969
        </td>
        <td>
          16343
          -
          16380
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup](rules.++(unknown).++(viewErrors), exl)
        </td>
      </tr><tr>
        <td>
          375
        </td>
        <td>
          3978
        </td>
        <td>
          16423
          -
          16567
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleError](if (outputRule.unary_!)
  RuleSyntaxError.apply(id, e.getMessage())
else
  OutputRuleSyntaxError.apply(id, e.getMessage()))
        </td>
      </tr><tr>
        <td>
          375
        </td>
        <td>
          3984
        </td>
        <td>
          16422
          -
          16598
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.util.ExpressionLookup](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleError](if (outputRule.unary_!)
  RuleSyntaxError.apply(id, e.getMessage())
else
  OutputRuleSyntaxError.apply(id, e.getMessage())), com.sparkutils.quality.impl.util.ExpressionLookup.apply(com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$1, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$2, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$3, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$4))
        </td>
      </tr><tr>
        <td>
          376
        </td>
        <td>
          3971
        </td>
        <td>
          16440
          -
          16451
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          377
        </td>
        <td>
          3973
        </td>
        <td>
          16463
          -
          16496
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          377
        </td>
        <td>
          3972
        </td>
        <td>
          16483
          -
          16495
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Throwable.getMessage
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.getMessage()
        </td>
      </tr><tr>
        <td>
          377
        </td>
        <td>
          3974
        </td>
        <td>
          16463
          -
          16496
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          379
        </td>
        <td>
          3977
        </td>
        <td>
          16520
          -
          16559
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          379
        </td>
        <td>
          3976
        </td>
        <td>
          16520
          -
          16559
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          379
        </td>
        <td>
          3975
        </td>
        <td>
          16546
          -
          16558
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Throwable.getMessage
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.getMessage()
        </td>
      </tr><tr>
        <td>
          380
        </td>
        <td>
          3980
        </td>
        <td>
          16579
          -
          16579
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$2
        </td>
      </tr><tr>
        <td>
          380
        </td>
        <td>
          3982
        </td>
        <td>
          16579
          -
          16579
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$4
        </td>
      </tr><tr>
        <td>
          380
        </td>
        <td>
          3979
        </td>
        <td>
          16579
          -
          16579
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$1
        </td>
      </tr><tr>
        <td>
          380
        </td>
        <td>
          3981
        </td>
        <td>
          16579
          -
          16579
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$3
        </td>
      </tr><tr>
        <td>
          380
        </td>
        <td>
          3983
        </td>
        <td>
          16569
          -
          16597
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.ExpressionLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.ExpressionLookup.apply(com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$1, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$2, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$3, com.sparkutils.quality.impl.util.ExpressionLookup.apply$default$4)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>