<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/impl/bloom/parquet/Bucketed.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality.impl.bloom.parquet
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality.impl.util.{BytePackingUtils, TSLocal, TransientHolder}
</span>4 <span style=''>import java.io._
</span>5 <span style=''>import com.sparkutils.quality.{BloomLookup, BloomModel}
</span>6 <span style=''>import org.apache.spark.sql.internal.SQLConf
</span>7 <span style=''>import org.apache.spark.sql.{DataFrame, SparkSession}
</span>8 <span style=''>
</span>9 <span style=''>object Bucketed {
</span>10 <span style=''>
</span>11 <span style=''>  // just two is:
</span>12 <span style=''>  //generated bloom map of 1000000000 entries in 9 m
</span>13 <span style=''>  //before actual count 0 824404383 (824404383) false positives took 9 m
</span>14 <span style=''>
</span>15 <span style=''>  //generated bloom map of 1000000000 entries in 9 m
</span>16 <span style=''>  //before actual count 0 273489593 (273489593) false positives took 11 m &lt;-- saturated even with 4, so need some math to figure out buckets to use
</span>17 <span style=''>
</span>18 <span style=''>  // generated bloom map of 1000000000 entries in 10 m
</span>19 <span style=''>  //before actual count 0     24650171 (24650171) false positives took 9 m &lt;-- 8 buckets max on each at 0.001 configured but then only 0.024 real with 8 buckets - still not &quot;bad&quot;
</span>20 <span style=''>
</span>21 <span style=''>  // generated bloom map of 1000000000 entries in 11 m
</span>22 <span style=''>  //before actual count 0      1270757 (1270757) false positives took 12 m &lt;-- 15 0.0012
</span>23 <span style=''>
</span>24 <span style=''>  def whichBloom(hash: Long, buckets: Int): Int = {
</span>25 <span style=''>    (</span><span style='background: #AEF1AE'>hash % buckets).abs.toInt</span><span style=''>  // the below is either 2, 4, or 8 to be useful, 16 is already too many buckets for a byte array
</span>26 <span style=''>  }
</span>27 <span style=''>
</span>28 <span style=''>
</span>29 <span style=''>}
</span>30 <span style=''>
</span>31 <span style=''>case class FileRoot(location: String) {
</span>32 <span style=''>  def asFile = </span><span style='background: #AEF1AE'>new File(location)</span><span style=''>
</span>33 <span style=''>}
</span>34 <span style=''>
</span>35 <span style=''>case class BucketedFilesRoot(bloomFileLocation: FileRoot, bloomId: String = java.util.UUID.randomUUID().toString) {
</span>36 <span style=''>  def fileLocation: File = {
</span>37 <span style=''>    val root = </span><span style='background: #AEF1AE'>new File(bloomFileLocation.asFile, bloomId)</span><span style=''>
</span>38 <span style=''>    </span><span style='background: #AEF1AE'>root.mkdir()</span><span style=''>
</span>39 <span style=''>    root
</span>40 <span style=''>  }
</span>41 <span style=''>}
</span>42 <span style=''>
</span>43 <span style=''>trait ToSerializedType[T, H] extends Serializable {
</span>44 <span style=''>  def serializeBuckets(filters: Seq[BlockSplitBloomFilterImpl], fpp: Double, numBuckets: Int, hint: H): Array[Byte]
</span>45 <span style=''>}
</span>46 <span style=''>
</span>47 <span style=''>object BucketedCreator {
</span>48 <span style=''>
</span>49 <span style=''>  /**
</span>50 <span style=''>   * Generates a bloom filter using the expression passed via bloomOn with optional repartitioning and a default fpp of 0.01.
</span>51 <span style=''>   * A unique run will be created so other results can co-exist but this can be overridden by specifying bloomId.
</span>52 <span style=''>   * The other interim result files will be removed and the resulting BucketedFiles can be used in lookups or stored elsewhere.
</span>53 <span style=''>   *
</span>54 <span style=''>   * @param dataFrame
</span>55 <span style=''>   * @param bloomOn a compatible expression to generate the bloom hashes against
</span>56 <span style=''>   * @param expectedSize
</span>57 <span style=''>   * @param fpp
</span>58 <span style=''>   * @param bloomId
</span>59 <span style=''>   * @param partitions
</span>60 <span style=''>   * @return
</span>61 <span style=''>   */
</span>62 <span style=''>  def bloomFrom(dataFrame: DataFrame, bloomOn: String, expectedSize: Long,
</span>63 <span style=''>                fpp: Double = 0.01, bloomId: String = java.util.UUID.randomUUID().toString, partitions: Int = 0): BloomModel = {
</span>64 <span style=''>    val df =
</span>65 <span style=''>      if (</span><span style='background: #AEF1AE'>partitions != 0</span><span style=''>)
</span>66 <span style=''>        </span><span style='background: #F0ADAD'>dataFrame.repartition(partitions)</span><span style=''>
</span>67 <span style=''>      else
</span>68 <span style=''>        </span><span style='background: #AEF1AE'>dataFrame</span><span style=''>
</span>69 <span style=''>
</span>70 <span style=''>    val interim = </span><span style='background: #AEF1AE'>df.selectExpr(s&quot;bigBloom($bloomOn, $expectedSize, cast($fpp as double), '$bloomId')&quot;).head.getAs[Array[Byte]](0)</span><span style=''>
</span>71 <span style=''>    val bloom = </span><span style='background: #AEF1AE'>BloomModel.deserialize(interim)</span><span style=''>
</span>72 <span style=''>    </span><span style='background: #AEF1AE'>bloom.cleanupOthers()</span><span style=''>
</span>73 <span style=''>    bloom
</span>74 <span style=''>  }
</span>75 <span style=''>
</span>76 <span style=''>  val bloomFileLocation = {
</span>77 <span style=''>    val defaultRoot = </span><span style='background: #AEF1AE'>SQLConf.get.getConfString(&quot;sparkutils.quality.bloom.root&quot;, &quot;/dbfs/&quot;)</span><span style=''>
</span>78 <span style=''>
</span>79 <span style=''>    // if it's running on databricks use a dbfs dir
</span>80 <span style=''>    val dbfs = </span><span style='background: #AEF1AE'>new File(defaultRoot)</span><span style=''>
</span>81 <span style=''>    val root =
</span>82 <span style=''>      if (</span><span style='background: #AEF1AE'>dbfs.exists()</span><span style=''>)
</span>83 <span style=''>        </span><span style='background: #AEF1AE'>dbfs</span><span style=''>
</span>84 <span style=''>      else </span><span style='background: #AEF1AE'>{
</span>85 <span style=''></span><span style='background: #AEF1AE'>        val temp = File.createTempFile(&quot;quality&quot;, &quot;bloom&quot;)
</span>86 <span style=''></span><span style='background: #AEF1AE'>        val tempPath = temp.getAbsolutePath
</span>87 <span style=''></span><span style='background: #AEF1AE'>        temp.delete()
</span>88 <span style=''></span><span style='background: #AEF1AE'>        new File(tempPath)
</span>89 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>90 <span style=''>
</span>91 <span style=''>    val fl = </span><span style='background: #AEF1AE'>new File(root, &quot;quality_bloom&quot;)</span><span style=''>
</span>92 <span style=''>    </span><span style='background: #AEF1AE'>fl.mkdirs()</span><span style=''>
</span>93 <span style=''>    </span><span style='background: #AEF1AE'>fl.getAbsolutePath</span><span style=''>
</span>94 <span style=''>  }
</span>95 <span style=''>
</span>96 <span style=''>  implicit val toLocalFiles = </span><span style='background: #AEF1AE'>new</span><span style=''> ToSerializedType[Array[Array[Byte]], BucketedFilesRoot] {
</span>97 <span style=''>    def serializeBuckets(filters: Seq[BlockSplitBloomFilterImpl], fpp: Double, numBuckets: Int, hint: BucketedFilesRoot): Array[Byte] = {
</span>98 <span style=''>      // verify there is no file, get id until it's done
</span>99 <span style=''>      var id: String = </span><span style='background: #AEF1AE'>null</span><span style=''>
</span>100 <span style=''>      var dir: File = </span><span style='background: #AEF1AE'>null</span><span style=''>
</span>101 <span style=''>      do {
</span>102 <span style=''>        id = </span><span style='background: #AEF1AE'>java.util.UUID.randomUUID().toString</span><span style=''>
</span>103 <span style=''>        dir = </span><span style='background: #AEF1AE'>new File(hint.fileLocation, id)</span><span style=''>
</span>104 <span style=''>      } while (</span><span style='background: #AEF1AE'>dir.exists()</span><span style=''>)
</span>105 <span style=''>      </span><span style='background: #AEF1AE'>dir.mkdirs()</span><span style=''>
</span>106 <span style=''>
</span>107 <span style=''>      </span><span style='background: #AEF1AE'>for {i &lt;- 0 until numBuckets} {
</span>108 <span style=''></span><span style='background: #AEF1AE'>        val fos = new FileOutputStream(new File(dir, i.toString))
</span>109 <span style=''></span><span style='background: #AEF1AE'>        filters(i).intBufferGen.get().bytes.fold(
</span>110 <span style=''></span><span style='background: #AEF1AE'>          for {j &lt;- </span><span style='background: #F0ADAD'>0</span><span style='background: #AEF1AE'> until </span><span style='background: #F0ADAD'>filters(i).intBuffer.limit</span><span style='background: #AEF1AE'>} {
</span>111 <span style=''></span><span style='background: #AEF1AE'>            val theInt = </span><span style='background: #F0ADAD'>filters(i).intBuffer.get(j)</span><span style='background: #AEF1AE'>
</span>112 <span style=''></span><span style='background: #AEF1AE'>            </span><span style='background: #F0ADAD'>fos.write(theInt.toByte)</span><span style='background: #AEF1AE'>
</span>113 <span style=''></span><span style='background: #AEF1AE'>            </span><span style='background: #F0ADAD'>fos.write((theInt &gt;&gt; 8).toByte)</span><span style='background: #AEF1AE'>
</span>114 <span style=''></span><span style='background: #AEF1AE'>            </span><span style='background: #F0ADAD'>fos.write((theInt &gt;&gt; 16).toByte)</span><span style='background: #AEF1AE'>
</span>115 <span style=''></span><span style='background: #AEF1AE'>            </span><span style='background: #F0ADAD'>fos.write((theInt &gt;&gt; 24).toByte)</span><span style='background: #AEF1AE'>
</span>116 <span style=''></span><span style='background: #AEF1AE'>          }
</span>117 <span style=''></span><span style='background: #AEF1AE'>        ) {
</span>118 <span style=''></span><span style='background: #AEF1AE'>          bytes =&gt; // faster if we have the underlying
</span>119 <span style=''></span><span style='background: #AEF1AE'>            fos.write(bytes)
</span>120 <span style=''></span><span style='background: #AEF1AE'>        }
</span>121 <span style=''></span><span style='background: #AEF1AE'>        fos.close()
</span>122 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>123 <span style=''>
</span>124 <span style=''>      val bucketedFiles = </span><span style='background: #AEF1AE'>BloomModel(dir.getAbsolutePath, fpp, numBuckets)</span><span style=''>
</span>125 <span style=''>      </span><span style='background: #AEF1AE'>bucketedFiles.serialize</span><span style=''>
</span>126 <span style=''>    }
</span>127 <span style=''>  }
</span>128 <span style=''>
</span>129 <span style=''>  /**
</span>130 <span style=''>   * Creates Buckets of Blooms based on assuming rounding and overflow behaviour for the Array[Byte] produced, leaving a maximum number of buckets of 15.
</span>131 <span style=''>   *
</span>132 <span style=''>   * To give an idea of what this means in practice:
</span>133 <span style=''>   * {{{
</span>134 <span style=''>   * 2750000000L for 0.1 will yield the max 15 buckets, anything below will be 0.1 (2.7b and below)
</span>135 <span style=''>   * 1663500000L for 0.01 will yield the max 15 buckets, anything below will be 0.01 (1.6b and below)
</span>136 <span style=''>   * 1102000000L for 0.001 will yield the max 15 buckets
</span>137 <span style=''>   *  760000000L for 0.0001 will yield the max 15 buckets
</span>138 <span style=''>   * }}}
</span>139 <span style=''>   *
</span>140 <span style=''>   * NOTE In the current impl overflows and weird results will occur with higher numbers of elements than 2.7b and 0.1.
</span>141 <span style=''>   *
</span>142 <span style=''>   * @param numBytes - calculate with optimalNumOfBits
</span>143 <span style=''>   * @param numBuckets - calculate with optimalNumberOfBuckets, only 15 max are possible with SerializedType as Array[Byte]
</span>144 <span style=''>   * @return
</span>145 <span style=''>   */
</span>146 <span style=''>  def apply[H, SerializedType: ({ type T[SerializedType] = ToSerializedType[SerializedType, H]})#T](numBytes: Int, numBuckets: Int, fpp: Double, hashImpl: BloomHash, hint: H): BucketedCreator[H, SerializedType] =
</span>147 <span style=''>    </span><span style='background: #AEF1AE'>BucketedCreator(numBytes, BlockSplitBloomFilterImpl.LOWER_BOUND_BYTES, BlockSplitBloomFilterImpl.UPPER_BOUND_BYTES,
</span>148 <span style=''></span><span style='background: #AEF1AE'>      hashImpl, fpp, numBuckets, implicitly[ToSerializedType[SerializedType, H]], hint)()</span><span style=''>
</span>149 <span style=''>
</span>150 <span style=''>  def apply[H, SerializedType: ({ type T[SerializedType] = ToSerializedType[SerializedType, H]})#T](numBytes: Int, numBuckets: Int, fpp: Double, hint: H): BucketedCreator[H, SerializedType] =
</span>151 <span style=''>    </span><span style='background: #AEF1AE'>apply(numBytes, numBuckets, fpp, new BloomHashImpl(BloomFilter.XXH64), hint)</span><span style=''>
</span>152 <span style=''>
</span>153 <span style=''>  def impl[H, SerializedType: ({ type T[SerializedType] = ToSerializedType[SerializedType, H]})#T](bitArrays: Array[Array[Byte]], hashImpl: BloomHash, fpp: Double, hint: H): BucketedCreator[H, SerializedType] =
</span>154 <span style=''>    </span><span style='background: #AEF1AE'>BucketedCreator[H, SerializedType](0, BlockSplitBloomFilterImpl.LOWER_BOUND_BYTES, BlockSplitBloomFilterImpl.UPPER_BOUND_BYTES,
</span>155 <span style=''></span><span style='background: #AEF1AE'>      hashImpl, fpp, bitArrays.length, implicitly[ToSerializedType[SerializedType, H]], hint)( {
</span>156 <span style=''></span><span style='background: #AEF1AE'>      (0 until bitArrays.length).map { i =&gt;
</span>157 <span style=''></span><span style='background: #AEF1AE'>        BlockSplitBloomFilterImpl.fromBytes(bitArrays(i))
</span>158 <span style=''></span><span style='background: #AEF1AE'>      }
</span>159 <span style=''></span><span style='background: #AEF1AE'>    })</span><span style=''>
</span>160 <span style=''>
</span>161 <span style=''>  def apply(bitArrays: Array[Array[Byte]], hashImpl: BloomHash, fpp: Double, hint: BucketedFilesRoot): BucketedCreator[BucketedFilesRoot, Array[Array[Byte]]] =
</span>162 <span style=''>    </span><span style='background: #AEF1AE'>impl(bitArrays, hashImpl, fpp, hint)</span><span style=''>
</span>163 <span style=''>
</span>164 <span style=''>  def apply(bitArrays: Array[Array[Byte]], fpp: Double, hint: BucketedFilesRoot): BucketedCreator[BucketedFilesRoot, Array[Array[Byte]]] =
</span>165 <span style=''>    </span><span style='background: #AEF1AE'>apply(bitArrays, new BloomHashImpl(BloomFilter.XXH64), fpp, hint)</span><span style=''>
</span>166 <span style=''>
</span>167 <span style=''>}
</span>168 <span style=''>
</span>169 <span style=''>/**
</span>170 <span style=''> * Buckets smaller optimised blooms by a mod on bucket size with array backing by default
</span>171 <span style=''> *
</span>172 <span style=''> * @param numBytes
</span>173 <span style=''> * @param iMinimumBytes
</span>174 <span style=''> * @param iMaximumBytes
</span>175 <span style=''> * @param hashImpl
</span>176 <span style=''> * @param numBuckets max is 15 algo wise but 8 breaks defaults for  spark.driver.maxResultSize on local 1gb it's 4g on db
</span>177 <span style=''> */
</span>178 <span style=''>case class BucketedCreator[H, SerializedType](numBytes: Int, iMinimumBytes: Int, iMaximumBytes: Int, hashImpl: BloomHash, fpp: Double, numBuckets: Int,
</span>179 <span style=''>                                           toType: ToSerializedType[SerializedType, H], hint: H)(
</span>180 <span style=''>  val filters: Seq[BlockSplitBloomFilterImpl] = (1 to numBuckets).map(_ =&gt; BlockSplitBloomFilterImpl(numBytes, iMinimumBytes, iMaximumBytes, hashImpl)),
</span>181 <span style=''>  val bucketedFiles: Option[BloomModel] = None
</span>182 <span style=''>) extends Bloom[SerializedType] {
</span>183 <span style=''>  type BloomType = BucketedCreator[H, SerializedType]
</span>184 <span style=''>
</span>185 <span style=''>  /** CTw added the or'ing */
</span>186 <span style=''>  def |= (that: BucketedCreator[H, SerializedType]): BucketedCreator[H, SerializedType] = {
</span>187 <span style=''>    </span><span style='background: #AEF1AE'>checkCompatibility(that)</span><span style=''>
</span>188 <span style=''>    // Breeze copies but we'll do in place
</span>189 <span style=''>    </span><span style='background: #AEF1AE'>for(i &lt;- 0 until numBuckets) {
</span>190 <span style=''></span><span style='background: #AEF1AE'>      filters(i) |= that.filters(i)</span><span style=''>
</span>191 <span style=''>    }
</span>192 <span style=''>    this
</span>193 <span style=''>  }
</span>194 <span style=''>
</span>195 <span style=''>  private def checkCompatibility(that: BucketedCreator[H, SerializedType]): Unit =
</span>196 <span style=''>    </span><span style='background: #AEF1AE'>require(iMaximumBytes == that.iMaximumBytes
</span>197 <span style=''></span><span style='background: #AEF1AE'>      &amp;&amp; iMinimumBytes == that.iMinimumBytes &amp;&amp;
</span>198 <span style=''></span><span style='background: #AEF1AE'>      hashImpl.hashStrategy == that.hashImpl.hashStrategy
</span>199 <span style=''></span><span style='background: #AEF1AE'>      &amp;&amp; filters.zip( that.filters ).forall( p =&gt; p._1.intBuffer.limit() == p._2.intBuffer.limit() )
</span>200 <span style=''></span><span style='background: #AEF1AE'>      , &quot;Must have the hash and bitset length to intersect&quot;)</span><span style=''>
</span>201 <span style=''>
</span>202 <span style=''>  def += (value: Any) = {
</span>203 <span style=''>    val h = </span><span style='background: #AEF1AE'>hashImpl.hash(value)</span><span style=''>
</span>204 <span style=''>    </span><span style='background: #AEF1AE'>filters(Bucketed.whichBloom(h, numBuckets)).insertHash(h)</span><span style=''>
</span>205 <span style=''>    </span><span style='background: #AEF1AE'>this.asInstanceOf[BloomType]</span><span style=''>
</span>206 <span style=''>  }
</span>207 <span style=''>
</span>208 <span style=''>  /**
</span>209 <span style=''>   * Combines all the buckets together via the serialize type.  If this is already linked to memory mapped files
</span>210 <span style=''>   * do not re-write, just serialize the bucketedFiles reference
</span>211 <span style=''>   * @return combined serialized blooms
</span>212 <span style=''>   */
</span>213 <span style=''>  override def serialized: Array[Byte] = </span><span style='background: #AEF1AE'>bucketedFiles.fold(toType.serializeBuckets(filters, fpp, numBuckets, hint))(_.serialize)</span><span style=''>
</span>214 <span style=''>}
</span>215 <span style=''>
</span>216 <span style=''>case class ThreadBucketedLookup(arrays: Array[Array[Byte]], hashImpl: BloomHash) extends com.sparkutils.quality.BloomLookup {
</span>217 <span style=''>
</span>218 <span style=''>  val filters = </span><span style='background: #AEF1AE'>TransientHolder{ () =&gt;
</span>219 <span style=''></span><span style='background: #AEF1AE'>    arrays.map( ThreadLookup(_, hashImpl) )
</span>220 <span style=''></span><span style='background: #AEF1AE'>  }</span><span style=''>
</span>221 <span style=''>
</span>222 <span style=''>  override def mightContain(value: Any): Boolean = {
</span>223 <span style=''>    val h = </span><span style='background: #AEF1AE'>hashImpl.hash(value)</span><span style=''>
</span>224 <span style=''>    </span><span style='background: #AEF1AE'>filters.get.apply(Bucketed.whichBloom(h, arrays.length)).findHash(h)</span><span style=''>
</span>225 <span style=''>  }
</span>226 <span style=''>}
</span>227 <span style=''>
</span>228 <span style=''>/**
</span>229 <span style=''> * The default BlockSplitBloomFilter is not threadsafe for lookup.
</span>230 <span style=''> * This implementation uses a thread local hash preparation for lookup
</span>231 <span style=''> *
</span>232 <span style=''> * @param bucketedFiles the bloom
</span>233 <span style=''> */
</span>234 <span style=''>case class ThreadSafeBucketedBloomLookupLazy(bucketedFiles: BloomModel,
</span>235 <span style=''>                                             hashStrategy: BloomFilter.HashStrategy = BloomFilter.XXH64) extends com.sparkutils.quality.BloomLookup {
</span>236 <span style=''>
</span>237 <span style=''>  // don't ship the bytes but lazy load on each box
</span>238 <span style=''>  val arrays = </span><span style='background: #AEF1AE'>TransientHolder{ () =&gt;
</span>239 <span style=''></span><span style='background: #AEF1AE'>    bucketedFiles.read
</span>240 <span style=''></span><span style='background: #AEF1AE'>  }</span><span style=''>
</span>241 <span style=''>
</span>242 <span style=''>  private val impl: TSLocal[ThreadBucketedLookup] = </span><span style='background: #AEF1AE'>TSLocal[ThreadBucketedLookup]{ () =&gt;
</span>243 <span style=''></span><span style='background: #AEF1AE'>
</span>244 <span style=''></span><span style='background: #AEF1AE'>    ThreadBucketedLookup(arrays.get(), new BloomHashImpl(hashStrategy))
</span>245 <span style=''></span><span style='background: #AEF1AE'>  }</span><span style=''>
</span>246 <span style=''>
</span>247 <span style=''>  override def mightContain(value: Any): Boolean = </span><span style='background: #AEF1AE'>impl.get().mightContain(value)</span><span style=''>
</span>248 <span style=''>
</span>249 <span style=''>}
</span>250 <span style=''>
</span>251 <span style=''>/**
</span>252 <span style=''> * By default eager, optionally lazy which will read the files from the executor
</span>253 <span style=''> */
</span>254 <span style=''>object ThreadSafeBucketedBloomLookup {
</span>255 <span style=''>  def lazyLookup(bucketedFiles: BloomModel) = </span><span style='background: #AEF1AE'>ThreadSafeBucketedBloomLookupLazy(bucketedFiles)</span><span style=''>
</span>256 <span style=''>  def apply(bucketedFiles: BloomModel) = {
</span>257 <span style=''>    val arrays = </span><span style='background: #AEF1AE'>bucketedFiles.read</span><span style=''>
</span>258 <span style=''>
</span>259 <span style=''>    </span><span style='background: #AEF1AE'>ThreadSafeBucketedBloomLookupEager(arrays)</span><span style=''>
</span>260 <span style=''>  }
</span>261 <span style=''>  def mappedLookup(bucketedFiles: BloomModel) = </span><span style='background: #AEF1AE'>ThreadSafeBucketedBloomLookupMapped(bucketedFiles)</span><span style=''>
</span>262 <span style=''>}
</span>263 <span style=''>
</span>264 <span style=''>/**
</span>265 <span style=''> * The default BlockSplitBloomFilter is not threadsafe for lookup.
</span>266 <span style=''> * This implementation uses a thread local hash preparation for lookup
</span>267 <span style=''> *
</span>268 <span style=''> * @param arrays the bloom
</span>269 <span style=''> */
</span>270 <span style=''>case class ThreadSafeBucketedBloomLookupEager(arrays: Array[Array[Byte]],
</span>271 <span style=''>                                         hashStrategy: BloomFilter.HashStrategy = BloomFilter.XXH64) extends BloomLookup {
</span>272 <span style=''>
</span>273 <span style=''>  private val impl: TSLocal[ThreadBucketedLookup] = </span><span style='background: #AEF1AE'>TSLocal[ThreadBucketedLookup]{ () =&gt;
</span>274 <span style=''></span><span style='background: #AEF1AE'>    ThreadBucketedLookup(arrays, new BloomHashImpl(hashStrategy))
</span>275 <span style=''></span><span style='background: #AEF1AE'>  }</span><span style=''>
</span>276 <span style=''>
</span>277 <span style=''>  override def mightContain(value: Any): Boolean = </span><span style='background: #AEF1AE'>impl.get().mightContain(value)</span><span style=''>
</span>278 <span style=''>
</span>279 <span style=''>}
</span>280 <span style=''>
</span>281 <span style=''>case class ThreadBucketedMappedLookup(bucketedFiles: BloomModel, hashImpl: BloomHash) extends BloomLookup {
</span>282 <span style=''>
</span>283 <span style=''>  val filters = </span><span style='background: #AEF1AE'>TransientHolder{ () =&gt;
</span>284 <span style=''></span><span style='background: #AEF1AE'>    bucketedFiles.maps.map( ThreadBufferLookup(_, hashImpl) )
</span>285 <span style=''></span><span style='background: #AEF1AE'>  }</span><span style=''>
</span>286 <span style=''>
</span>287 <span style=''>  override def mightContain(value: Any): Boolean = {
</span>288 <span style=''>    val h = </span><span style='background: #AEF1AE'>hashImpl.hash(value)</span><span style=''>
</span>289 <span style=''>    </span><span style='background: #AEF1AE'>filters.get.apply(Bucketed.whichBloom(h, bucketedFiles.numBuckets)).findHash(h)</span><span style=''>
</span>290 <span style=''>  }
</span>291 <span style=''>}
</span>292 <span style=''>
</span>293 <span style=''>/**
</span>294 <span style=''> * The default BlockSplitBloomFilter is not threadsafe for lookup.
</span>295 <span style=''> * This implementation uses a thread local hash preparation for lookup
</span>296 <span style=''> *
</span>297 <span style=''> * @param bucketedFiles the bloom
</span>298 <span style=''> */
</span>299 <span style=''>case class ThreadSafeBucketedBloomLookupMapped(bucketedFiles: BloomModel,
</span>300 <span style=''>                                               hashStrategy: BloomFilter.HashStrategy = BloomFilter.XXH64) extends BloomLookup {
</span>301 <span style=''>
</span>302 <span style=''>  private val impl: TSLocal[ThreadBucketedMappedLookup] = </span><span style='background: #AEF1AE'>TSLocal[ThreadBucketedMappedLookup]{ () =&gt;
</span>303 <span style=''></span><span style='background: #AEF1AE'>
</span>304 <span style=''></span><span style='background: #AEF1AE'>    ThreadBucketedMappedLookup(bucketedFiles, new BloomHashImpl(hashStrategy))
</span>305 <span style=''></span><span style='background: #AEF1AE'>  }</span><span style=''>
</span>306 <span style=''>
</span>307 <span style=''>  override def mightContain(value: Any): Boolean = </span><span style='background: #AEF1AE'>impl.get().mightContain(value)</span><span style=''>
</span>308 <span style=''>
</span>309 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          25
        </td>
        <td>
          4004
        </td>
        <td>
          1112
          -
          1126
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.%
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          hash.%(buckets)
        </td>
      </tr><tr>
        <td>
          25
        </td>
        <td>
          4005
        </td>
        <td>
          1112
          -
          1137
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Long.toInt
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.longWrapper(hash.%(buckets)).abs.toInt
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          4007
        </td>
        <td>
          1299
          -
          1317
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.io.File(FileRoot.this.location)
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          4006
        </td>
        <td>
          1308
          -
          1316
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.FileRoot.location
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          FileRoot.this.location
        </td>
      </tr><tr>
        <td>
          37
        </td>
        <td>
          4009
        </td>
        <td>
          1516
          -
          1523
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedFilesRoot.bloomId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedFilesRoot.this.bloomId
        </td>
      </tr><tr>
        <td>
          37
        </td>
        <td>
          4008
        </td>
        <td>
          1490
          -
          1514
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.FileRoot.asFile
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedFilesRoot.this.bloomFileLocation.asFile
        </td>
      </tr><tr>
        <td>
          37
        </td>
        <td>
          4010
        </td>
        <td>
          1481
          -
          1524
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.io.File(BucketedFilesRoot.this.bloomFileLocation.asFile, BucketedFilesRoot.this.bloomId)
        </td>
      </tr><tr>
        <td>
          38
        </td>
        <td>
          4011
        </td>
        <td>
          1529
          -
          1541
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.mkdir
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          root.mkdir()
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          4012
        </td>
        <td>
          2567
          -
          2582
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.!=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          partitions.!=(0)
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          4013
        </td>
        <td>
          2592
          -
          2625
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.repartition
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          dataFrame.repartition(partitions)
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          4014
        </td>
        <td>
          2592
          -
          2625
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.spark.sql.Dataset.repartition
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          dataFrame.repartition(partitions)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          4015
        </td>
        <td>
          2645
          -
          2654
        </td>
        <td>
          Ident
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.dataFrame
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          dataFrame
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          4016
        </td>
        <td>
          2674
          -
          2786
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Row.getAs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          df.selectExpr(scala.StringContext.apply(&quot;bigBloom(&quot;, &quot;, &quot;, &quot;, cast(&quot;, &quot; as double), \'&quot;, &quot;\')&quot;).s(bloomOn, expectedSize, fpp, bloomId)).head().getAs[Array[Byte]](0)
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          4017
        </td>
        <td>
          2803
          -
          2834
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.BloomModel.deserialize
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.BloomModel.deserialize(interim)
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          4018
        </td>
        <td>
          2839
          -
          2860
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.BloomModel.cleanupOthers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          bloom.cleanupOthers()
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          4019
        </td>
        <td>
          2926
          -
          2994
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.internal.SQLConf.getConfString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.internal.SQLConf.get.getConfString(&quot;sparkutils.quality.bloom.root&quot;, &quot;/dbfs/&quot;)
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          4020
        </td>
        <td>
          3063
          -
          3084
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.io.File(defaultRoot)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          4021
        </td>
        <td>
          3110
          -
          3123
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.exists
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          dbfs.exists()
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          4022
        </td>
        <td>
          3133
          -
          3137
        </td>
        <td>
          Ident
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.dbfs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          dbfs
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          4027
        </td>
        <td>
          3149
          -
          3310
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val temp: java.io.File = java.io.File.createTempFile(&quot;quality&quot;, &quot;bloom&quot;);
  val tempPath: String = temp.getAbsolutePath();
  temp.delete();
  new java.io.File(tempPath)
}
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          4023
        </td>
        <td>
          3170
          -
          3209
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.createTempFile
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.io.File.createTempFile(&quot;quality&quot;, &quot;bloom&quot;)
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          4024
        </td>
        <td>
          3233
          -
          3253
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.getAbsolutePath
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          temp.getAbsolutePath()
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          4025
        </td>
        <td>
          3262
          -
          3275
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.delete
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          temp.delete()
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          4026
        </td>
        <td>
          3284
          -
          3302
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.io.File(tempPath)
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          4028
        </td>
        <td>
          3325
          -
          3356
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.io.File(root, &quot;quality_bloom&quot;)
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          4029
        </td>
        <td>
          3361
          -
          3372
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.mkdirs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          fl.mkdirs()
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          4030
        </td>
        <td>
          3377
          -
          3395
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.getAbsolutePath
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          fl.getAbsolutePath()
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          4068
        </td>
        <td>
          3431
          -
          3434
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.$anon.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anon()
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          4031
        </td>
        <td>
          3711
          -
          3715
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          null
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          4032
        </td>
        <td>
          3738
          -
          3742
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          null
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          4040
        </td>
        <td>
          3749
          -
          3749
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          4039
        </td>
        <td>
          3749
          -
          3749
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          4038
        </td>
        <td>
          3749
          -
          3749
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.$anon.doWhile$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          doWhile$1()
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          4037
        </td>
        <td>
          3749
          -
          3749
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.$anon.doWhile$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          doWhile$1()
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          4033
        </td>
        <td>
          3767
          -
          3803
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.UUID.toString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.util.UUID.randomUUID().toString()
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          4035
        </td>
        <td>
          3818
          -
          3849
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.io.File(hint.fileLocation, id)
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          4034
        </td>
        <td>
          3827
          -
          3844
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedFilesRoot.fileLocation
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          hint.fileLocation
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          4036
        </td>
        <td>
          3865
          -
          3877
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.exists
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          dir.exists()
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          4041
        </td>
        <td>
          3885
          -
          3897
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.mkdirs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          dir.mkdirs()
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          4042
        </td>
        <td>
          3915
          -
          3916
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          4064
        </td>
        <td>
          3905
          -
          4480
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Range.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.intWrapper(0).until(numBuckets).foreach[Unit](((i: Int) =&gt; {
  val fos: java.io.FileOutputStream = new java.io.FileOutputStream(new java.io.File(dir, i.toString()));
  filters.apply(i).intBufferGen.get().bytes.fold[Unit](scala.Predef.intWrapper(0).until(filters.apply(i).intBuffer.limit()).foreach[Unit](((j: Int) =&gt; {
    val theInt: Int = filters.apply(i).intBuffer.get(j);
    fos.write(theInt.toByte.toInt);
    fos.write(theInt.&gt;&gt;(8).toByte.toInt);
    fos.write(theInt.&gt;&gt;(16).toByte.toInt);
    fos.write(theInt.&gt;&gt;(24).toByte.toInt)
  })))(((bytes: Array[Byte]) =&gt; fos.write(bytes)));
  fos.close()
}))
        </td>
      </tr><tr>
        <td>
          108
        </td>
        <td>
          4045
        </td>
        <td>
          3955
          -
          4002
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.FileOutputStream.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.io.FileOutputStream(new java.io.File(dir, i.toString()))
        </td>
      </tr><tr>
        <td>
          108
        </td>
        <td>
          4044
        </td>
        <td>
          3976
          -
          4001
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.io.File(dir, i.toString())
        </td>
      </tr><tr>
        <td>
          108
        </td>
        <td>
          4043
        </td>
        <td>
          3990
          -
          4000
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.toString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          i.toString()
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          4060
        </td>
        <td>
          4063
          -
          4346
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Range.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.intWrapper(0).until(filters.apply(i).intBuffer.limit()).foreach[Unit](((j: Int) =&gt; {
  val theInt: Int = filters.apply(i).intBuffer.get(j);
  fos.write(theInt.toByte.toInt);
  fos.write(theInt.&gt;&gt;(8).toByte.toInt);
  fos.write(theInt.&gt;&gt;(16).toByte.toInt);
  fos.write(theInt.&gt;&gt;(24).toByte.toInt)
}))
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          4047
        </td>
        <td>
          4081
          -
          4107
        </td>
        <td>
          Apply
        </td>
        <td>
          java.nio.Buffer.limit
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          filters.apply(i).intBuffer.limit()
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          4046
        </td>
        <td>
          4073
          -
          4074
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          0
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          4048
        </td>
        <td>
          4136
          -
          4163
        </td>
        <td>
          Apply
        </td>
        <td>
          java.nio.IntBuffer.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          filters.apply(i).intBuffer.get(j)
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          4049
        </td>
        <td>
          4186
          -
          4199
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Byte.toInt
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          theInt.toByte.toInt
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          4050
        </td>
        <td>
          4176
          -
          4200
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.FileOutputStream.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fos.write(theInt.toByte.toInt)
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          4051
        </td>
        <td>
          4234
          -
          4235
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          8
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          4053
        </td>
        <td>
          4213
          -
          4244
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.FileOutputStream.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fos.write(theInt.&gt;&gt;(8).toByte.toInt)
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          4052
        </td>
        <td>
          4224
          -
          4243
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Byte.toInt
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          theInt.&gt;&gt;(8).toByte.toInt
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          4054
        </td>
        <td>
          4278
          -
          4280
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          16
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          4056
        </td>
        <td>
          4257
          -
          4289
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.FileOutputStream.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fos.write(theInt.&gt;&gt;(16).toByte.toInt)
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          4055
        </td>
        <td>
          4268
          -
          4288
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Byte.toInt
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          theInt.&gt;&gt;(16).toByte.toInt
        </td>
      </tr><tr>
        <td>
          115
        </td>
        <td>
          4058
        </td>
        <td>
          4313
          -
          4333
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Byte.toInt
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          theInt.&gt;&gt;(24).toByte.toInt
        </td>
      </tr><tr>
        <td>
          115
        </td>
        <td>
          4057
        </td>
        <td>
          4323
          -
          4325
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          24
        </td>
      </tr><tr>
        <td>
          115
        </td>
        <td>
          4059
        </td>
        <td>
          4302
          -
          4334
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.FileOutputStream.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fos.write(theInt.&gt;&gt;(24).toByte.toInt)
        </td>
      </tr><tr>
        <td>
          117
        </td>
        <td>
          4062
        </td>
        <td>
          4011
          -
          4452
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.fold
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          filters.apply(i).intBufferGen.get().bytes.fold[Unit](scala.Predef.intWrapper(0).until(filters.apply(i).intBuffer.limit()).foreach[Unit](((j: Int) =&gt; {
  val theInt: Int = filters.apply(i).intBuffer.get(j);
  fos.write(theInt.toByte.toInt);
  fos.write(theInt.&gt;&gt;(8).toByte.toInt);
  fos.write(theInt.&gt;&gt;(16).toByte.toInt);
  fos.write(theInt.&gt;&gt;(24).toByte.toInt)
})))(((bytes: Array[Byte]) =&gt; fos.write(bytes)))
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          4061
        </td>
        <td>
          4426
          -
          4442
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.FileOutputStream.write
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          fos.write(bytes)
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          4063
        </td>
        <td>
          4461
          -
          4472
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.FileOutputStream.close
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          fos.close()
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          4066
        </td>
        <td>
          4508
          -
          4556
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.BloomModel.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.BloomModel.apply(dir.getAbsolutePath(), fpp, numBuckets)
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          4065
        </td>
        <td>
          4519
          -
          4538
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.File.getAbsolutePath
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          dir.getAbsolutePath()
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          4067
        </td>
        <td>
          4563
          -
          4586
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.BloomModel.serialize
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          bucketedFiles.serialize
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          4069
        </td>
        <td>
          5722
          -
          5765
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl.LOWER_BOUND_BYTES
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BlockSplitBloomFilterImpl.LOWER_BOUND_BYTES
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          4072
        </td>
        <td>
          5711
          -
          5711
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.apply$default$9
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.apply$default$9[H, SerializedType](x$1, x$2, x$3, x$4, x$5, x$6, x$7, x$8)
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          4070
        </td>
        <td>
          5767
          -
          5810
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl.UPPER_BOUND_BYTES
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BlockSplitBloomFilterImpl.UPPER_BOUND_BYTES
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          4073
        </td>
        <td>
          5711
          -
          5711
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.apply$default$10
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.apply$default$10[H, SerializedType](x$1, x$2, x$3, x$4, x$5, x$6, x$7, x$8)
        </td>
      </tr><tr>
        <td>
          148
        </td>
        <td>
          4071
        </td>
        <td>
          5845
          -
          5892
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Predef.implicitly
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.implicitly[com.sparkutils.quality.impl.bloom.parquet.ToSerializedType[SerializedType,H]](evidence$1)
        </td>
      </tr><tr>
        <td>
          148
        </td>
        <td>
          4074
        </td>
        <td>
          5696
          -
          5901
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.apply[H, SerializedType](x$1, x$2, x$3, x$4, x$5, x$6, x$7, x$8)(x$9, x$10)
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          4075
        </td>
        <td>
          6099
          -
          6175
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.apply[H, SerializedType](numBytes, numBuckets, fpp, new BloomHashImpl(BloomFilter.XXH64), hint)(evidence$2)
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          4076
        </td>
        <td>
          6427
          -
          6428
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          4087
        </td>
        <td>
          6426
          -
          6426
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.apply$default$10
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.apply$default$10[H, SerializedType](x$1, x$2, x$3, x$4, x$5, x$6, x$7, x$8)
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          4078
        </td>
        <td>
          6475
          -
          6518
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl.UPPER_BOUND_BYTES
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BlockSplitBloomFilterImpl.UPPER_BOUND_BYTES
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          4077
        </td>
        <td>
          6430
          -
          6473
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl.LOWER_BOUND_BYTES
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BlockSplitBloomFilterImpl.LOWER_BOUND_BYTES
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          4080
        </td>
        <td>
          6559
          -
          6606
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Predef.implicitly
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.implicitly[com.sparkutils.quality.impl.bloom.parquet.ToSerializedType[SerializedType,H]](evidence$3)
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          4088
        </td>
        <td>
          6392
          -
          6733
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.apply[H, SerializedType](x$1, x$2, x$3, x$4, x$5, x$6, x$7, x$8)(x$9, x$10)
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          4079
        </td>
        <td>
          6541
          -
          6557
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Array.length
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          bitArrays.length
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          4081
        </td>
        <td>
          6624
          -
          6625
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          4086
        </td>
        <td>
          6624
          -
          6726
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.intWrapper(0).until(bitArrays.length).map[com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, Seq[com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl]](((i: Int) =&gt; BlockSplitBloomFilterImpl.fromBytes(bitArrays.apply(i))))(immutable.this.IndexedSeq.canBuildFrom[com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl])
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          4085
        </td>
        <td>
          6654
          -
          6654
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.IndexedSeq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.IndexedSeq.canBuildFrom[com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl]
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          4082
        </td>
        <td>
          6632
          -
          6648
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Array.length
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          bitArrays.length
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          4084
        </td>
        <td>
          6669
          -
          6718
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl.fromBytes
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BlockSplitBloomFilterImpl.fromBytes(bitArrays.apply(i))
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          4083
        </td>
        <td>
          6705
          -
          6717
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          bitArrays.apply(i)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          4090
        </td>
        <td>
          6899
          -
          6935
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.impl
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.impl[com.sparkutils.quality.impl.bloom.parquet.BucketedFilesRoot, Array[Array[Byte]]](bitArrays, hashImpl, fpp, hint)(BucketedCreator.this.toLocalFiles)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          4089
        </td>
        <td>
          6903
          -
          6903
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.toLocalFiles
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.toLocalFiles
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          4093
        </td>
        <td>
          7080
          -
          7145
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.apply(bitArrays, new BloomHashImpl(BloomFilter.XXH64), fpp, hint)
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          4092
        </td>
        <td>
          7097
          -
          7133
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomHashImpl.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new BloomHashImpl(BloomFilter.XXH64)
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          4091
        </td>
        <td>
          7115
          -
          7132
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomFilter.XXH64
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BloomFilter.XXH64
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          4094
        </td>
        <td>
          8124
          -
          8148
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.checkCompatibility
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.checkCompatibility(that)
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          4096
        </td>
        <td>
          8213
          -
          8223
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.numBuckets
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.numBuckets
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          4099
        </td>
        <td>
          8196
          -
          8262
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Range.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.intWrapper(0).until(BucketedCreator.this.numBuckets).foreach[com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl](((i: Int) =&gt; BucketedCreator.this.filters.apply(i).|=(that.filters.apply(i))))
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          4095
        </td>
        <td>
          8205
          -
          8206
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          4098
        </td>
        <td>
          8233
          -
          8262
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl.|=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.filters.apply(i).|=(that.filters.apply(i))
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          4097
        </td>
        <td>
          8247
          -
          8262
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SeqLike.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          that.filters.apply(i)
        </td>
      </tr><tr>
        <td>
          196
        </td>
        <td>
          4112
        </td>
        <td>
          8370
          -
          8681
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.require(BucketedCreator.this.iMaximumBytes.==(that.iMaximumBytes).&amp;&amp;(BucketedCreator.this.iMinimumBytes.==(that.iMinimumBytes)).&amp;&amp;(BucketedCreator.this.hashImpl.hashStrategy.==(that.hashImpl.hashStrategy)).&amp;&amp;(BucketedCreator.this.filters.zip[com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, Seq[(com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl)]](that.filters)(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl)]).forall(((p: (com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl)) =&gt; p._1.intBuffer.limit().==(p._2.intBuffer.limit())))), &quot;Must have the hash and bitset length to intersect&quot;)
        </td>
      </tr><tr>
        <td>
          196
        </td>
        <td>
          4100
        </td>
        <td>
          8395
          -
          8413
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.iMaximumBytes
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          that.iMaximumBytes
        </td>
      </tr><tr>
        <td>
          197
        </td>
        <td>
          4102
        </td>
        <td>
          8423
          -
          8458
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.iMinimumBytes.==(that.iMinimumBytes)
        </td>
      </tr><tr>
        <td>
          197
        </td>
        <td>
          4101
        </td>
        <td>
          8440
          -
          8458
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.iMinimumBytes
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          that.iMinimumBytes
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          4104
        </td>
        <td>
          8468
          -
          8519
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.hashImpl.hashStrategy.==(that.hashImpl.hashStrategy)
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          4103
        </td>
        <td>
          8493
          -
          8519
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomHash.hashStrategy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          that.hashImpl.hashStrategy
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          4108
        </td>
        <td>
          8570
          -
          8618
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1.intBuffer.limit().==(p._2.intBuffer.limit())
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          4105
        </td>
        <td>
          8542
          -
          8554
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.filters
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          that.filters
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          4107
        </td>
        <td>
          8596
          -
          8618
        </td>
        <td>
          Apply
        </td>
        <td>
          java.nio.Buffer.limit
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.intBuffer.limit()
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          4110
        </td>
        <td>
          8378
          -
          8620
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Boolean.&amp;&amp;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.iMaximumBytes.==(that.iMaximumBytes).&amp;&amp;(BucketedCreator.this.iMinimumBytes.==(that.iMinimumBytes)).&amp;&amp;(BucketedCreator.this.hashImpl.hashStrategy.==(that.hashImpl.hashStrategy)).&amp;&amp;(BucketedCreator.this.filters.zip[com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, Seq[(com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl)]](that.filters)(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl)]).forall(((p: (com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl)) =&gt; p._1.intBuffer.limit().==(p._2.intBuffer.limit()))))
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          4106
        </td>
        <td>
          8540
          -
          8540
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[(com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl)]
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          4109
        </td>
        <td>
          8529
          -
          8620
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.forall
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.filters.zip[com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, Seq[(com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl)]](that.filters)(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl)]).forall(((p: (com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl, com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl)) =&gt; p._1.intBuffer.limit().==(p._2.intBuffer.limit())))
        </td>
      </tr><tr>
        <td>
          200
        </td>
        <td>
          4111
        </td>
        <td>
          8629
          -
          8680
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Must have the hash and bitset length to intersect&quot;
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          4113
        </td>
        <td>
          8721
          -
          8741
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomHash.hash
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.hashImpl.hash(value)
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          4114
        </td>
        <td>
          8746
          -
          8803
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BlockSplitBloomFilterImpl.insertHash
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.filters.apply(Bucketed.whichBloom(h, BucketedCreator.this.numBuckets)).insertHash(h)
        </td>
      </tr><tr>
        <td>
          205
        </td>
        <td>
          4115
        </td>
        <td>
          8808
          -
          8836
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          this.asInstanceOf[BucketedCreator.this.BloomType]
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          4117
        </td>
        <td>
          9165
          -
          9168
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.fpp
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.fpp
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          4120
        </td>
        <td>
          9132
          -
          9187
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ToSerializedType.serializeBuckets
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.toType.serializeBuckets(BucketedCreator.this.filters, BucketedCreator.this.fpp, BucketedCreator.this.numBuckets, BucketedCreator.this.hint)
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          4122
        </td>
        <td>
          9113
          -
          9201
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.fold
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.bucketedFiles.fold[Array[Byte]](BucketedCreator.this.toType.serializeBuckets(BucketedCreator.this.filters, BucketedCreator.this.fpp, BucketedCreator.this.numBuckets, BucketedCreator.this.hint))(((x$2: com.sparkutils.quality.BloomModel) =&gt; x$2.serialize))
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          4116
        </td>
        <td>
          9156
          -
          9163
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.filters
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.filters
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          4119
        </td>
        <td>
          9182
          -
          9186
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.hint
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.hint
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          4121
        </td>
        <td>
          9189
          -
          9200
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.BloomModel.serialize
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2.serialize
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          4118
        </td>
        <td>
          9170
          -
          9180
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BucketedCreator.numBuckets
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          BucketedCreator.this.numBuckets
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          4128
        </td>
        <td>
          9348
          -
          9418
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.TransientHolder.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.TransientHolder.apply[Array[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup]]((() =&gt; scala.Predef.refArrayOps[Array[Byte]](ThreadBucketedLookup.this.arrays).map[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup, Array[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup]](((x$3: Array[Byte]) =&gt; ThreadLookup.apply(x$3, ThreadBucketedLookup.this.hashImpl)))(scala.this.Array.canBuildFrom[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup]((ClassTag.apply[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup](classOf[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup]): scala.reflect.ClassTag[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup])))))
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          4126
        </td>
        <td>
          9385
          -
          9385
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Array.canBuildFrom[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup]((ClassTag.apply[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup](classOf[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup]): scala.reflect.ClassTag[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup]))
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          4123
        </td>
        <td>
          9375
          -
          9381
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedLookup.arrays
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedLookup.this.arrays
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          4125
        </td>
        <td>
          9387
          -
          9412
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadLookup.apply(x$3, ThreadBucketedLookup.this.hashImpl)
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          4124
        </td>
        <td>
          9403
          -
          9411
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedLookup.hashImpl
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedLookup.this.hashImpl
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          4127
        </td>
        <td>
          9375
          -
          9414
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[Array[Byte]](ThreadBucketedLookup.this.arrays).map[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup, Array[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup]](((x$3: Array[Byte]) =&gt; ThreadLookup.apply(x$3, ThreadBucketedLookup.this.hashImpl)))(scala.this.Array.canBuildFrom[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup]((ClassTag.apply[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup](classOf[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup]): scala.reflect.ClassTag[com.sparkutils.quality.impl.bloom.parquet.ThreadLookup])))
        </td>
      </tr><tr>
        <td>
          223
        </td>
        <td>
          4129
        </td>
        <td>
          9485
          -
          9505
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomHash.hash
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedLookup.this.hashImpl.hash(value)
        </td>
      </tr><tr>
        <td>
          224
        </td>
        <td>
          4130
        </td>
        <td>
          9510
          -
          9578
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomLookupImpl.findHash
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedLookup.this.filters.get().apply(Bucketed.whichBloom(h, ThreadBucketedLookup.this.arrays.length)).findHash(h)
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          4132
        </td>
        <td>
          10059
          -
          10108
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.TransientHolder.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.TransientHolder.apply[Array[Array[Byte]]]((() =&gt; ThreadSafeBucketedBloomLookupLazy.this.bucketedFiles.read))
        </td>
      </tr><tr>
        <td>
          239
        </td>
        <td>
          4131
        </td>
        <td>
          10086
          -
          10104
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.BloomModel.read
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupLazy.this.bucketedFiles.read
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          4137
        </td>
        <td>
          10162
          -
          10275
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.TSLocal.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.TSLocal.apply[com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedLookup]((() =&gt; ThreadBucketedLookup.apply(ThreadSafeBucketedBloomLookupLazy.this.arrays.get(), new BloomHashImpl(ThreadSafeBucketedBloomLookupLazy.this.hashStrategy))))
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          4135
        </td>
        <td>
          10239
          -
          10270
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomHashImpl.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new BloomHashImpl(ThreadSafeBucketedBloomLookupLazy.this.hashStrategy)
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          4134
        </td>
        <td>
          10257
          -
          10269
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupLazy.hashStrategy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupLazy.this.hashStrategy
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          4133
        </td>
        <td>
          10225
          -
          10237
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.TransientHolder.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupLazy.this.arrays.get()
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          4136
        </td>
        <td>
          10204
          -
          10271
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedLookup.apply(ThreadSafeBucketedBloomLookupLazy.this.arrays.get(), new BloomHashImpl(ThreadSafeBucketedBloomLookupLazy.this.hashStrategy))
        </td>
      </tr><tr>
        <td>
          247
        </td>
        <td>
          4138
        </td>
        <td>
          10328
          -
          10358
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedLookup.mightContain
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupLazy.this.impl.get().mightContain(value)
        </td>
      </tr><tr>
        <td>
          255
        </td>
        <td>
          4140
        </td>
        <td>
          10537
          -
          10585
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupLazy.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupLazy.apply(bucketedFiles, ThreadSafeBucketedBloomLookupLazy.apply$default$2)
        </td>
      </tr><tr>
        <td>
          255
        </td>
        <td>
          4139
        </td>
        <td>
          10537
          -
          10537
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupLazy.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupLazy.apply$default$2
        </td>
      </tr><tr>
        <td>
          257
        </td>
        <td>
          4141
        </td>
        <td>
          10646
          -
          10664
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.BloomModel.read
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          bucketedFiles.read
        </td>
      </tr><tr>
        <td>
          259
        </td>
        <td>
          4143
        </td>
        <td>
          10670
          -
          10712
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupEager.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupEager.apply(arrays, ThreadSafeBucketedBloomLookupEager.apply$default$2)
        </td>
      </tr><tr>
        <td>
          259
        </td>
        <td>
          4142
        </td>
        <td>
          10670
          -
          10670
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupEager.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupEager.apply$default$2
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          4144
        </td>
        <td>
          10765
          -
          10765
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupMapped.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupMapped.apply$default$2
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          4145
        </td>
        <td>
          10765
          -
          10815
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupMapped.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupMapped.apply(bucketedFiles, ThreadSafeBucketedBloomLookupMapped.apply$default$2)
        </td>
      </tr><tr>
        <td>
          273
        </td>
        <td>
          4150
        </td>
        <td>
          11245
          -
          11351
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.TSLocal.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.TSLocal.apply[com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedLookup]((() =&gt; ThreadBucketedLookup.apply(ThreadSafeBucketedBloomLookupEager.this.arrays, new BloomHashImpl(ThreadSafeBucketedBloomLookupEager.this.hashStrategy))))
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          4147
        </td>
        <td>
          11333
          -
          11345
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupEager.hashStrategy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupEager.this.hashStrategy
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          4149
        </td>
        <td>
          11286
          -
          11347
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedLookup.apply(ThreadSafeBucketedBloomLookupEager.this.arrays, new BloomHashImpl(ThreadSafeBucketedBloomLookupEager.this.hashStrategy))
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          4146
        </td>
        <td>
          11307
          -
          11313
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupEager.arrays
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupEager.this.arrays
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          4148
        </td>
        <td>
          11315
          -
          11346
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomHashImpl.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new BloomHashImpl(ThreadSafeBucketedBloomLookupEager.this.hashStrategy)
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          4151
        </td>
        <td>
          11404
          -
          11434
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedLookup.mightContain
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupEager.this.impl.get().mightContain(value)
        </td>
      </tr><tr>
        <td>
          283
        </td>
        <td>
          4156
        </td>
        <td>
          11564
          -
          11652
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.TransientHolder.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.TransientHolder.apply[Seq[com.sparkutils.quality.impl.bloom.parquet.ThreadBufferLookup]]((() =&gt; ThreadBucketedMappedLookup.this.bucketedFiles.maps.map[com.sparkutils.quality.impl.bloom.parquet.ThreadBufferLookup, Seq[com.sparkutils.quality.impl.bloom.parquet.ThreadBufferLookup]](((x$4: java.nio.IntBuffer) =&gt; ThreadBufferLookup.apply(x$4, ThreadBucketedMappedLookup.this.hashImpl)))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.bloom.parquet.ThreadBufferLookup])))
        </td>
      </tr><tr>
        <td>
          284
        </td>
        <td>
          4153
        </td>
        <td>
          11615
          -
          11646
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadBufferLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBufferLookup.apply(x$4, ThreadBucketedMappedLookup.this.hashImpl)
        </td>
      </tr><tr>
        <td>
          284
        </td>
        <td>
          4152
        </td>
        <td>
          11637
          -
          11645
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedMappedLookup.hashImpl
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedMappedLookup.this.hashImpl
        </td>
      </tr><tr>
        <td>
          284
        </td>
        <td>
          4155
        </td>
        <td>
          11591
          -
          11648
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedMappedLookup.this.bucketedFiles.maps.map[com.sparkutils.quality.impl.bloom.parquet.ThreadBufferLookup, Seq[com.sparkutils.quality.impl.bloom.parquet.ThreadBufferLookup]](((x$4: java.nio.IntBuffer) =&gt; ThreadBufferLookup.apply(x$4, ThreadBucketedMappedLookup.this.hashImpl)))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.bloom.parquet.ThreadBufferLookup])
        </td>
      </tr><tr>
        <td>
          284
        </td>
        <td>
          4154
        </td>
        <td>
          11613
          -
          11613
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.bloom.parquet.ThreadBufferLookup]
        </td>
      </tr><tr>
        <td>
          288
        </td>
        <td>
          4157
        </td>
        <td>
          11719
          -
          11739
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomHash.hash
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedMappedLookup.this.hashImpl.hash(value)
        </td>
      </tr><tr>
        <td>
          289
        </td>
        <td>
          4158
        </td>
        <td>
          11744
          -
          11823
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomLookupImpl.findHash
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedMappedLookup.this.filters.get().apply(Bucketed.whichBloom(h, ThreadBucketedMappedLookup.this.bucketedFiles.numBuckets)).findHash(h)
        </td>
      </tr><tr>
        <td>
          302
        </td>
        <td>
          4163
        </td>
        <td>
          12276
          -
          12402
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.TSLocal.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.TSLocal.apply[com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedMappedLookup]((() =&gt; ThreadBucketedMappedLookup.apply(ThreadSafeBucketedBloomLookupMapped.this.bucketedFiles, new BloomHashImpl(ThreadSafeBucketedBloomLookupMapped.this.hashStrategy))))
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          4162
        </td>
        <td>
          12324
          -
          12398
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedMappedLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadBucketedMappedLookup.apply(ThreadSafeBucketedBloomLookupMapped.this.bucketedFiles, new BloomHashImpl(ThreadSafeBucketedBloomLookupMapped.this.hashStrategy))
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          4159
        </td>
        <td>
          12351
          -
          12364
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupMapped.bucketedFiles
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupMapped.this.bucketedFiles
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          4161
        </td>
        <td>
          12366
          -
          12397
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.BloomHashImpl.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new BloomHashImpl(ThreadSafeBucketedBloomLookupMapped.this.hashStrategy)
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          4160
        </td>
        <td>
          12384
          -
          12396
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadSafeBucketedBloomLookupMapped.hashStrategy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupMapped.this.hashStrategy
        </td>
      </tr><tr>
        <td>
          307
        </td>
        <td>
          4164
        </td>
        <td>
          12455
          -
          12485
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.bloom.parquet.ThreadBucketedMappedLookup.mightContain
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ThreadSafeBucketedBloomLookupMapped.this.impl.get().mightContain(value)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>