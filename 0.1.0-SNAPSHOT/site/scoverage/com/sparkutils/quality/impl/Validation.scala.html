<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/impl/Validation.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality.impl
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality
</span>4 <span style=''>import com.sparkutils.quality.VariablesLookup.Identifiers
</span>5 <span style=''>import com.sparkutils.quality.impl.Validation.validate
</span>6 <span style=''>import com.sparkutils.quality.utils.RuleSuiteDocs.{IdTrEither, LambdaId, OutputExpressionId, RuleId}
</span>7 <span style=''>import com.sparkutils.quality.utils.{Docs, DocsParser, RuleSuiteDocs, WithDocs}
</span>8 <span style=''>import com.sparkutils.quality.{ExpressionLookup, ExpressionRule, HasExpr, HasRuleText, Id, NoOpRunOnPassProcessor, OutputExpression, Rule, RuleLogicUtils, RuleSuite, RunOnPassProcessor, VariablesLookup, namesFromSchema}
</span>9 <span style=''>import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation
</span>10 <span style=''>import org.apache.spark.sql.{Column, DataFrame, QualitySparkUtils, Row, SparkSession}
</span>11 <span style=''>import org.apache.spark.sql.catalyst.expressions.{Expression, LambdaFunction, SubqueryExpression}
</span>12 <span style=''>import org.apache.spark.sql.catalyst.plans.logical.Project
</span>13 <span style=''>import org.apache.spark.sql.types.StructType
</span>14 <span style=''>
</span>15 <span style=''>import scala.collection.mutable
</span>16 <span style=''>
</span>17 <span style=''>sealed trait RuleRelevant
</span>18 <span style=''>sealed trait LambdaRelevant
</span>19 <span style=''>sealed trait OutputExpressionRelevant
</span>20 <span style=''>
</span>21 <span style=''>sealed trait HasId {
</span>22 <span style=''>  def id: Id
</span>23 <span style=''>}
</span>24 <span style=''>
</span>25 <span style=''>sealed trait HasOutputText {
</span>26 <span style=''>  def outputText: String
</span>27 <span style=''>}
</span>28 <span style=''>
</span>29 <span style=''>sealed trait HasNonIdText {
</span>30 <span style=''>  def nonIdText: String
</span>31 <span style=''>}
</span>32 <span style=''>
</span>33 <span style=''>/**
</span>34 <span style=''> * Base for RuleWarnings
</span>35 <span style=''> */
</span>36 <span style=''>sealed trait RuleWarning extends HasId with HasOutputText with HasNonIdText {
</span>37 <span style=''>  def warning: String
</span>38 <span style=''>
</span>39 <span style=''>  override def nonIdText: String = </span><span style='background: #AEF1AE'>warning</span><span style=''>
</span>40 <span style=''>
</span>41 <span style=''>  /**
</span>42 <span style=''>   * If the error is syntax based - defined by parsing, rather than any later stage
</span>43 <span style=''>   * @return
</span>44 <span style=''>   */
</span>45 <span style=''>  def syntax: Boolean = </span><span style='background: #AEF1AE'>false</span><span style=''>
</span>46 <span style=''>
</span>47 <span style=''>  def warningText = </span><span style='background: #AEF1AE'>s&quot;$warning, occurred when processing id $id&quot;</span><span style=''>
</span>48 <span style=''>
</span>49 <span style=''>  override def outputText: String = </span><span style='background: #AEF1AE'>warningText</span><span style=''>
</span>50 <span style=''>}
</span>51 <span style=''>
</span>52 <span style=''>sealed trait SyntaxWarning extends RuleWarning {
</span>53 <span style=''>  final override def syntax: Boolean = </span><span style='background: #AEF1AE'>true</span><span style=''>
</span>54 <span style=''>}
</span>55 <span style=''>
</span>56 <span style=''>sealed trait SyntaxNameWarning extends SyntaxWarning {
</span>57 <span style=''>  def name: String
</span>58 <span style=''>}
</span>59 <span style=''>
</span>60 <span style=''>case class LambdaPossibleSOE(id: Id) extends RuleWarning with LambdaRelevant {
</span>61 <span style=''>  val warning = </span><span style='background: #AEF1AE'>&quot;Possible SOE detected&quot;</span><span style=''>
</span>62 <span style=''>}
</span>63 <span style=''>
</span>64 <span style=''>case class NonLambdaDocParameters(id: Id) extends SyntaxWarning {
</span>65 <span style=''>  val warning = </span><span style='background: #AEF1AE'>&quot;Parameter documentation is present on a non lambda expression&quot;</span><span style=''>
</span>66 <span style=''>}
</span>67 <span style=''>
</span>68 <span style=''>case class ExtraDocParameter(id: Id, name: String) extends SyntaxNameWarning with LambdaRelevant {
</span>69 <span style=''>  val warning = </span><span style='background: #AEF1AE'>s&quot;Parameter $name is not found in the lambda expression&quot;</span><span style=''>
</span>70 <span style=''>}
</span>71 <span style=''>
</span>72 <span style=''>/**
</span>73 <span style=''> * Base for RuleErrors
</span>74 <span style=''> */
</span>75 <span style=''>sealed trait RuleError extends HasId with HasOutputText with HasNonIdText {
</span>76 <span style=''>  def error: String
</span>77 <span style=''>
</span>78 <span style=''>  override def nonIdText: String = </span><span style='background: #AEF1AE'>error</span><span style=''>
</span>79 <span style=''>  /**
</span>80 <span style=''>   * If the error is syntax based - defined by parsing, rather than any later stage
</span>81 <span style=''>   * @return
</span>82 <span style=''>   */
</span>83 <span style=''>  def syntax: Boolean = </span><span style='background: #AEF1AE'>false</span><span style=''>
</span>84 <span style=''>
</span>85 <span style=''>  def errorText = </span><span style='background: #AEF1AE'>s&quot;$error occurred when processing id $id&quot;</span><span style=''>
</span>86 <span style=''>
</span>87 <span style=''>  override def outputText: String = </span><span style='background: #AEF1AE'>errorText</span><span style=''>
</span>88 <span style=''>}
</span>89 <span style=''>
</span>90 <span style=''>sealed trait SyntaxError extends RuleError {
</span>91 <span style=''>  final override def syntax: Boolean = </span><span style='background: #AEF1AE'>true</span><span style=''>
</span>92 <span style=''>}
</span>93 <span style=''>
</span>94 <span style=''>sealed trait NameMissingError extends RuleError {
</span>95 <span style=''>  def name: String
</span>96 <span style=''>  final override def error = </span><span style='background: #AEF1AE'>s&quot;Name $name is missing&quot;</span><span style=''>
</span>97 <span style=''>}
</span>98 <span style=''>
</span>99 <span style=''>sealed trait ViewMissingError extends RuleError {
</span>100 <span style=''>  def name: String
</span>101 <span style=''>  final override def error = </span><span style='background: #AEF1AE'>s&quot;</span><span style='background: #F0ADAD'>View $name is missing&quot;</span><span style=''>
</span>102 <span style=''>}
</span>103 <span style=''>
</span>104 <span style=''>case class LambdaSyntaxError(id: Id, error: String) extends SyntaxError with LambdaRelevant
</span>105 <span style=''>case class LambdaStackOverflowError(id: Id) extends SyntaxError with LambdaRelevant {
</span>106 <span style=''>  val error = </span><span style='background: #AEF1AE'>&quot;A lambda function seems to infinitely recurse&quot;</span><span style=''>
</span>107 <span style=''>}
</span>108 <span style=''>case class LambdaNameError(name: String, id: Id) extends NameMissingError with LambdaRelevant
</span>109 <span style=''>case class LambdaMultipleImplementationWithSameArityError(name: String, count: Int, argLength: Int, ids: Set[Id]) extends SyntaxError with LambdaRelevant {
</span>110 <span style=''>  val error = </span><span style='background: #AEF1AE'>s&quot;Lambda function $name has $count implementations with $argLength arguments&quot;</span><span style=''>
</span>111 <span style=''>  val id = </span><span style='background: #AEF1AE'>ids.head</span><span style=''>
</span>112 <span style=''>}
</span>113 <span style=''>case class LambdaViewError(name: String, id: Id) extends ViewMissingError with LambdaRelevant
</span>114 <span style=''>
</span>115 <span style=''>case class RuleSyntaxError(id: Id, error: String) extends SyntaxError with RuleRelevant
</span>116 <span style=''>case class RuleNameError(name: String, id: Id) extends NameMissingError with RuleRelevant
</span>117 <span style=''>case class RuleViewError(name: String, id: Id) extends ViewMissingError with RuleRelevant
</span>118 <span style=''>
</span>119 <span style=''>case class OutputRuleSyntaxError(id: Id, error: String) extends SyntaxError with OutputExpressionRelevant
</span>120 <span style=''>case class OutputRuleNameError(name: String, id: Id) extends NameMissingError with OutputExpressionRelevant
</span>121 <span style=''>case class OutputRuleViewError(name: String, id: Id) extends ViewMissingError with OutputExpressionRelevant
</span>122 <span style=''>
</span>123 <span style=''>case class LambdaSparkFunctionNameError(name: String, id: Id) extends NameMissingError with LambdaRelevant
</span>124 <span style=''>case class SparkFunctionNameError(name: String, id: Id) extends NameMissingError with RuleRelevant
</span>125 <span style=''>case class OuputSparkFunctionNameError(name: String, id: Id) extends NameMissingError with OutputExpressionRelevant
</span>126 <span style=''>
</span>127 <span style=''>case class DataFrameSyntaxError(error: String) extends SyntaxError {
</span>128 <span style=''>  val id = </span><span style='background: #AEF1AE'>Validation.dataFrameSyntaxErrorId</span><span style=''>
</span>129 <span style=''>}
</span>130 <span style=''>
</span>131 <span style=''>/**
</span>132 <span style=''> * Paramters to pass into showString for debugging / validation
</span>133 <span style=''> * @param numRows defaults to 1000
</span>134 <span style=''> * @param truncate
</span>135 <span style=''> * @param vertical
</span>136 <span style=''> */
</span>137 <span style=''>case class ShowParams(numRows: Int = 1000, truncate: Int = 0, vertical: Boolean = false)
</span>138 <span style=''>
</span>139 <span style=''>object Validation {
</span>140 <span style=''>  val unknownSOEId = </span><span style='background: #AEF1AE'>Id(Int.MinValue,Int.MinValue)</span><span style=''>
</span>141 <span style=''>  val dataFrameSyntaxErrorId = </span><span style='background: #AEF1AE'>Id(Int.MinValue+1,Int.MinValue+1)</span><span style=''>
</span>142 <span style=''>
</span>143 <span style=''>  protected[quality] val defaultViewLookup: String =&gt; Boolean =
</span>144 <span style=''>    </span><span style='background: #AEF1AE'>SparkSession.active.catalog.tableExists(_)</span><span style=''>
</span>145 <span style=''>
</span>146 <span style=''>  protected[quality] val emptyDocs = </span><span style='background: #AEF1AE'>Docs()</span><span style=''>
</span>147 <span style=''>
</span>148 <span style=''>  /**
</span>149 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>150 <span style=''>   *
</span>151 <span style=''>   * @param schemaOrFrame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>152 <span style=''>   * @param ruleSuite
</span>153 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>154 <span style=''>   * @param showParams - configure how the output text is formatted using the same options and formatting as dataFrame.show
</span>155 <span style=''>   * @param qualityName - the column name to store the runnerFunction results in
</span>156 <span style=''>   * @param recursiveLambdasSOEIsOk - this signals that finding a recursive lambda SOE should not stop the evaluations - if true it will still try to run any runnerFunction but may not give the correct results
</span>157 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>158 <span style=''>   * @param viewLookup - for any subquery used looks up the view name for being present (quoted and with schema), defaults to the current spark catalogue
</span>159 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>160 <span style=''>   */
</span>161 <span style=''>  def validate(schemaOrFrame: Either[StructType, DataFrame], ruleSuite: RuleSuite, showParams: ShowParams = ShowParams(),
</span>162 <span style=''>               runnerFunction: Option[DataFrame =&gt; Column] = None, qualityName: String = &quot;Quality&quot;,
</span>163 <span style=''>               recursiveLambdasSOEIsOk: Boolean = false, transformBeforeShow: DataFrame =&gt; DataFrame = identity, viewLookup: String =&gt; Boolean = Validation.defaultViewLookup):
</span>164 <span style=''>                (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) = {
</span>165 <span style=''>    val schema = </span><span style='background: #AEF1AE'>schemaOrFrame.fold(identity, _.schema)</span><span style=''>
</span>166 <span style=''>
</span>167 <span style=''>    val names = </span><span style='background: #AEF1AE'>namesFromSchema(schema)</span><span style=''>
</span>168 <span style=''>
</span>169 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>170 <span style=''>
</span>171 <span style=''>    val ((lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, lambdas, lambdaDocWarnings, lambadaExpressionLookups, lambdaViewErrors)) =
</span>172 <span style=''>      validateLambdas(ruleSuite, recursiveLambdasSOEIsOk, names, viewLookup) match {
</span>173 <span style=''>        case Left(toReturn) =&gt; return toReturn
</span>174 <span style=''>        case Right(result) =&gt; result
</span>175 <span style=''>      }
</span>176 <span style=''>
</span>177 <span style=''>    </span><span style='background: #AEF1AE'>docsWarnings ++= lambdaDocWarnings</span><span style=''>
</span>178 <span style=''>
</span>179 <span style=''>    val (ruleErrors, ruleDocWarnings, rules, outputExpressions, ruleExpressionLookups) = validateRules(ruleSuite, lambdaLookups, names, viewLookup)
</span>180 <span style=''>
</span>181 <span style=''>    </span><span style='background: #AEF1AE'>docsWarnings ++= ruleDocWarnings</span><span style=''>
</span>182 <span style=''>
</span>183 <span style=''>    val (showOut, dfErrors) =
</span>184 <span style=''>      validateAgainstDataFrame(schemaOrFrame, showParams, runnerFunction, qualityName, transformBeforeShow, schema, viewLookup)
</span>185 <span style=''>
</span>186 <span style=''>    </span><span style='background: #AEF1AE'>(unknownLambdaSparkFunctionErrors ++ lambdaArityErrors ++ dfErrors ++ ruleErrors ++ lambdaNameErrors ++ lambdaSyntaxErrors.map(_._2.right.get).toSet ++ lambdaViewErrors,
</span>187 <span style=''></span><span style='background: #AEF1AE'>      potentialOverflows.map( LambdaPossibleSOE ) ++ (Set() ++ docsWarnings)
</span>188 <span style=''></span><span style='background: #AEF1AE'>      , showOut, RuleSuiteDocs(rules, outputExpressions, lambdas), lambadaExpressionLookups ++ ruleExpressionLookups)</span><span style=''>
</span>189 <span style=''>  }
</span>190 <span style=''>
</span>191 <span style=''>  protected def validateAgainstDataFrame(schemaOrFrame: Either[StructType, DataFrame], showParams: ShowParams, runnerFunction: Option[DataFrame =&gt; Column], qualityName: String, transformBeforeShow: DataFrame =&gt; DataFrame, schema: StructType, viewLookup: String =&gt; Boolean) = {
</span>192 <span style=''>    val basedf = </span><span style='background: #AEF1AE'>schemaOrFrame.right.getOrElse {
</span>193 <span style=''></span><span style='background: #AEF1AE'>      val session = SparkSession.active
</span>194 <span style=''></span><span style='background: #AEF1AE'>      val empty = session.sparkContext.emptyRDD[Row]
</span>195 <span style=''></span><span style='background: #AEF1AE'>      session.createDataFrame(empty, schema)
</span>196 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>197 <span style=''>
</span>198 <span style=''>    val (showOut, dfErrors) =
</span>199 <span style=''>      runnerFunction.fold((&quot;&quot;, Set.empty[RuleError]))(rf =&gt; {
</span>200 <span style=''>        val runner = rf(basedf)
</span>201 <span style=''>        try {
</span>202 <span style=''>          val withRules = basedf.withColumn(qualityName, runner)
</span>203 <span style=''>          val transformed = transformBeforeShow(withRules)
</span>204 <span style=''>          (QualitySparkUtils.toString(transformed, showParams), Set.empty)
</span>205 <span style=''>        } catch {
</span>206 <span style=''>          case e: Throwable =&gt; (&quot;&quot;, Set(DataFrameSyntaxError(e.getMessage)))
</span>207 <span style=''>        }
</span>208 <span style=''>      })
</span>209 <span style=''>    </span><span style='background: #AEF1AE'>(showOut, dfErrors)</span><span style=''>
</span>210 <span style=''>  }
</span>211 <span style=''>
</span>212 <span style=''>  protected def validateRules(ruleSuite: RuleSuite, lambdaLookups: Map[String, Map[Id, Set[String]]], names: Set[String], viewLookup: String =&gt; Boolean)= {
</span>213 <span style=''>    val doRule = </span><span style='background: #AEF1AE'>validateRule(lambdaLookups, names)</span><span style=''> _
</span>214 <span style=''>
</span>215 <span style=''>    var rules = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[Rule]]</span><span style=''>
</span>216 <span style=''>    var outputExpressions = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[RunOnPassProcessor]]</span><span style=''>
</span>217 <span style=''>    var exprLookups = </span><span style='background: #AEF1AE'>Map.empty[IdTrEither, ExpressionLookup]</span><span style=''>
</span>218 <span style=''>
</span>219 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>220 <span style=''>
</span>221 <span style=''>    def addDocs[T](id: Id, rule: T, expressionRule: HasRuleText): (Id, WithDocs[T]) =
</span>222 <span style=''>      </span><span style='background: #AEF1AE'>DocsParser.parse(expressionRule.rule).map { parseddocs =&gt;
</span>223 <span style=''></span><span style='background: #AEF1AE'>        val res = id -&gt; WithDocs(rule, parseddocs)
</span>224 <span style=''></span><span style='background: #AEF1AE'>        if (parseddocs.params.nonEmpty) {
</span>225 <span style=''></span><span style='background: #AEF1AE'>          docsWarnings += NonLambdaDocParameters(id)
</span>226 <span style=''></span><span style='background: #AEF1AE'>        }
</span>227 <span style=''></span><span style='background: #AEF1AE'>        res
</span>228 <span style=''></span><span style='background: #AEF1AE'>      }.getOrElse(id -&gt; WithDocs(rule, emptyDocs))</span><span style=''>
</span>229 <span style=''>
</span>230 <span style=''>    // do the rules
</span>231 <span style=''>    val ruleErrors =
</span>232 <span style=''>      </span><span style='background: #AEF1AE'>ruleSuite.ruleSets.flatMap { rs =&gt;
</span>233 <span style=''></span><span style='background: #AEF1AE'>        rs.rules.flatMap { r =&gt;
</span>234 <span style=''></span><span style='background: #AEF1AE'>          rules += addDocs(r.id, r, r.expression.asInstanceOf[HasRuleText])
</span>235 <span style=''></span><span style='background: #AEF1AE'>
</span>236 <span style=''></span><span style='background: #AEF1AE'>          val (ruleErrors, exprLookup) = doRule(r.id, r.expression.asInstanceOf[HasExpr].expr, false, viewLookup)
</span>237 <span style=''></span><span style='background: #AEF1AE'>          exprLookups += RuleId(r.id) -&gt; exprLookup
</span>238 <span style=''></span><span style='background: #AEF1AE'>
</span>239 <span style=''></span><span style='background: #AEF1AE'>          val outputErrors =
</span>240 <span style=''></span><span style='background: #AEF1AE'>            if (r.runOnPassProcessor != NoOpRunOnPassProcessor.noOp) {
</span>241 <span style=''></span><span style='background: #AEF1AE'>              outputExpressions += addDocs(r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[OutputExpression])
</span>242 <span style=''></span><span style='background: #AEF1AE'>
</span>243 <span style=''></span><span style='background: #AEF1AE'>              val (oErrors, oExprLookup) = doRule(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup)
</span>244 <span style=''></span><span style='background: #AEF1AE'>              exprLookups += OutputExpressionId(r.runOnPassProcessor.id) -&gt; oExprLookup
</span>245 <span style=''></span><span style='background: #AEF1AE'>              oErrors
</span>246 <span style=''></span><span style='background: #AEF1AE'>            } else
</span>247 <span style=''></span><span style='background: #AEF1AE'>              Set.empty
</span>248 <span style=''></span><span style='background: #AEF1AE'>
</span>249 <span style=''></span><span style='background: #AEF1AE'>          ruleErrors ++ outputErrors
</span>250 <span style=''></span><span style='background: #AEF1AE'>        }
</span>251 <span style=''></span><span style='background: #AEF1AE'>      }.toSet</span><span style=''>
</span>252 <span style=''>
</span>253 <span style=''>    </span><span style='background: #AEF1AE'>(ruleErrors, Set() ++ docsWarnings, Map() ++ rules, outputExpressions, Map() ++ exprLookups)</span><span style=''>
</span>254 <span style=''>  }
</span>255 <span style=''>
</span>256 <span style=''>  protected def validateLambdas(ruleSuite: RuleSuite, recursiveLambdasSOEIsOk: Boolean, names: Set[String], viewLookup: String =&gt; Boolean): Either[(Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]),
</span>257 <span style=''>    (Seq[(String, Either[(Id, Expression), LambdaSyntaxError])], Map[String, Map[Id, Set[String]]],
</span>258 <span style=''>      Set[Id], Set[LambdaSparkFunctionNameError], Set[LambdaMultipleImplementationWithSameArityError], Set[LambdaNameError], Map[Id, WithDocs[quality.LambdaFunction]], Set[RuleWarning], Map[IdTrEither, ExpressionLookup], Set[LambdaViewError])] = {
</span>259 <span style=''>
</span>260 <span style=''>    var lambdas = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[quality.LambdaFunction]]</span><span style=''>
</span>261 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>262 <span style=''>
</span>263 <span style=''>    val viewErrors = </span><span style='background: #AEF1AE'>ruleSuite.lambdaFunctions.flatMap { f =&gt;
</span>264 <span style=''></span><span style='background: #AEF1AE'>      try {
</span>265 <span style=''></span><span style='background: #AEF1AE'>        subQueryErrors(viewLookup, f.expr, LambdaViewError(_, f.id))
</span>266 <span style=''></span><span style='background: #AEF1AE'>      } catch {
</span>267 <span style=''></span><span style='background: #AEF1AE'>        // Might be a parser error, skip to let the below code pick it up
</span>268 <span style=''></span><span style='background: #AEF1AE'>        case _: Throwable =&gt; Set.empty[LambdaViewError]
</span>269 <span style=''></span><span style='background: #AEF1AE'>      }
</span>270 <span style=''></span><span style='background: #AEF1AE'>    }.toSet</span><span style=''>
</span>271 <span style=''>
</span>272 <span style=''>    val (lambdaLeftExpressions, lambdaSyntaxErrors) = ruleSuite.lambdaFunctions.map { f =&gt;
</span>273 <span style=''>      (f.name,
</span>274 <span style=''>        try {
</span>275 <span style=''>          val expr = f.expr
</span>276 <span style=''>          val ret = Left((f.id, expr))
</span>277 <span style=''>
</span>278 <span style=''>          val args =
</span>279 <span style=''>            expr match {
</span>280 <span style=''>              case lambda: LambdaFunction =&gt; lambda.arguments.map(VariablesLookup.toName).toSet
</span>281 <span style=''>              case _ =&gt; Set.empty[String]
</span>282 <span style=''>            }
</span>283 <span style=''>
</span>284 <span style=''>          DocsParser.parse(f.rule).map { parseddocs =&gt;
</span>285 <span style=''>            lambdas += f.id -&gt; WithDocs(f, parseddocs)
</span>286 <span style=''>
</span>287 <span style=''>            parseddocs.params.keySet.foreach { name =&gt;
</span>288 <span style=''>              if (!args.contains(name)) {
</span>289 <span style=''>                docsWarnings += ExtraDocParameter(f.id, name)
</span>290 <span style=''>              }
</span>291 <span style=''>            }
</span>292 <span style=''>          }.getOrElse {
</span>293 <span style=''>            lambdas += f.id -&gt; WithDocs(f, emptyDocs)
</span>294 <span style=''>          }
</span>295 <span style=''>
</span>296 <span style=''>          ret
</span>297 <span style=''>        } catch {
</span>298 <span style=''>          case e: Throwable =&gt; Right(LambdaSyntaxError(f.id, e.getMessage))
</span>299 <span style=''>        })
</span>300 <span style=''>    }.partition {
</span>301 <span style=''>      _._2.isLeft
</span>302 <span style=''>    }
</span>303 <span style=''>
</span>304 <span style=''>    val lambdaNameToExpressions = </span><span style='background: #AEF1AE'>lambdaLeftExpressions.groupBy(p =&gt; p._1).mapValues(e =&gt; e.map(_._2.left.get).toMap)</span><span style=''>
</span>305 <span style=''>
</span>306 <span style=''>    val (lambdaLookups, potentialOverflows, unknownLambdaSparkFunctions) = try {
</span>307 <span style=''>      VariablesLookup.processLambdas(lambdaNameToExpressions)
</span>308 <span style=''>    } catch {
</span>309 <span style=''>      // SOE is possible with lambdas calling lambdas, capture that as a distinct issue
</span>310 <span style=''>      case soe: StackOverflowError =&gt;
</span>311 <span style=''>        if (recursiveLambdasSOEIsOk)
</span>312 <span style=''>        // type needed otherwise it gets stuck with the first param type derivation _1 &lt;: String instead of String
</span>313 <span style=''>          (Map.empty[String, Map[Id, Identifiers]], Set.empty[Id], Map.empty[Id, Set[String]])
</span>314 <span style=''>        else
</span>315 <span style=''>          return Left((Set(LambdaStackOverflowError(Validation.unknownSOEId)), Set.empty[RuleWarning], &quot;&quot;, RuleSuiteDocs(), Map.empty[IdTrEither, ExpressionLookup]))
</span>316 <span style=''>    }
</span>317 <span style=''>
</span>318 <span style=''>    // now that they are looked up, a bit duplicative but...
</span>319 <span style=''>    val exprLookups = </span><span style='background: #AEF1AE'>lambdaNameToExpressions.values.flatMap( m =&gt; m.map(pair =&gt; LambdaId(pair._1) -&gt; VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))).toMap</span><span style=''>
</span>320 <span style=''>
</span>321 <span style=''>    val unknownLambdaSparkFunctionErrors = </span><span style='background: #AEF1AE'>unknownLambdaSparkFunctions.flatMap(p =&gt; p._2.map(name =&gt;
</span>322 <span style=''></span><span style='background: #AEF1AE'>      LambdaSparkFunctionNameError(name, p._1))).toSet</span><span style=''>
</span>323 <span style=''>
</span>324 <span style=''>    val lambdaArityErrors = </span><span style='background: #AEF1AE'>lambdaNameToExpressions.filter(p =&gt; p._2.size &gt; 1).flatMap {
</span>325 <span style=''></span><span style='background: #AEF1AE'>      pairs =&gt;
</span>326 <span style=''></span><span style='background: #AEF1AE'>        val map = pairs._2
</span>327 <span style=''></span><span style='background: #AEF1AE'>
</span>328 <span style=''></span><span style='background: #AEF1AE'>        val counts = map.groupBy(_._2.children.size - 1) // one child is the return
</span>329 <span style=''></span><span style='background: #AEF1AE'>        val moreThan1 = counts.collectFirst { case f if f._2.size &gt; 1 =&gt; f }
</span>330 <span style=''></span><span style='background: #AEF1AE'>        moreThan1.map { f =&gt;
</span>331 <span style=''></span><span style='background: #AEF1AE'>          LambdaMultipleImplementationWithSameArityError(pairs._1, f._2.size, f._1, f._2.keySet)
</span>332 <span style=''></span><span style='background: #AEF1AE'>        }
</span>333 <span style=''></span><span style='background: #AEF1AE'>    }.toSet</span><span style=''>
</span>334 <span style=''>
</span>335 <span style=''>    // do we have variables used in the lambdas which are not in the schema?
</span>336 <span style=''>    val lambdaNameErrors: Set[LambdaNameError] =
</span>337 <span style=''>      </span><span style='background: #AEF1AE'>lambdaLookups.flatMap { p =&gt;
</span>338 <span style=''></span><span style='background: #AEF1AE'>        p._2.flatMap { pair =&gt;
</span>339 <span style=''></span><span style='background: #AEF1AE'>          val (id, identifiers) = pair
</span>340 <span style=''></span><span style='background: #AEF1AE'>          if (identifiers.diff(names).isEmpty)
</span>341 <span style=''></span><span style='background: #AEF1AE'>            None
</span>342 <span style=''></span><span style='background: #AEF1AE'>          else
</span>343 <span style=''></span><span style='background: #AEF1AE'>            Some(identifiers.diff(names).map(LambdaNameError(_, id)))
</span>344 <span style=''></span><span style='background: #AEF1AE'>        }
</span>345 <span style=''></span><span style='background: #AEF1AE'>      }.flatten.toSet</span><span style=''>
</span>346 <span style=''>    </span><span style='background: #AEF1AE'>Right((lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, Map() ++ lambdas, Set() ++ docsWarnings, exprLookups, viewErrors))</span><span style=''>
</span>347 <span style=''>  }
</span>348 <span style=''>
</span>349 <span style=''>  protected def subQueryErrors[T](lookup: String =&gt; Boolean, expression: Expression, f: String =&gt; T): Set[T] = (</span><span style='background: #AEF1AE'>expression collect {
</span>350 <span style=''></span><span style='background: #AEF1AE'>    case s: SubqueryExpression =&gt; s.plan.collect{
</span>351 <span style=''></span><span style='background: #AEF1AE'>      case rel: UnresolvedRelation if !lookup(rel.tableName) =&gt;
</span>352 <span style=''></span><span style='background: #AEF1AE'>        f(rel.tableName)
</span>353 <span style=''></span><span style='background: #AEF1AE'>    }
</span>354 <span style=''></span><span style='background: #AEF1AE'>  }).flatten.toSet</span><span style=''>
</span>355 <span style=''>
</span>356 <span style=''>  protected def validateRule(lambdaLookups: Map[String, Map[Id, Set[String]]], names: Set[String])(id: Id, exprThunk: =&gt; Expression, outputRule: Boolean, viewLookup: String =&gt; Boolean): (Set[RuleError], ExpressionLookup) =
</span>357 <span style=''>    try {
</span>358 <span style=''>      </span><span style='background: #AEF1AE'>val expr = exprThunk
</span>359 <span style=''></span><span style='background: #AEF1AE'>      val exl @ ExpressionLookup(exprFields, unknownSparkFunctions, _, _) = VariablesLookup.fieldsFromExpression(expr, lambdaLookups)
</span>360 <span style=''></span><span style='background: #AEF1AE'>      val rules = exprFields.flatMap{
</span>361 <span style=''></span><span style='background: #AEF1AE'>        field =&gt;
</span>362 <span style=''></span><span style='background: #AEF1AE'>          if (names.contains(field))
</span>363 <span style=''></span><span style='background: #AEF1AE'>            None
</span>364 <span style=''></span><span style='background: #AEF1AE'>          else
</span>365 <span style=''></span><span style='background: #AEF1AE'>            Some(
</span>366 <span style=''></span><span style='background: #AEF1AE'>              if (!outputRule)
</span>367 <span style=''></span><span style='background: #AEF1AE'>                RuleNameError(field, id)
</span>368 <span style=''></span><span style='background: #AEF1AE'>              else
</span>369 <span style=''></span><span style='background: #AEF1AE'>                OutputRuleNameError(field, id)
</span>370 <span style=''></span><span style='background: #AEF1AE'>            )
</span>371 <span style=''></span><span style='background: #AEF1AE'>      }.toSet[RuleError]
</span>372 <span style=''></span><span style='background: #AEF1AE'>
</span>373 <span style=''></span><span style='background: #AEF1AE'>      val viewErrors = subQueryErrors(viewLookup, exprThunk, if (outputRule) OutputRuleViewError(_, id) else RuleViewError(_, id))
</span>374 <span style=''></span><span style='background: #AEF1AE'>
</span>375 <span style=''></span><span style='background: #AEF1AE'>      val unknown = unknownSparkFunctions.map{ name =&gt;
</span>376 <span style=''></span><span style='background: #AEF1AE'>        if (!outputRule)
</span>377 <span style=''></span><span style='background: #AEF1AE'>          SparkFunctionNameError(name, id)
</span>378 <span style=''></span><span style='background: #AEF1AE'>        else
</span>379 <span style=''></span><span style='background: #AEF1AE'>          OuputSparkFunctionNameError(name, id)
</span>380 <span style=''></span><span style='background: #AEF1AE'>      }
</span>381 <span style=''></span><span style='background: #AEF1AE'>
</span>382 <span style=''></span><span style='background: #AEF1AE'>      (rules ++ unknown ++ viewErrors, exl)</span><span style=''>
</span>383 <span style=''>    } catch {
</span>384 <span style=''>      case e: Throwable =&gt; </span><span style='background: #AEF1AE'>(Set(
</span>385 <span style=''></span><span style='background: #AEF1AE'>        if (!outputRule)
</span>386 <span style=''></span><span style='background: #AEF1AE'>          RuleSyntaxError(id, e.getMessage)
</span>387 <span style=''></span><span style='background: #AEF1AE'>        else
</span>388 <span style=''></span><span style='background: #AEF1AE'>          OutputRuleSyntaxError(id, e.getMessage)
</span>389 <span style=''></span><span style='background: #AEF1AE'>      ), ExpressionLookup())</span><span style=''>
</span>390 <span style=''>    }
</span>391 <span style=''>
</span>392 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          2944
        </td>
        <td>
          1379
          -
          1386
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warning
        </td>
      </tr><tr>
        <td>
          45
        </td>
        <td>
          2945
        </td>
        <td>
          1521
          -
          1526
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          false
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          2948
        </td>
        <td>
          1591
          -
          1592
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          2951
        </td>
        <td>
          1548
          -
          1592
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;, occurred when processing id &quot;, &quot;&quot;).s(RuleWarning.this.warning, RuleWarning.this.id)
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          2947
        </td>
        <td>
          1558
          -
          1589
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;, occurred when processing id &quot;
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          2950
        </td>
        <td>
          1589
          -
          1591
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasId.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.id
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          2949
        </td>
        <td>
          1551
          -
          1558
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warning
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          2946
        </td>
        <td>
          1550
          -
          1551
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          2952
        </td>
        <td>
          1630
          -
          1641
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warningText
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warningText
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          2953
        </td>
        <td>
          1733
          -
          1737
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          true
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          2954
        </td>
        <td>
          1913
          -
          1936
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Possible SOE detected&quot;
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          2955
        </td>
        <td>
          2022
          -
          2085
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter documentation is present on a non lambda expression&quot;
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          2957
        </td>
        <td>
          2221
          -
          2260
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is not found in the lambda expression&quot;
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          2956
        </td>
        <td>
          2206
          -
          2217
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter &quot;
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          2959
        </td>
        <td>
          2204
          -
          2260
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Parameter &quot;, &quot; is not found in the lambda expression&quot;).s(ExtraDocParameter.this.name)
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          2958
        </td>
        <td>
          2217
          -
          2221
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ExtraDocParameter.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExtraDocParameter.this.name
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          2960
        </td>
        <td>
          2427
          -
          2432
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.error
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.error
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          2961
        </td>
        <td>
          2566
          -
          2571
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          false
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          2963
        </td>
        <td>
          2599
          -
          2629
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; occurred when processing id &quot;
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          2966
        </td>
        <td>
          2629
          -
          2631
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasId.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.id
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          2962
        </td>
        <td>
          2593
          -
          2594
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          2965
        </td>
        <td>
          2594
          -
          2599
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.error
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.error
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          2967
        </td>
        <td>
          2591
          -
          2632
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot; occurred when processing id &quot;, &quot;&quot;).s(RuleError.this.error, RuleError.this.id)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          2964
        </td>
        <td>
          2631
          -
          2632
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          2968
        </td>
        <td>
          2670
          -
          2679
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.errorText
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.errorText
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          2969
        </td>
        <td>
          2767
          -
          2771
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          true
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          2972
        </td>
        <td>
          2881
          -
          2885
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.NameMissingError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NameMissingError.this.name
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          2971
        </td>
        <td>
          2885
          -
          2897
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is missing&quot;
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          2970
        </td>
        <td>
          2875
          -
          2881
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Name &quot;
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          2973
        </td>
        <td>
          2873
          -
          2897
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Name &quot;, &quot; is missing&quot;).s(NameMissingError.this.name)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          2975
        </td>
        <td>
          3011
          -
          3023
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot; is missing&quot;
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          2977
        </td>
        <td>
          2999
          -
          3023
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;View &quot;, &quot; is missing&quot;).s(ViewMissingError.this.name)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          2974
        </td>
        <td>
          3001
          -
          3007
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;View &quot;
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          2976
        </td>
        <td>
          3007
          -
          3011
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ViewMissingError.name
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ViewMissingError.this.name
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          2978
        </td>
        <td>
          3219
          -
          3266
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;A lambda function seems to infinitely recurse&quot;
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          2981
        </td>
        <td>
          3567
          -
          3590
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; implementations with &quot;
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          2984
        </td>
        <td>
          3562
          -
          3567
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.count
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.count
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          2986
        </td>
        <td>
          3533
          -
          3610
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Lambda function &quot;, &quot; has &quot;, &quot; implementations with &quot;, &quot; arguments&quot;).s(LambdaMultipleImplementationWithSameArityError.this.name, LambdaMultipleImplementationWithSameArityError.this.count, LambdaMultipleImplementationWithSameArityError.this.argLength)
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          2980
        </td>
        <td>
          3556
          -
          3562
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; has &quot;
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          2983
        </td>
        <td>
          3552
          -
          3556
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.name
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          2985
        </td>
        <td>
          3590
          -
          3599
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.argLength
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.argLength
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          2979
        </td>
        <td>
          3535
          -
          3552
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Lambda function &quot;
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          2982
        </td>
        <td>
          3599
          -
          3610
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; arguments&quot;
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          2987
        </td>
        <td>
          3622
          -
          3630
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.IterableLike.head
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.ids.head
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          2988
        </td>
        <td>
          4723
          -
          4756
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.dataFrameSyntaxErrorId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.dataFrameSyntaxErrorId
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          2989
        </td>
        <td>
          5036
          -
          5065
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.Id.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.Id.apply(-2147483648, -2147483648)
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          2990
        </td>
        <td>
          5097
          -
          5130
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.Id.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.Id.apply(-2147483647, -2147483647)
        </td>
      </tr><tr>
        <td>
          144
        </td>
        <td>
          2991
        </td>
        <td>
          5200
          -
          5242
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalog.Catalog.tableExists
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active.catalog.tableExists(x$1)
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          2993
        </td>
        <td>
          5281
          -
          5281
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply$default$2
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          2995
        </td>
        <td>
          5281
          -
          5287
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply(com.sparkutils.quality.utils.Docs.apply$default$1, com.sparkutils.quality.utils.Docs.apply$default$2, com.sparkutils.quality.utils.Docs.apply$default$3)
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          2992
        </td>
        <td>
          5281
          -
          5281
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply$default$1
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          2994
        </td>
        <td>
          5281
          -
          5281
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.utils.Docs.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.Docs.apply$default$3
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          2996
        </td>
        <td>
          7149
          -
          7157
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.identity
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.identity[org.apache.spark.sql.types.StructType](x)
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          2998
        </td>
        <td>
          7130
          -
          7168
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.fold
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          schemaOrFrame.fold[org.apache.spark.sql.types.StructType]({
  ((x: org.apache.spark.sql.types.StructType) =&gt; scala.Predef.identity[org.apache.spark.sql.types.StructType](x))
}, ((x$2: org.apache.spark.sql.DataFrame) =&gt; x$2.schema))
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          2997
        </td>
        <td>
          7159
          -
          7167
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.Dataset.schema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2.schema
        </td>
      </tr><tr>
        <td>
          167
        </td>
        <td>
          2999
        </td>
        <td>
          7186
          -
          7209
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.LookupIdFunctionsImports.namesFromSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.namesFromSchema(schema)
        </td>
      </tr><tr>
        <td>
          169
        </td>
        <td>
          3000
        </td>
        <td>
          7234
          -
          7260
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          3008
        </td>
        <td>
          7407
          -
          7407
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._8
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._8
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          3002
        </td>
        <td>
          7292
          -
          7292
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._2
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          3005
        </td>
        <td>
          7361
          -
          7361
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._5
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          3004
        </td>
        <td>
          7327
          -
          7327
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._4
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          3007
        </td>
        <td>
          7398
          -
          7398
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._7
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._7
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          3010
        </td>
        <td>
          7452
          -
          7452
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._10
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._10
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          3001
        </td>
        <td>
          7272
          -
          7272
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._1
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          3009
        </td>
        <td>
          7426
          -
          7426
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._9
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._9
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          3003
        </td>
        <td>
          7307
          -
          7307
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._3
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          3006
        </td>
        <td>
          7380
          -
          7380
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._6
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          3011
        </td>
        <td>
          7655
          -
          7689
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.Growable.++=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.++=(lambdaDocWarnings)
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          3013
        </td>
        <td>
          7712
          -
          7712
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._2
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          3016
        </td>
        <td>
          7755
          -
          7755
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._5
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          3012
        </td>
        <td>
          7700
          -
          7700
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._1
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          3015
        </td>
        <td>
          7736
          -
          7736
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._4
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          3014
        </td>
        <td>
          7729
          -
          7729
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._3
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          3017
        </td>
        <td>
          7844
          -
          7876
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.Growable.++=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.++=(ruleDocWarnings)
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          3019
        </td>
        <td>
          7896
          -
          7896
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._2
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          3018
        </td>
        <td>
          7887
          -
          7887
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._1
        </td>
      </tr><tr>
        <td>
          186
        </td>
        <td>
          3020
        </td>
        <td>
          8042
          -
          8209
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownLambdaSparkFunctionErrors.++[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]](lambdaArityErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]).++[com.sparkutils.quality.impl.RuleError, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](dfErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]).++(ruleErrors).++(lambdaNameErrors).++(lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$6: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$6._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError]).++(lambdaViewErrors)
        </td>
      </tr><tr>
        <td>
          186
        </td>
        <td>
          3027
        </td>
        <td>
          8041
          -
          8405
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple5.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple5.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning], String, com.sparkutils.quality.utils.RuleSuiteDocs, scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](unknownLambdaSparkFunctionErrors.++[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]](lambdaArityErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]).++[com.sparkutils.quality.impl.RuleError, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](dfErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]).++(ruleErrors).++(lambdaNameErrors).++(lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$6: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$6._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError]).++(lambdaViewErrors), potentialOverflows.map[com.sparkutils.quality.impl.LambdaPossibleSOE, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaPossibleSOE]](LambdaPossibleSOE)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]).++[com.sparkutils.quality.impl.RuleWarning, Set[com.sparkutils.quality.impl.RuleWarning]](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning]), showOut, com.sparkutils.quality.utils.RuleSuiteDocs.apply(rules, outputExpressions, lambdas), lambadaExpressionLookups.++[com.sparkutils.quality.ExpressionLookup](ruleExpressionLookups))
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          3022
        </td>
        <td>
          8265
          -
          8286
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          3021
        </td>
        <td>
          8239
          -
          8239
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          3024
        </td>
        <td>
          8217
          -
          8287
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          potentialOverflows.map[com.sparkutils.quality.impl.LambdaPossibleSOE, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaPossibleSOE]](LambdaPossibleSOE)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]).++[com.sparkutils.quality.impl.RuleWarning, Set[com.sparkutils.quality.impl.RuleWarning]](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning])
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          3023
        </td>
        <td>
          8261
          -
          8261
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning]
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          3026
        </td>
        <td>
          8355
          -
          8404
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambadaExpressionLookups.++[com.sparkutils.quality.ExpressionLookup](ruleExpressionLookups)
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          3025
        </td>
        <td>
          8305
          -
          8353
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.RuleSuiteDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.RuleSuiteDocs.apply(rules, outputExpressions, lambdas)
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          3031
        </td>
        <td>
          8705
          -
          8880
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.RightProjection.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          schemaOrFrame.right.getOrElse[org.apache.spark.sql.DataFrame]({
  val session: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession.active;
  val empty: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = session.sparkContext.emptyRDD[org.apache.spark.sql.Row]((ClassTag.apply[org.apache.spark.sql.Row](classOf[org.apache.spark.sql.Row]): scala.reflect.ClassTag[org.apache.spark.sql.Row]));
  session.createDataFrame(empty, schema)
})
        </td>
      </tr><tr>
        <td>
          193
        </td>
        <td>
          3028
        </td>
        <td>
          8757
          -
          8776
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.SparkSession.active
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active
        </td>
      </tr><tr>
        <td>
          194
        </td>
        <td>
          3029
        </td>
        <td>
          8795
          -
          8829
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.SparkContext.emptyRDD
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          session.sparkContext.emptyRDD[org.apache.spark.sql.Row]((ClassTag.apply[org.apache.spark.sql.Row](classOf[org.apache.spark.sql.Row]): scala.reflect.ClassTag[org.apache.spark.sql.Row]))
        </td>
      </tr><tr>
        <td>
          195
        </td>
        <td>
          3030
        </td>
        <td>
          8836
          -
          8874
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.SparkSession.createDataFrame
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          session.createDataFrame(empty, schema)
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          3033
        </td>
        <td>
          8900
          -
          8900
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._2
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          3032
        </td>
        <td>
          8891
          -
          8891
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._1
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          3034
        </td>
        <td>
          9337
          -
          9356
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[String, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](showOut, dfErrors)
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          3035
        </td>
        <td>
          9535
          -
          9569
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validateRule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validateRule(lambdaLookups, names)(id, exprThunk, outputRule, viewLookup)
        </td>
      </tr><tr>
        <td>
          215
        </td>
        <td>
          3036
        </td>
        <td>
          9589
          -
          9618
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]]
        </td>
      </tr><tr>
        <td>
          216
        </td>
        <td>
          3037
        </td>
        <td>
          9647
          -
          9690
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]]
        </td>
      </tr><tr>
        <td>
          217
        </td>
        <td>
          3038
        </td>
        <td>
          9713
          -
          9752
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup]
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          3039
        </td>
        <td>
          9777
          -
          9803
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          222
        </td>
        <td>
          3040
        </td>
        <td>
          9914
          -
          9933
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.HasRuleText.rule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expressionRule.rule
        </td>
      </tr><tr>
        <td>
          223
        </td>
        <td>
          3042
        </td>
        <td>
          9973
          -
          10005
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, parseddocs))
        </td>
      </tr><tr>
        <td>
          223
        </td>
        <td>
          3041
        </td>
        <td>
          9979
          -
          10005
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.WithDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.WithDocs.apply[T](rule, parseddocs)
        </td>
      </tr><tr>
        <td>
          224
        </td>
        <td>
          3047
        </td>
        <td>
          10014
          -
          10014
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          224
        </td>
        <td>
          3043
        </td>
        <td>
          10018
          -
          10044
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.nonEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parseddocs.params.nonEmpty
        </td>
      </tr><tr>
        <td>
          224
        </td>
        <td>
          3048
        </td>
        <td>
          10014
          -
          10014
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3044
        </td>
        <td>
          10074
          -
          10100
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.NonLambdaDocParameters.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NonLambdaDocParameters.apply(id)
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3046
        </td>
        <td>
          10058
          -
          10100
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.+=(NonLambdaDocParameters.apply(id))
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3045
        </td>
        <td>
          10058
          -
          10100
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.+=(NonLambdaDocParameters.apply(id))
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          3049
        </td>
        <td>
          10162
          -
          10171
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.emptyDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.emptyDocs
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          3052
        </td>
        <td>
          9897
          -
          10173
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.DocsParser.parse(expressionRule.rule).map[(com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[T])](((parseddocs: com.sparkutils.quality.utils.Docs) =&gt; {
  val res: (com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[T]) = scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, parseddocs));
  if (parseddocs.params.nonEmpty)
    docsWarnings.+=(NonLambdaDocParameters.apply(id))
  else
    ();
  res
})).getOrElse[(com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[T])](scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, Validation.this.emptyDocs)))
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          3051
        </td>
        <td>
          10141
          -
          10172
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.utils.WithDocs[T]](com.sparkutils.quality.utils.WithDocs.apply[T](rule, Validation.this.emptyDocs))
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          3050
        </td>
        <td>
          10147
          -
          10172
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.WithDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.WithDocs.apply[T](rule, Validation.this.emptyDocs)
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          3078
        </td>
        <td>
          10249
          -
          10249
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          3076
        </td>
        <td>
          10282
          -
          10282
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          3077
        </td>
        <td>
          10265
          -
          11127
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rs.rules.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((r: com.sparkutils.quality.Rule) =&gt; {
  rules = rules.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$8: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.id, r.expression.asInstanceOf[com.sparkutils.quality.HasExpr].expr, false, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((ruleErrors @ _), (exprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](ruleErrors, exprLookup)
  };
  val ruleErrors: Set[com.sparkutils.quality.impl.RuleError] = x$8._1;
  val exprLookup: com.sparkutils.quality.ExpressionLookup = x$8._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup));
  val outputErrors: scala.collection.immutable.Set[_ &lt;: com.sparkutils.quality.impl.RuleError] = if (r.runOnPassProcessor.!=(com.sparkutils.quality.NoOpRunOnPassProcessor.noOp))
    {
      outputExpressions = outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
        case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](oErrors, oExprLookup)
      };
      val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
      val oExprLookup: com.sparkutils.quality.ExpressionLookup = x$9._2;
      exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup));
      oErrors
    }
  else
    scala.Predef.Set.empty[Nothing];
  ruleErrors.++(outputErrors)
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError])
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          3053
        </td>
        <td>
          10316
          -
          10320
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.Rule.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.id
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          3056
        </td>
        <td>
          10299
          -
          10364
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rules.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]))
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          3055
        </td>
        <td>
          10308
          -
          10364
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.addDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText])
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          3054
        </td>
        <td>
          10325
          -
          10363
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]
        </td>
      </tr><tr>
        <td>
          236
        </td>
        <td>
          3058
        </td>
        <td>
          10393
          -
          10393
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._2
        </td>
      </tr><tr>
        <td>
          236
        </td>
        <td>
          3057
        </td>
        <td>
          10381
          -
          10381
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._1
        </td>
      </tr><tr>
        <td>
          237
        </td>
        <td>
          3060
        </td>
        <td>
          10490
          -
          10531
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup))
        </td>
      </tr><tr>
        <td>
          237
        </td>
        <td>
          3059
        </td>
        <td>
          10505
          -
          10531
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup)
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          3062
        </td>
        <td>
          10578
          -
          10629
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.!=(com.sparkutils.quality.NoOpRunOnPassProcessor.noOp)
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          3061
        </td>
        <td>
          10602
          -
          10629
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.NoOpRunOnPassProcessor.noOp
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.NoOpRunOnPassProcessor.noOp
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          3072
        </td>
        <td>
          10631
          -
          11050
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  outputExpressions = outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](oErrors, oExprLookup)
  };
  val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
  val oExprLookup: com.sparkutils.quality.ExpressionLookup = x$9._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup));
  oErrors
}
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          3065
        </td>
        <td>
          10723
          -
          10789
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          3064
        </td>
        <td>
          10701
          -
          10721
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.Rule.runOnPassProcessor
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          3067
        </td>
        <td>
          10647
          -
          10790
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]))
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          3063
        </td>
        <td>
          10676
          -
          10699
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.RunOnPassProcessor.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.id
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          3066
        </td>
        <td>
          10668
          -
          10790
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.addDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression])
        </td>
      </tr><tr>
        <td>
          243
        </td>
        <td>
          3069
        </td>
        <td>
          10820
          -
          10820
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$9._2
        </td>
      </tr><tr>
        <td>
          243
        </td>
        <td>
          3068
        </td>
        <td>
          10811
          -
          10811
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$9._1
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          3071
        </td>
        <td>
          10941
          -
          11014
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup))
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          3070
        </td>
        <td>
          10956
          -
          11014
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup)
        </td>
      </tr><tr>
        <td>
          247
        </td>
        <td>
          3073
        </td>
        <td>
          11070
          -
          11079
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          247
        </td>
        <td>
          3074
        </td>
        <td>
          11070
          -
          11079
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          249
        </td>
        <td>
          3075
        </td>
        <td>
          11091
          -
          11117
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleErrors.++(outputErrors)
        </td>
      </tr><tr>
        <td>
          251
        </td>
        <td>
          3079
        </td>
        <td>
          10222
          -
          11141
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.ruleSets.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((rs: com.sparkutils.quality.RuleSet) =&gt; rs.rules.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((r: com.sparkutils.quality.Rule) =&gt; {
  rules = rules.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.HasRuleText]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$8: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.id, r.expression.asInstanceOf[com.sparkutils.quality.HasExpr].expr, false, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((ruleErrors @ _), (exprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](ruleErrors, exprLookup)
  };
  val ruleErrors: Set[com.sparkutils.quality.impl.RuleError] = x$8._1;
  val exprLookup: com.sparkutils.quality.ExpressionLookup = x$8._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](exprLookup));
  val outputErrors: scala.collection.immutable.Set[_ &lt;: com.sparkutils.quality.impl.RuleError] = if (r.runOnPassProcessor.!=(com.sparkutils.quality.NoOpRunOnPassProcessor.noOp))
    {
      outputExpressions = outputExpressions.+[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]](addDocs[com.sparkutils.quality.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup) @unchecked) match {
        case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](oErrors, oExprLookup)
      };
      val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
      val oExprLookup: com.sparkutils.quality.ExpressionLookup = x$9._2;
      exprLookups = exprLookups.+[com.sparkutils.quality.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.ExpressionLookup](oExprLookup));
      oErrors
    }
  else
    scala.Predef.Set.empty[Nothing];
  ruleErrors.++(outputErrors)
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError])))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]).toSet[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          253
        </td>
        <td>
          3080
        </td>
        <td>
          11160
          -
          11181
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          253
        </td>
        <td>
          3082
        </td>
        <td>
          11218
          -
          11238
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, Nothing]().++[com.sparkutils.quality.ExpressionLookup](exprLookups)
        </td>
      </tr><tr>
        <td>
          253
        </td>
        <td>
          3081
        </td>
        <td>
          11183
          -
          11197
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](rules)
        </td>
      </tr><tr>
        <td>
          253
        </td>
        <td>
          3083
        </td>
        <td>
          11147
          -
          11239
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple5.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple5.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.RunOnPassProcessor]], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](ruleErrors, scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.Rule]](rules), outputExpressions, scala.Predef.Map.apply[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, Nothing]().++[com.sparkutils.quality.ExpressionLookup](exprLookups))
        </td>
      </tr><tr>
        <td>
          260
        </td>
        <td>
          3084
        </td>
        <td>
          11853
          -
          11900
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]]
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          3085
        </td>
        <td>
          11924
          -
          11950
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          3092
        </td>
        <td>
          12007
          -
          12007
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          265
        </td>
        <td>
          3089
        </td>
        <td>
          12034
          -
          12094
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$10: String) =&gt; LambdaViewError.apply(x$10, f.id)))
        </td>
      </tr><tr>
        <td>
          265
        </td>
        <td>
          3088
        </td>
        <td>
          12069
          -
          12093
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaViewError.apply(x$10, f.id)
        </td>
      </tr><tr>
        <td>
          265
        </td>
        <td>
          3087
        </td>
        <td>
          12088
          -
          12092
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.LambdaFunction.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.id
        </td>
      </tr><tr>
        <td>
          265
        </td>
        <td>
          3090
        </td>
        <td>
          12034
          -
          12094
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$10: String) =&gt; LambdaViewError.apply(x$10, f.id)))
        </td>
      </tr><tr>
        <td>
          265
        </td>
        <td>
          3086
        </td>
        <td>
          12061
          -
          12067
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.HasRuleText.expr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.expr
        </td>
      </tr><tr>
        <td>
          268
        </td>
        <td>
          3091
        </td>
        <td>
          12214
          -
          12240
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          270
        </td>
        <td>
          3093
        </td>
        <td>
          11973
          -
          12260
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.lambdaFunctions.flatMap[com.sparkutils.quality.impl.LambdaViewError, Seq[com.sparkutils.quality.impl.LambdaViewError]](((f: com.sparkutils.quality.LambdaFunction) =&gt; try {
  Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$10: String) =&gt; LambdaViewError.apply(x$10, f.id)))
} catch {
  case (_: Throwable) =&gt; scala.Predef.Set.empty[com.sparkutils.quality.impl.LambdaViewError]
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaViewError]).toSet[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          272
        </td>
        <td>
          3094
        </td>
        <td>
          12271
          -
          12271
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$12._1
        </td>
      </tr><tr>
        <td>
          272
        </td>
        <td>
          3095
        </td>
        <td>
          12294
          -
          12294
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$12._2
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          3098
        </td>
        <td>
          13297
          -
          13297
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          3097
        </td>
        <td>
          13298
          -
          13311
        </td>
        <td>
          Select
        </td>
        <td>
          scala.util.Either.LeftProjection.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$13._2.left.get
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          3100
        </td>
        <td>
          13292
          -
          13318
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$13: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$13._2.left.get))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]).toMap[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          3096
        </td>
        <td>
          13271
          -
          13275
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          3099
        </td>
        <td>
          13313
          -
          13313
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          3101
        </td>
        <td>
          13236
          -
          13319
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.mapValues
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaLeftExpressions.groupBy[String](((p: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; p._1)).mapValues[scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]](((e: Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])]) =&gt; e.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$13: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$13._2.left.get))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]).toMap[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])))
        </td>
      </tr><tr>
        <td>
          306
        </td>
        <td>
          3103
        </td>
        <td>
          13345
          -
          13345
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._2
        </td>
      </tr><tr>
        <td>
          306
        </td>
        <td>
          3102
        </td>
        <td>
          13330
          -
          13330
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._1
        </td>
      </tr><tr>
        <td>
          306
        </td>
        <td>
          3104
        </td>
        <td>
          13365
          -
          13365
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._3
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3107
        </td>
        <td>
          14237
          -
          14244
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pair._2
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3106
        </td>
        <td>
          14179
          -
          14196
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3109
        </td>
        <td>
          14179
          -
          14260
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.ExpressionLookup](com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3112
        </td>
        <td>
          14158
          -
          14158
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Iterable.canBuildFrom[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3111
        </td>
        <td>
          14165
          -
          14261
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          m.map[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup), scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](((pair: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.ExpressionLookup](com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))))(immutable.this.Map.canBuildFrom[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup])
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3105
        </td>
        <td>
          14188
          -
          14195
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pair._1
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3114
        </td>
        <td>
          14120
          -
          14268
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaNameToExpressions.values.flatMap[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup), Iterable[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]](((m: scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) =&gt; m.map[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup), scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup]](((pair: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; scala.Predef.ArrowAssoc[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.utils.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.ExpressionLookup](com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))))(immutable.this.Map.canBuildFrom[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup])))(collection.this.Iterable.canBuildFrom[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]).toMap[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup](scala.Predef.$conforms[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)])
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3108
        </td>
        <td>
          14200
          -
          14260
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.VariablesLookup.fieldsFromExpression
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups)
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3110
        </td>
        <td>
          14170
          -
          14170
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Map.canBuildFrom[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup]
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3113
        </td>
        <td>
          14263
          -
          14263
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.ExpressionLookup)]
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          3118
        </td>
        <td>
          14354
          -
          14418
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.map[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((name: String) =&gt; LambdaSparkFunctionNameError.apply(name, p._1)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError])
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          3117
        </td>
        <td>
          14362
          -
          14362
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          3119
        </td>
        <td>
          14348
          -
          14348
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          3116
        </td>
        <td>
          14377
          -
          14417
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaSparkFunctionNameError.apply(name, p._1)
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          3115
        </td>
        <td>
          14412
          -
          14416
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          3120
        </td>
        <td>
          14313
          -
          14425
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownLambdaSparkFunctions.flatMap[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((p: (com.sparkutils.quality.Id, Set[String])) =&gt; p._2.map[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((name: String) =&gt; LambdaSparkFunctionNameError.apply(name, p._1)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError])))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]).toSet[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          324
        </td>
        <td>
          3121
        </td>
        <td>
          14491
          -
          14504
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.size.&gt;(1)
        </td>
      </tr><tr>
        <td>
          324
        </td>
        <td>
          3135
        </td>
        <td>
          14514
          -
          14514
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]
        </td>
      </tr><tr>
        <td>
          326
        </td>
        <td>
          3122
        </td>
        <td>
          14549
          -
          14557
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pairs._2
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          3124
        </td>
        <td>
          14580
          -
          14615
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableLike.groupBy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          map.groupBy[Int](((x$15: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$15._2.children.size.-(1)))
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          3123
        </td>
        <td>
          14592
          -
          14614
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.-
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$15._2.children.size.-(1)
        </td>
      </tr><tr>
        <td>
          329
        </td>
        <td>
          3125
        </td>
        <td>
          14699
          -
          14712
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.size.&gt;(1)
        </td>
      </tr><tr>
        <td>
          329
        </td>
        <td>
          3127
        </td>
        <td>
          14667
          -
          14719
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.collectFirst
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          counts.collectFirst[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] with Serializable {
    def &lt;init&gt;(): &lt;$anon: ((Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]), B1 &gt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
      case (f @ _) if f._2.size.&gt;(1) =&gt; f
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): Boolean = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
      case (f @ _) if f._2.size.&gt;(1) =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]))
        </td>
      </tr><tr>
        <td>
          329
        </td>
        <td>
          3126
        </td>
        <td>
          14687
          -
          14687
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          3133
        </td>
        <td>
          14728
          -
          14855
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet)))
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          3134
        </td>
        <td>
          14728
          -
          14855
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet))))
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          3130
        </td>
        <td>
          14827
          -
          14831
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._1
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          3129
        </td>
        <td>
          14816
          -
          14825
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.size
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.size
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          3132
        </td>
        <td>
          14759
          -
          14845
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet)
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          3128
        </td>
        <td>
          14806
          -
          14814
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pairs._1
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          3131
        </td>
        <td>
          14833
          -
          14844
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.immutable.MapLike.keySet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.keySet
        </td>
      </tr><tr>
        <td>
          333
        </td>
        <td>
          3136
        </td>
        <td>
          14455
          -
          14867
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaNameToExpressions.filter(((p: (String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; p._2.size.&gt;(1))).flatMap[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]](((pairs: (String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; {
  val map: scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression] = pairs._2;
  val counts: scala.collection.immutable.Map[Int,scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]] = map.groupBy[Int](((x$15: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$15._2.children.size.-(1)));
  val moreThan1: Option[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] = counts.collectFirst[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](({
    @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] with Serializable {
      def &lt;init&gt;(): &lt;$anon: ((Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])&gt; = {
        $anonfun.super.&lt;init&gt;();
        ()
      };
      final override def applyOrElse[A1 &lt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]), B1 &gt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
        case (f @ _) if f._2.size.&gt;(1) =&gt; f
        case (defaultCase$ @ _) =&gt; default.apply(x1)
      };
      final def isDefinedAt(x1: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): Boolean = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
        case (f @ _) if f._2.size.&gt;(1) =&gt; true
        case (defaultCase$ @ _) =&gt; false
      }
    };
    new $anonfun()
  }: PartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]));
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet))))
}))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]).toSet[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]
        </td>
      </tr><tr>
        <td>
          337
        </td>
        <td>
          3151
        </td>
        <td>
          15023
          -
          15023
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          3150
        </td>
        <td>
          15038
          -
          15258
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)) =&gt; {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$16: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) = (pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) @unchecked) match {
    case (_1: com.sparkutils.quality.Id, _2: com.sparkutils.quality.VariablesLookup.Identifiers)(com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)((id @ _), (identifiers @ _)) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers](id, identifiers)
  };
  val id: com.sparkutils.quality.Id = x$16._1;
  val identifiers: com.sparkutils.quality.VariablesLookup.Identifiers = x$16._2;
  if (identifiers.diff(names).isEmpty)
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
}))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]])
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          3149
        </td>
        <td>
          15051
          -
          15051
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          339
        </td>
        <td>
          3138
        </td>
        <td>
          15080
          -
          15080
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$16._2
        </td>
      </tr><tr>
        <td>
          339
        </td>
        <td>
          3137
        </td>
        <td>
          15076
          -
          15076
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$16._1
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          3139
        </td>
        <td>
          15114
          -
          15145
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SetLike.isEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.diff(names).isEmpty
        </td>
      </tr><tr>
        <td>
          341
        </td>
        <td>
          3142
        </td>
        <td>
          15159
          -
          15163
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          341
        </td>
        <td>
          3141
        </td>
        <td>
          15159
          -
          15163
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          341
        </td>
        <td>
          3140
        </td>
        <td>
          15159
          -
          15163
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3148
        </td>
        <td>
          15191
          -
          15248
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3145
        </td>
        <td>
          15196
          -
          15247
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3147
        </td>
        <td>
          15191
          -
          15248
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3144
        </td>
        <td>
          15223
          -
          15223
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError]
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3143
        </td>
        <td>
          15224
          -
          15246
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaNameError.apply(x$17, id)
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3146
        </td>
        <td>
          15191
          -
          15248
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError]))
        </td>
      </tr><tr>
        <td>
          345
        </td>
        <td>
          3153
        </td>
        <td>
          15001
          -
          15280
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaLookups.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((p: (String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.VariablesLookup.Identifiers])) =&gt; p._2.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)) =&gt; {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$16: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) = (pair: (com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers) @unchecked) match {
    case (_1: com.sparkutils.quality.Id, _2: com.sparkutils.quality.VariablesLookup.Identifiers)(com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers)((id @ _), (identifiers @ _)) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, com.sparkutils.quality.VariablesLookup.Identifiers](id, identifiers)
  };
  val id: com.sparkutils.quality.Id = x$16._1;
  val identifiers: com.sparkutils.quality.VariablesLookup.Identifiers = x$16._2;
  if (identifiers.diff(names).isEmpty)
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
}))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]])))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]).flatten[com.sparkutils.quality.impl.LambdaNameError](scala.Predef.$conforms[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]).toSet[com.sparkutils.quality.impl.LambdaNameError]
        </td>
      </tr><tr>
        <td>
          345
        </td>
        <td>
          3152
        </td>
        <td>
          15267
          -
          15267
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          3157
        </td>
        <td>
          15285
          -
          15484
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, (Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError])](scala.Tuple10.apply[Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError]](lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]](lambdas), scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), exprLookups, viewErrors))
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          3154
        </td>
        <td>
          15418
          -
          15434
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]](lambdas)
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          3156
        </td>
        <td>
          15291
          -
          15483
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple10.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple10.apply[Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.utils.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError]](lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.utils.WithDocs[com.sparkutils.quality.LambdaFunction]](lambdas), scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), exprLookups, viewErrors)
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          3155
        </td>
        <td>
          15436
          -
          15457
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          349
        </td>
        <td>
          3164
        </td>
        <td>
          15621
          -
          15621
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          350
        </td>
        <td>
          3163
        </td>
        <td>
          15657
          -
          15767
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.trees.TreeNode.collect
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          s.plan.collect[T](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T] with Serializable {
    def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =&gt; T&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, B1 &gt;: T](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
      case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; f.apply(rel.tableName)
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
      case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T]))
        </td>
      </tr><tr>
        <td>
          350
        </td>
        <td>
          3162
        </td>
        <td>
          15671
          -
          15671
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          3159
        </td>
        <td>
          15711
          -
          15733
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lookup.apply(rel.tableName).unary_!
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          3158
        </td>
        <td>
          15719
          -
          15732
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedRelation.tableName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rel.tableName
        </td>
      </tr><tr>
        <td>
          352
        </td>
        <td>
          3160
        </td>
        <td>
          15747
          -
          15760
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedRelation.tableName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rel.tableName
        </td>
      </tr><tr>
        <td>
          352
        </td>
        <td>
          3161
        </td>
        <td>
          15745
          -
          15761
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Function1.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.apply(rel.tableName)
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          3166
        </td>
        <td>
          15602
          -
          15786
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expression.collect[Seq[T]](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.expressions.Expression,Seq[T]] with Serializable {
    def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.expressions.Expression =&gt; Seq[T]&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.expressions.Expression, B1 &gt;: Seq[T]](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.expressions.Expression]: org.apache.spark.sql.catalyst.expressions.Expression): org.apache.spark.sql.catalyst.expressions.Expression @unchecked) match {
      case (s @ (_: org.apache.spark.sql.catalyst.expressions.SubqueryExpression)) =&gt; s.plan.collect[T](({
        @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T] with Serializable {
          def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =&gt; T&gt; = {
            $anonfun.super.&lt;init&gt;();
            ()
          };
          final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, B1 &gt;: T](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
            case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; f.apply(rel.tableName)
            case (defaultCase$ @ _) =&gt; default.apply(x1)
          };
          final def isDefinedAt(x1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
            case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; true
            case (defaultCase$ @ _) =&gt; false
          }
        };
        new $anonfun()
      }: PartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T]))
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: org.apache.spark.sql.catalyst.expressions.Expression): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.expressions.Expression]: org.apache.spark.sql.catalyst.expressions.Expression): org.apache.spark.sql.catalyst.expressions.Expression @unchecked) match {
      case (s @ (_: org.apache.spark.sql.catalyst.expressions.SubqueryExpression)) =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[org.apache.spark.sql.catalyst.expressions.Expression,Seq[T]])).flatten[T](scala.Predef.$conforms[Seq[T]]).toSet[T]
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          3165
        </td>
        <td>
          15773
          -
          15773
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[Seq[T]]
        </td>
      </tr><tr>
        <td>
          357
        </td>
        <td>
          3198
        </td>
        <td>
          16027
          -
          16870
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val expr: org.apache.spark.sql.catalyst.expressions.Expression = exprThunk;
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$18: (com.sparkutils.quality.ExpressionLookup, com.sparkutils.quality.VariablesLookup.Identifiers, com.sparkutils.quality.VariablesLookup.Identifiers) = (com.sparkutils.quality.VariablesLookup.fieldsFromExpression(expr, lambdaLookups): com.sparkutils.quality.ExpressionLookup @unchecked) match {
    case (exl @ (attributesUsed: com.sparkutils.quality.VariablesLookup.Identifiers, unknownSparkFunctions: com.sparkutils.quality.VariablesLookup.Identifiers, lambdas: Set[com.sparkutils.quality.Id], sparkFunctions: Set[String])com.sparkutils.quality.ExpressionLookup((exprFields @ _), (unknownSparkFunctions @ _), _, _)) =&gt; scala.Tuple3.apply[com.sparkutils.quality.ExpressionLookup, com.sparkutils.quality.VariablesLookup.Identifiers, com.sparkutils.quality.VariablesLookup.Identifiers](exl, exprFields, unknownSparkFunctions)
  };
  val exl: com.sparkutils.quality.ExpressionLookup = x$18._1;
  val exprFields: com.sparkutils.quality.VariablesLookup.Identifiers = x$18._2;
  val unknownSparkFunctions: com.sparkutils.quality.VariablesLookup.Identifiers = x$18._3;
  val rules: scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError] = exprFields.flatMap[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((field: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (names.contains(field))
  scala.this.Option.option2Iterable[Nothing](scala.None)
else
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
    RuleNameError.apply(field, id)
  else
    OutputRuleNameError.apply(field, id)))))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]).toSet[com.sparkutils.quality.impl.RuleError];
  val viewErrors: Set[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable] = Validation.this.subQueryErrors[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable](viewLookup, exprThunk, if (outputRule)
    ((x$19: String) =&gt; OutputRuleViewError.apply(x$19, id))
  else
    ((x$20: String) =&gt; RuleViewError.apply(x$20, id)));
  val unknown: scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable] = unknownSparkFunctions.map[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((name: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (outputRule.unary_!)
    SparkFunctionNameError.apply(name, id)
  else
    OuputSparkFunctionNameError.apply(name, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]);
  scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](rules.++(unknown).++(viewErrors), exl)
}
        </td>
      </tr><tr>
        <td>
          359
        </td>
        <td>
          3169
        </td>
        <td>
          16093
          -
          16093
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._3
        </td>
      </tr><tr>
        <td>
          359
        </td>
        <td>
          3168
        </td>
        <td>
          16081
          -
          16081
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._2
        </td>
      </tr><tr>
        <td>
          359
        </td>
        <td>
          3167
        </td>
        <td>
          16058
          -
          16058
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._1
        </td>
      </tr><tr>
        <td>
          360
        </td>
        <td>
          3182
        </td>
        <td>
          16218
          -
          16218
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          3170
        </td>
        <td>
          16251
          -
          16272
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          names.contains(field)
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          3172
        </td>
        <td>
          16286
          -
          16290
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          3171
        </td>
        <td>
          16286
          -
          16290
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          3173
        </td>
        <td>
          16286
          -
          16290
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          365
        </td>
        <td>
          3181
        </td>
        <td>
          16318
          -
          16475
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id)))
        </td>
      </tr><tr>
        <td>
          365
        </td>
        <td>
          3180
        </td>
        <td>
          16318
          -
          16475
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id)))
        </td>
      </tr><tr>
        <td>
          365
        </td>
        <td>
          3179
        </td>
        <td>
          16318
          -
          16475
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id))
        </td>
      </tr><tr>
        <td>
          366
        </td>
        <td>
          3174
        </td>
        <td>
          16342
          -
          16353
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          367
        </td>
        <td>
          3175
        </td>
        <td>
          16371
          -
          16395
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          367
        </td>
        <td>
          3176
        </td>
        <td>
          16371
          -
          16395
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          369
        </td>
        <td>
          3178
        </td>
        <td>
          16431
          -
          16461
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          369
        </td>
        <td>
          3177
        </td>
        <td>
          16431
          -
          16461
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          371
        </td>
        <td>
          3183
        </td>
        <td>
          16200
          -
          16500
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprFields.flatMap[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((field: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (names.contains(field))
  scala.this.Option.option2Iterable[Nothing](scala.None)
else
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
    RuleNameError.apply(field, id)
  else
    OutputRuleNameError.apply(field, id)))))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]).toSet[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          373
        </td>
        <td>
          3184
        </td>
        <td>
          16579
          -
          16605
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleViewError.apply(x$19, id)
        </td>
      </tr><tr>
        <td>
          373
        </td>
        <td>
          3187
        </td>
        <td>
          16611
          -
          16631
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((x$20: String) =&gt; RuleViewError.apply(x$20, id))
        </td>
      </tr><tr>
        <td>
          373
        </td>
        <td>
          3186
        </td>
        <td>
          16611
          -
          16631
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleViewError.apply(x$20, id)
        </td>
      </tr><tr>
        <td>
          373
        </td>
        <td>
          3188
        </td>
        <td>
          16525
          -
          16632
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable](viewLookup, exprThunk, if (outputRule)
  ((x$19: String) =&gt; OutputRuleViewError.apply(x$19, id))
else
  ((x$20: String) =&gt; RuleViewError.apply(x$20, id)))
        </td>
      </tr><tr>
        <td>
          373
        </td>
        <td>
          3185
        </td>
        <td>
          16579
          -
          16605
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((x$19: String) =&gt; OutputRuleViewError.apply(x$19, id))
        </td>
      </tr><tr>
        <td>
          375
        </td>
        <td>
          3195
        </td>
        <td>
          16654
          -
          16825
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownSparkFunctions.map[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((name: com.sparkutils.quality.VariablesLookup.Identifier) =&gt; if (outputRule.unary_!)
  SparkFunctionNameError.apply(name, id)
else
  OuputSparkFunctionNameError.apply(name, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable])
        </td>
      </tr><tr>
        <td>
          375
        </td>
        <td>
          3194
        </td>
        <td>
          16679
          -
          16679
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]
        </td>
      </tr><tr>
        <td>
          376
        </td>
        <td>
          3189
        </td>
        <td>
          16701
          -
          16712
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          377
        </td>
        <td>
          3190
        </td>
        <td>
          16724
          -
          16756
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.SparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          SparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          377
        </td>
        <td>
          3191
        </td>
        <td>
          16724
          -
          16756
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.SparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          SparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          379
        </td>
        <td>
          3193
        </td>
        <td>
          16780
          -
          16817
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OuputSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OuputSparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          379
        </td>
        <td>
          3192
        </td>
        <td>
          16780
          -
          16817
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OuputSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OuputSparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          382
        </td>
        <td>
          3196
        </td>
        <td>
          16834
          -
          16864
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rules.++(unknown).++(viewErrors)
        </td>
      </tr><tr>
        <td>
          382
        </td>
        <td>
          3197
        </td>
        <td>
          16833
          -
          16870
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](rules.++(unknown).++(viewErrors), exl)
        </td>
      </tr><tr>
        <td>
          384
        </td>
        <td>
          3212
        </td>
        <td>
          16912
          -
          17078
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.ExpressionLookup](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleError](if (outputRule.unary_!)
  RuleSyntaxError.apply(id, e.getMessage())
else
  OutputRuleSyntaxError.apply(id, e.getMessage())), com.sparkutils.quality.ExpressionLookup.apply(com.sparkutils.quality.ExpressionLookup.apply$default$1, com.sparkutils.quality.ExpressionLookup.apply$default$2, com.sparkutils.quality.ExpressionLookup.apply$default$3, com.sparkutils.quality.ExpressionLookup.apply$default$4))
        </td>
      </tr><tr>
        <td>
          384
        </td>
        <td>
          3206
        </td>
        <td>
          16913
          -
          17057
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleError](if (outputRule.unary_!)
  RuleSyntaxError.apply(id, e.getMessage())
else
  OutputRuleSyntaxError.apply(id, e.getMessage()))
        </td>
      </tr><tr>
        <td>
          385
        </td>
        <td>
          3199
        </td>
        <td>
          16930
          -
          16941
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          386
        </td>
        <td>
          3202
        </td>
        <td>
          16953
          -
          16986
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          386
        </td>
        <td>
          3201
        </td>
        <td>
          16953
          -
          16986
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          386
        </td>
        <td>
          3200
        </td>
        <td>
          16973
          -
          16985
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Throwable.getMessage
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.getMessage()
        </td>
      </tr><tr>
        <td>
          388
        </td>
        <td>
          3205
        </td>
        <td>
          17010
          -
          17049
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          388
        </td>
        <td>
          3204
        </td>
        <td>
          17010
          -
          17049
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          388
        </td>
        <td>
          3203
        </td>
        <td>
          17036
          -
          17048
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Throwable.getMessage
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.getMessage()
        </td>
      </tr><tr>
        <td>
          389
        </td>
        <td>
          3208
        </td>
        <td>
          17059
          -
          17059
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$2
        </td>
      </tr><tr>
        <td>
          389
        </td>
        <td>
          3211
        </td>
        <td>
          17059
          -
          17077
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply(com.sparkutils.quality.ExpressionLookup.apply$default$1, com.sparkutils.quality.ExpressionLookup.apply$default$2, com.sparkutils.quality.ExpressionLookup.apply$default$3, com.sparkutils.quality.ExpressionLookup.apply$default$4)
        </td>
      </tr><tr>
        <td>
          389
        </td>
        <td>
          3207
        </td>
        <td>
          17059
          -
          17059
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$1
        </td>
      </tr><tr>
        <td>
          389
        </td>
        <td>
          3210
        </td>
        <td>
          17059
          -
          17059
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$4
        </td>
      </tr><tr>
        <td>
          389
        </td>
        <td>
          3209
        </td>
        <td>
          17059
          -
          17059
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.ExpressionLookup.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.ExpressionLookup.apply$default$3
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>