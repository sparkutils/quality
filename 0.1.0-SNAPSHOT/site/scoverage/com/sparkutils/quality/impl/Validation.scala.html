<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/impl/Validation.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality.impl
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality.impl.VariablesLookup.Identifiers
</span>4 <span style=''>import com.sparkutils.quality.impl.util.RuleSuiteDocs.{IdTrEither, LambdaId, OutputExpressionId, RuleId}
</span>5 <span style=''>import com.sparkutils.quality.impl.util.{Docs, DocsParser, RuleSuiteDocs, WithDocs}
</span>6 <span style=''>import com.sparkutils.quality._
</span>7 <span style=''>import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation
</span>8 <span style=''>import org.apache.spark.sql.catalyst.expressions.{Expression, SubqueryExpression, LambdaFunction =&gt; SLambdaFunction}
</span>9 <span style=''>import org.apache.spark.sql.types.StructType
</span>10 <span style=''>import org.apache.spark.sql._
</span>11 <span style=''>
</span>12 <span style=''>import scala.collection.mutable
</span>13 <span style=''>
</span>14 <span style=''>sealed trait RuleRelevant
</span>15 <span style=''>sealed trait LambdaRelevant
</span>16 <span style=''>sealed trait OutputExpressionRelevant
</span>17 <span style=''>
</span>18 <span style=''>sealed trait HasId {
</span>19 <span style=''>  def id: Id
</span>20 <span style=''>}
</span>21 <span style=''>
</span>22 <span style=''>sealed trait HasOutputText {
</span>23 <span style=''>  def outputText: String
</span>24 <span style=''>}
</span>25 <span style=''>
</span>26 <span style=''>sealed trait HasNonIdText {
</span>27 <span style=''>  def nonIdText: String
</span>28 <span style=''>}
</span>29 <span style=''>
</span>30 <span style=''>/**
</span>31 <span style=''> * Base for RuleWarnings
</span>32 <span style=''> */
</span>33 <span style=''>sealed trait RuleWarning extends HasId with HasOutputText with HasNonIdText {
</span>34 <span style=''>  def warning: String
</span>35 <span style=''>
</span>36 <span style=''>  override def nonIdText: String = </span><span style='background: #AEF1AE'>warning</span><span style=''>
</span>37 <span style=''>
</span>38 <span style=''>  /**
</span>39 <span style=''>   * If the error is syntax based - defined by parsing, rather than any later stage
</span>40 <span style=''>   * @return
</span>41 <span style=''>   */
</span>42 <span style=''>  def syntax: Boolean = </span><span style='background: #AEF1AE'>false</span><span style=''>
</span>43 <span style=''>
</span>44 <span style=''>  def warningText = </span><span style='background: #AEF1AE'>s&quot;$warning, occurred when processing id $id&quot;</span><span style=''>
</span>45 <span style=''>
</span>46 <span style=''>  override def outputText: String = </span><span style='background: #AEF1AE'>warningText</span><span style=''>
</span>47 <span style=''>}
</span>48 <span style=''>
</span>49 <span style=''>sealed trait SyntaxWarning extends RuleWarning {
</span>50 <span style=''>  final override def syntax: Boolean = </span><span style='background: #AEF1AE'>true</span><span style=''>
</span>51 <span style=''>}
</span>52 <span style=''>
</span>53 <span style=''>sealed trait SyntaxNameWarning extends SyntaxWarning {
</span>54 <span style=''>  def name: String
</span>55 <span style=''>}
</span>56 <span style=''>
</span>57 <span style=''>case class LambdaPossibleSOE(id: Id) extends RuleWarning with LambdaRelevant {
</span>58 <span style=''>  val warning = </span><span style='background: #AEF1AE'>&quot;Possible SOE detected&quot;</span><span style=''>
</span>59 <span style=''>}
</span>60 <span style=''>
</span>61 <span style=''>case class NonLambdaDocParameters(id: Id) extends SyntaxWarning {
</span>62 <span style=''>  val warning = </span><span style='background: #AEF1AE'>&quot;Parameter documentation is present on a non lambda expression&quot;</span><span style=''>
</span>63 <span style=''>}
</span>64 <span style=''>
</span>65 <span style=''>case class ExtraDocParameter(id: Id, name: String) extends SyntaxNameWarning with LambdaRelevant {
</span>66 <span style=''>  val warning = </span><span style='background: #AEF1AE'>s&quot;Parameter $name is not found in the lambda expression&quot;</span><span style=''>
</span>67 <span style=''>}
</span>68 <span style=''>
</span>69 <span style=''>/**
</span>70 <span style=''> * Base for RuleErrors
</span>71 <span style=''> */
</span>72 <span style=''>sealed trait RuleError extends HasId with HasOutputText with HasNonIdText {
</span>73 <span style=''>  def error: String
</span>74 <span style=''>
</span>75 <span style=''>  override def nonIdText: String = </span><span style='background: #AEF1AE'>error</span><span style=''>
</span>76 <span style=''>  /**
</span>77 <span style=''>   * If the error is syntax based - defined by parsing, rather than any later stage
</span>78 <span style=''>   * @return
</span>79 <span style=''>   */
</span>80 <span style=''>  def syntax: Boolean = </span><span style='background: #AEF1AE'>false</span><span style=''>
</span>81 <span style=''>
</span>82 <span style=''>  def errorText = </span><span style='background: #AEF1AE'>s&quot;$error occurred when processing id $id&quot;</span><span style=''>
</span>83 <span style=''>
</span>84 <span style=''>  override def outputText: String = </span><span style='background: #AEF1AE'>errorText</span><span style=''>
</span>85 <span style=''>}
</span>86 <span style=''>
</span>87 <span style=''>sealed trait SyntaxError extends RuleError {
</span>88 <span style=''>  final override def syntax: Boolean = </span><span style='background: #AEF1AE'>true</span><span style=''>
</span>89 <span style=''>}
</span>90 <span style=''>
</span>91 <span style=''>sealed trait NameMissingError extends RuleError {
</span>92 <span style=''>  def name: String
</span>93 <span style=''>  final override def error = </span><span style='background: #AEF1AE'>s&quot;Name $name is missing&quot;</span><span style=''>
</span>94 <span style=''>}
</span>95 <span style=''>
</span>96 <span style=''>sealed trait ViewMissingError extends RuleError {
</span>97 <span style=''>  def name: String
</span>98 <span style=''>  final override def error = </span><span style='background: #AEF1AE'>s&quot;</span><span style='background: #F0ADAD'>View $name is missing&quot;</span><span style=''>
</span>99 <span style=''>}
</span>100 <span style=''>
</span>101 <span style=''>case class LambdaSyntaxError(id: Id, error: String) extends SyntaxError with LambdaRelevant
</span>102 <span style=''>case class LambdaStackOverflowError(id: Id) extends SyntaxError with LambdaRelevant {
</span>103 <span style=''>  val error = </span><span style='background: #AEF1AE'>&quot;A lambda function seems to infinitely recurse&quot;</span><span style=''>
</span>104 <span style=''>}
</span>105 <span style=''>case class LambdaNameError(name: String, id: Id) extends NameMissingError with LambdaRelevant
</span>106 <span style=''>case class LambdaMultipleImplementationWithSameArityError(name: String, count: Int, argLength: Int, ids: Set[Id]) extends SyntaxError with LambdaRelevant {
</span>107 <span style=''>  val error = </span><span style='background: #AEF1AE'>s&quot;Lambda function $name has $count implementations with $argLength arguments&quot;</span><span style=''>
</span>108 <span style=''>  val id = </span><span style='background: #AEF1AE'>ids.head</span><span style=''>
</span>109 <span style=''>}
</span>110 <span style=''>case class LambdaViewError(name: String, id: Id) extends ViewMissingError with LambdaRelevant
</span>111 <span style=''>
</span>112 <span style=''>case class RuleSyntaxError(id: Id, error: String) extends SyntaxError with RuleRelevant
</span>113 <span style=''>case class RuleNameError(name: String, id: Id) extends NameMissingError with RuleRelevant
</span>114 <span style=''>case class RuleViewError(name: String, id: Id) extends ViewMissingError with RuleRelevant
</span>115 <span style=''>
</span>116 <span style=''>case class OutputRuleSyntaxError(id: Id, error: String) extends SyntaxError with OutputExpressionRelevant
</span>117 <span style=''>case class OutputRuleNameError(name: String, id: Id) extends NameMissingError with OutputExpressionRelevant
</span>118 <span style=''>case class OutputRuleViewError(name: String, id: Id) extends ViewMissingError with OutputExpressionRelevant
</span>119 <span style=''>
</span>120 <span style=''>case class LambdaSparkFunctionNameError(name: String, id: Id) extends NameMissingError with LambdaRelevant
</span>121 <span style=''>case class SparkFunctionNameError(name: String, id: Id) extends NameMissingError with RuleRelevant
</span>122 <span style=''>case class OuputSparkFunctionNameError(name: String, id: Id) extends NameMissingError with OutputExpressionRelevant
</span>123 <span style=''>
</span>124 <span style=''>case class DataFrameSyntaxError(error: String) extends SyntaxError {
</span>125 <span style=''>  val id = </span><span style='background: #AEF1AE'>Validation.dataFrameSyntaxErrorId</span><span style=''>
</span>126 <span style=''>}
</span>127 <span style=''>
</span>128 <span style=''>/**
</span>129 <span style=''> * Paramters to pass into showString for debugging / validation
</span>130 <span style=''> * @param numRows defaults to 1000
</span>131 <span style=''> * @param truncate
</span>132 <span style=''> * @param vertical
</span>133 <span style=''> */
</span>134 <span style=''>case class ShowParams(numRows: Int = 1000, truncate: Int = 0, vertical: Boolean = false)
</span>135 <span style=''>
</span>136 <span style=''>object Validation {
</span>137 <span style=''>  val unknownSOEId = </span><span style='background: #AEF1AE'>Id(Int.MinValue,Int.MinValue)</span><span style=''>
</span>138 <span style=''>  val dataFrameSyntaxErrorId = </span><span style='background: #AEF1AE'>Id(Int.MinValue+1,Int.MinValue+1)</span><span style=''>
</span>139 <span style=''>
</span>140 <span style=''>  protected[quality] val defaultViewLookup: String =&gt; Boolean =
</span>141 <span style=''>    </span><span style='background: #AEF1AE'>SparkSession.active.catalog.tableExists(_)</span><span style=''>
</span>142 <span style=''>
</span>143 <span style=''>  protected[quality] val emptyDocs = </span><span style='background: #AEF1AE'>Docs()</span><span style=''>
</span>144 <span style=''>
</span>145 <span style=''>  /**
</span>146 <span style=''>   * For a given dataFrame provide a full set of any validation errors for a given ruleSuite.
</span>147 <span style=''>   *
</span>148 <span style=''>   * @param schemaOrFrame when it's a Left( StructType ) the struct will be used to test against and an emptyDataframe of this type created to resolve on the spark level.  Using Right(DataFrame) will cause that dataframe to be used which is great for test cases with a runnerFunction
</span>149 <span style=''>   * @param ruleSuite
</span>150 <span style=''>   * @param runnerFunction - allows you to create a ruleRunner or ruleEngineRunner with different configurations
</span>151 <span style=''>   * @param showParams - configure how the output text is formatted using the same options and formatting as dataFrame.show
</span>152 <span style=''>   * @param qualityName - the column name to store the runnerFunction results in
</span>153 <span style=''>   * @param recursiveLambdasSOEIsOk - this signals that finding a recursive lambda SOE should not stop the evaluations - if true it will still try to run any runnerFunction but may not give the correct results
</span>154 <span style=''>   * @param transformBeforeShow - an optional transformation function to help shape what results are pushed to show
</span>155 <span style=''>   * @param viewLookup - for any subquery used looks up the view name for being present (quoted and with schema), defaults to the current spark catalogue
</span>156 <span style=''>   * @return A set of errors and the output from the dataframe when a runnerFunction is specified
</span>157 <span style=''>   */
</span>158 <span style=''>  def validate(schemaOrFrame: Either[StructType, DataFrame], ruleSuite: RuleSuite, showParams: ShowParams = ShowParams(),
</span>159 <span style=''>               runnerFunction: Option[DataFrame =&gt; Column] = None, qualityName: String = &quot;Quality&quot;,
</span>160 <span style=''>               recursiveLambdasSOEIsOk: Boolean = false, transformBeforeShow: DataFrame =&gt; DataFrame = identity, viewLookup: String =&gt; Boolean = Validation.defaultViewLookup):
</span>161 <span style=''>                (Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]) = {
</span>162 <span style=''>    val schema = </span><span style='background: #AEF1AE'>schemaOrFrame.fold(identity, _.schema)</span><span style=''>
</span>163 <span style=''>
</span>164 <span style=''>    val names = </span><span style='background: #AEF1AE'>namesFromSchema(schema)</span><span style=''>
</span>165 <span style=''>
</span>166 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>167 <span style=''>
</span>168 <span style=''>    val ((lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, lambdas, lambdaDocWarnings, lambadaExpressionLookups, lambdaViewErrors)) =
</span>169 <span style=''>      validateLambdas(ruleSuite, recursiveLambdasSOEIsOk, names, viewLookup) match {
</span>170 <span style=''>        case Left(toReturn) =&gt; return toReturn
</span>171 <span style=''>        case Right(result) =&gt; result
</span>172 <span style=''>      }
</span>173 <span style=''>
</span>174 <span style=''>    </span><span style='background: #AEF1AE'>docsWarnings ++= lambdaDocWarnings</span><span style=''>
</span>175 <span style=''>
</span>176 <span style=''>    val (ruleErrors, ruleDocWarnings, rules, outputExpressions, ruleExpressionLookups) = validateRules(ruleSuite, lambdaLookups, names, viewLookup)
</span>177 <span style=''>
</span>178 <span style=''>    </span><span style='background: #AEF1AE'>docsWarnings ++= ruleDocWarnings</span><span style=''>
</span>179 <span style=''>
</span>180 <span style=''>    val (showOut, dfErrors) =
</span>181 <span style=''>      validateAgainstDataFrame(schemaOrFrame, showParams, runnerFunction, qualityName, transformBeforeShow, schema, viewLookup)
</span>182 <span style=''>
</span>183 <span style=''>    </span><span style='background: #AEF1AE'>(unknownLambdaSparkFunctionErrors ++ lambdaArityErrors ++ dfErrors ++ ruleErrors ++ lambdaNameErrors ++ lambdaSyntaxErrors.map(_._2.right.get).toSet ++ lambdaViewErrors,
</span>184 <span style=''></span><span style='background: #AEF1AE'>      potentialOverflows.map( LambdaPossibleSOE ) ++ (Set() ++ docsWarnings)
</span>185 <span style=''></span><span style='background: #AEF1AE'>      , showOut, RuleSuiteDocs(rules, outputExpressions, lambdas), lambadaExpressionLookups ++ ruleExpressionLookups)</span><span style=''>
</span>186 <span style=''>  }
</span>187 <span style=''>
</span>188 <span style=''>  protected def validateAgainstDataFrame(schemaOrFrame: Either[StructType, DataFrame], showParams: ShowParams, runnerFunction: Option[DataFrame =&gt; Column], qualityName: String, transformBeforeShow: DataFrame =&gt; DataFrame, schema: StructType, viewLookup: String =&gt; Boolean) = {
</span>189 <span style=''>    val basedf = </span><span style='background: #AEF1AE'>schemaOrFrame.right.getOrElse {
</span>190 <span style=''></span><span style='background: #AEF1AE'>      val session = SparkSession.active
</span>191 <span style=''></span><span style='background: #AEF1AE'>      val empty = session.sparkContext.emptyRDD[Row]
</span>192 <span style=''></span><span style='background: #AEF1AE'>      session.createDataFrame(empty, schema)
</span>193 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>194 <span style=''>
</span>195 <span style=''>    val (showOut, dfErrors) =
</span>196 <span style=''>      runnerFunction.fold((&quot;&quot;, Set.empty[RuleError]))(rf =&gt; {
</span>197 <span style=''>        val runner = rf(basedf)
</span>198 <span style=''>        try {
</span>199 <span style=''>          val withRules = basedf.withColumn(qualityName, runner)
</span>200 <span style=''>          val transformed = transformBeforeShow(withRules)
</span>201 <span style=''>          (QualitySparkUtils.toString(transformed, showParams), Set.empty)
</span>202 <span style=''>        } catch {
</span>203 <span style=''>          case e: Throwable =&gt; (&quot;&quot;, Set(DataFrameSyntaxError(e.getMessage)))
</span>204 <span style=''>        }
</span>205 <span style=''>      })
</span>206 <span style=''>    </span><span style='background: #AEF1AE'>(showOut, dfErrors)</span><span style=''>
</span>207 <span style=''>  }
</span>208 <span style=''>
</span>209 <span style=''>  protected def validateRules(ruleSuite: RuleSuite, lambdaLookups: Map[String, Map[Id, Set[String]]], names: Set[String], viewLookup: String =&gt; Boolean)= {
</span>210 <span style=''>    val doRule = </span><span style='background: #AEF1AE'>validateRule(lambdaLookups, names)</span><span style=''> _
</span>211 <span style=''>
</span>212 <span style=''>    var rules = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[Rule]]</span><span style=''>
</span>213 <span style=''>    var outputExpressions = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[RunOnPassProcessor]]</span><span style=''>
</span>214 <span style=''>    var exprLookups = </span><span style='background: #AEF1AE'>Map.empty[IdTrEither, ExpressionLookup]</span><span style=''>
</span>215 <span style=''>
</span>216 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>217 <span style=''>
</span>218 <span style=''>    def addDocs[T](id: Id, rule: T, expressionRule: HasRuleText): (Id, WithDocs[T]) =
</span>219 <span style=''>      </span><span style='background: #AEF1AE'>DocsParser.parse(expressionRule.rule).map { parseddocs =&gt;
</span>220 <span style=''></span><span style='background: #AEF1AE'>        val res = id -&gt; WithDocs(rule, parseddocs)
</span>221 <span style=''></span><span style='background: #AEF1AE'>        if (parseddocs.params.nonEmpty) {
</span>222 <span style=''></span><span style='background: #AEF1AE'>          docsWarnings += NonLambdaDocParameters(id)
</span>223 <span style=''></span><span style='background: #AEF1AE'>        }
</span>224 <span style=''></span><span style='background: #AEF1AE'>        res
</span>225 <span style=''></span><span style='background: #AEF1AE'>      }.getOrElse(id -&gt; WithDocs(rule, emptyDocs))</span><span style=''>
</span>226 <span style=''>
</span>227 <span style=''>    // do the rules
</span>228 <span style=''>    val ruleErrors =
</span>229 <span style=''>      </span><span style='background: #AEF1AE'>ruleSuite.ruleSets.flatMap { rs =&gt;
</span>230 <span style=''></span><span style='background: #AEF1AE'>        rs.rules.flatMap { r =&gt;
</span>231 <span style=''></span><span style='background: #AEF1AE'>          rules += addDocs(r.id, r, r.expression.asInstanceOf[HasRuleText])
</span>232 <span style=''></span><span style='background: #AEF1AE'>
</span>233 <span style=''></span><span style='background: #AEF1AE'>          val (ruleErrors, exprLookup) = doRule(r.id, r.expression.asInstanceOf[HasExpr].expr, false, viewLookup)
</span>234 <span style=''></span><span style='background: #AEF1AE'>          exprLookups += RuleId(r.id) -&gt; exprLookup
</span>235 <span style=''></span><span style='background: #AEF1AE'>
</span>236 <span style=''></span><span style='background: #AEF1AE'>          val outputErrors =
</span>237 <span style=''></span><span style='background: #AEF1AE'>            if (r.runOnPassProcessor != NoOpRunOnPassProcessor.noOp) {
</span>238 <span style=''></span><span style='background: #AEF1AE'>              outputExpressions += addDocs(r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[OutputExpression])
</span>239 <span style=''></span><span style='background: #AEF1AE'>
</span>240 <span style=''></span><span style='background: #AEF1AE'>              val (oErrors, oExprLookup) = doRule(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup)
</span>241 <span style=''></span><span style='background: #AEF1AE'>              exprLookups += OutputExpressionId(r.runOnPassProcessor.id) -&gt; oExprLookup
</span>242 <span style=''></span><span style='background: #AEF1AE'>              oErrors
</span>243 <span style=''></span><span style='background: #AEF1AE'>            } else
</span>244 <span style=''></span><span style='background: #AEF1AE'>              Set.empty
</span>245 <span style=''></span><span style='background: #AEF1AE'>
</span>246 <span style=''></span><span style='background: #AEF1AE'>          ruleErrors ++ outputErrors
</span>247 <span style=''></span><span style='background: #AEF1AE'>        }
</span>248 <span style=''></span><span style='background: #AEF1AE'>      }.toSet</span><span style=''>
</span>249 <span style=''>
</span>250 <span style=''>    </span><span style='background: #AEF1AE'>(ruleErrors, Set() ++ docsWarnings, Map() ++ rules, outputExpressions, Map() ++ exprLookups)</span><span style=''>
</span>251 <span style=''>  }
</span>252 <span style=''>
</span>253 <span style=''>  protected def validateLambdas(ruleSuite: RuleSuite, recursiveLambdasSOEIsOk: Boolean, names: Set[String], viewLookup: String =&gt; Boolean): Either[(Set[RuleError], Set[RuleWarning], String, RuleSuiteDocs, Map[IdTrEither, ExpressionLookup]),
</span>254 <span style=''>    (Seq[(String, Either[(Id, Expression), LambdaSyntaxError])], Map[String, Map[Id, Set[String]]],
</span>255 <span style=''>      Set[Id], Set[LambdaSparkFunctionNameError], Set[LambdaMultipleImplementationWithSameArityError], Set[LambdaNameError], Map[Id, WithDocs[LambdaFunction]], Set[RuleWarning], Map[IdTrEither, ExpressionLookup], Set[LambdaViewError])] = {
</span>256 <span style=''>
</span>257 <span style=''>    var lambdas = </span><span style='background: #AEF1AE'>Map.empty[Id, WithDocs[LambdaFunction]]</span><span style=''>
</span>258 <span style=''>    val docsWarnings = </span><span style='background: #AEF1AE'>mutable.Set[RuleWarning]()</span><span style=''>
</span>259 <span style=''>
</span>260 <span style=''>    val viewErrors = </span><span style='background: #AEF1AE'>ruleSuite.lambdaFunctions.flatMap { f =&gt;
</span>261 <span style=''></span><span style='background: #AEF1AE'>      try {
</span>262 <span style=''></span><span style='background: #AEF1AE'>        subQueryErrors(viewLookup, f.expr, LambdaViewError(_, f.id))
</span>263 <span style=''></span><span style='background: #AEF1AE'>      } catch {
</span>264 <span style=''></span><span style='background: #AEF1AE'>        // Might be a parser error, skip to let the below code pick it up
</span>265 <span style=''></span><span style='background: #AEF1AE'>        case _: Throwable =&gt; Set.empty[LambdaViewError]
</span>266 <span style=''></span><span style='background: #AEF1AE'>      }
</span>267 <span style=''></span><span style='background: #AEF1AE'>    }.toSet</span><span style=''>
</span>268 <span style=''>
</span>269 <span style=''>    val (lambdaLeftExpressions, lambdaSyntaxErrors) = ruleSuite.lambdaFunctions.map { f =&gt;
</span>270 <span style=''>      (f.name,
</span>271 <span style=''>        try {
</span>272 <span style=''>          val expr = f.expr
</span>273 <span style=''>          val ret = Left((f.id, expr))
</span>274 <span style=''>
</span>275 <span style=''>          val args =
</span>276 <span style=''>            expr match {
</span>277 <span style=''>              case lambda: SLambdaFunction =&gt; lambda.arguments.map(VariablesLookup.toName).toSet
</span>278 <span style=''>              case _ =&gt; Set.empty[String]
</span>279 <span style=''>            }
</span>280 <span style=''>
</span>281 <span style=''>          DocsParser.parse(f.rule).map { parseddocs =&gt;
</span>282 <span style=''>            lambdas += f.id -&gt; WithDocs(f, parseddocs)
</span>283 <span style=''>
</span>284 <span style=''>            parseddocs.params.keySet.foreach { name =&gt;
</span>285 <span style=''>              if (!args.contains(name)) {
</span>286 <span style=''>                docsWarnings += ExtraDocParameter(f.id, name)
</span>287 <span style=''>              }
</span>288 <span style=''>            }
</span>289 <span style=''>          }.getOrElse {
</span>290 <span style=''>            lambdas += f.id -&gt; WithDocs(f, emptyDocs)
</span>291 <span style=''>          }
</span>292 <span style=''>
</span>293 <span style=''>          ret
</span>294 <span style=''>        } catch {
</span>295 <span style=''>          case e: Throwable =&gt; Right(LambdaSyntaxError(f.id, e.getMessage))
</span>296 <span style=''>        })
</span>297 <span style=''>    }.partition {
</span>298 <span style=''>      _._2.isLeft
</span>299 <span style=''>    }
</span>300 <span style=''>
</span>301 <span style=''>    val lambdaNameToExpressions = </span><span style='background: #AEF1AE'>lambdaLeftExpressions.groupBy(p =&gt; p._1).mapValues(e =&gt; e.map(_._2.left.get).toMap)</span><span style=''>
</span>302 <span style=''>
</span>303 <span style=''>    val (lambdaLookups, potentialOverflows, unknownLambdaSparkFunctions) = try {
</span>304 <span style=''>      VariablesLookup.processLambdas(lambdaNameToExpressions)
</span>305 <span style=''>    } catch {
</span>306 <span style=''>      // SOE is possible with lambdas calling lambdas, capture that as a distinct issue
</span>307 <span style=''>      case soe: StackOverflowError =&gt;
</span>308 <span style=''>        if (recursiveLambdasSOEIsOk)
</span>309 <span style=''>        // type needed otherwise it gets stuck with the first param type derivation _1 &lt;: String instead of String
</span>310 <span style=''>          (Map.empty[String, Map[Id, Identifiers]], Set.empty[Id], Map.empty[Id, Set[String]])
</span>311 <span style=''>        else
</span>312 <span style=''>          return Left((Set(LambdaStackOverflowError(Validation.unknownSOEId)), Set.empty[RuleWarning], &quot;&quot;, RuleSuiteDocs(), Map.empty[IdTrEither, ExpressionLookup]))
</span>313 <span style=''>    }
</span>314 <span style=''>
</span>315 <span style=''>    // now that they are looked up, a bit duplicative but...
</span>316 <span style=''>    val exprLookups = </span><span style='background: #AEF1AE'>lambdaNameToExpressions.values.flatMap( m =&gt; m.map(pair =&gt; LambdaId(pair._1) -&gt; VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))).toMap</span><span style=''>
</span>317 <span style=''>
</span>318 <span style=''>    val unknownLambdaSparkFunctionErrors = </span><span style='background: #AEF1AE'>unknownLambdaSparkFunctions.flatMap(p =&gt; p._2.map(name =&gt;
</span>319 <span style=''></span><span style='background: #AEF1AE'>      LambdaSparkFunctionNameError(name, p._1))).toSet</span><span style=''>
</span>320 <span style=''>
</span>321 <span style=''>    val lambdaArityErrors = </span><span style='background: #AEF1AE'>lambdaNameToExpressions.filter(p =&gt; p._2.size &gt; 1).flatMap {
</span>322 <span style=''></span><span style='background: #AEF1AE'>      pairs =&gt;
</span>323 <span style=''></span><span style='background: #AEF1AE'>        val map = pairs._2
</span>324 <span style=''></span><span style='background: #AEF1AE'>
</span>325 <span style=''></span><span style='background: #AEF1AE'>        val counts = map.groupBy(_._2.children.size - 1) // one child is the return
</span>326 <span style=''></span><span style='background: #AEF1AE'>        val moreThan1 = counts.collectFirst { case f if f._2.size &gt; 1 =&gt; f }
</span>327 <span style=''></span><span style='background: #AEF1AE'>        moreThan1.map { f =&gt;
</span>328 <span style=''></span><span style='background: #AEF1AE'>          LambdaMultipleImplementationWithSameArityError(pairs._1, f._2.size, f._1, f._2.keySet)
</span>329 <span style=''></span><span style='background: #AEF1AE'>        }
</span>330 <span style=''></span><span style='background: #AEF1AE'>    }.toSet</span><span style=''>
</span>331 <span style=''>
</span>332 <span style=''>    // do we have variables used in the lambdas which are not in the schema?
</span>333 <span style=''>    val lambdaNameErrors: Set[LambdaNameError] =
</span>334 <span style=''>      </span><span style='background: #AEF1AE'>lambdaLookups.flatMap { p =&gt;
</span>335 <span style=''></span><span style='background: #AEF1AE'>        p._2.flatMap { pair =&gt;
</span>336 <span style=''></span><span style='background: #AEF1AE'>          val (id, identifiers) = pair
</span>337 <span style=''></span><span style='background: #AEF1AE'>          if (identifiers.diff(names).isEmpty)
</span>338 <span style=''></span><span style='background: #AEF1AE'>            None
</span>339 <span style=''></span><span style='background: #AEF1AE'>          else
</span>340 <span style=''></span><span style='background: #AEF1AE'>            Some(identifiers.diff(names).map(LambdaNameError(_, id)))
</span>341 <span style=''></span><span style='background: #AEF1AE'>        }
</span>342 <span style=''></span><span style='background: #AEF1AE'>      }.flatten.toSet</span><span style=''>
</span>343 <span style=''>    </span><span style='background: #AEF1AE'>Right((lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, Map() ++ lambdas, Set() ++ docsWarnings, exprLookups, viewErrors))</span><span style=''>
</span>344 <span style=''>  }
</span>345 <span style=''>
</span>346 <span style=''>  protected def subQueryErrors[T](lookup: String =&gt; Boolean, expression: Expression, f: String =&gt; T): Set[T] = (</span><span style='background: #AEF1AE'>expression collect {
</span>347 <span style=''></span><span style='background: #AEF1AE'>    case s: SubqueryExpression =&gt; s.plan.collect{
</span>348 <span style=''></span><span style='background: #AEF1AE'>      case rel: UnresolvedRelation if !lookup(rel.tableName) =&gt;
</span>349 <span style=''></span><span style='background: #AEF1AE'>        f(rel.tableName)
</span>350 <span style=''></span><span style='background: #AEF1AE'>    }
</span>351 <span style=''></span><span style='background: #AEF1AE'>  }).flatten.toSet</span><span style=''>
</span>352 <span style=''>
</span>353 <span style=''>  protected def validateRule(lambdaLookups: Map[String, Map[Id, Set[String]]], names: Set[String])(id: Id, exprThunk: =&gt; Expression, outputRule: Boolean, viewLookup: String =&gt; Boolean): (Set[RuleError], ExpressionLookup) =
</span>354 <span style=''>    try {
</span>355 <span style=''>      </span><span style='background: #AEF1AE'>val expr = exprThunk
</span>356 <span style=''></span><span style='background: #AEF1AE'>      val exl @ ExpressionLookup(exprFields, unknownSparkFunctions, _, _) = VariablesLookup.fieldsFromExpression(expr, lambdaLookups)
</span>357 <span style=''></span><span style='background: #AEF1AE'>      val rules = exprFields.flatMap{
</span>358 <span style=''></span><span style='background: #AEF1AE'>        field =&gt;
</span>359 <span style=''></span><span style='background: #AEF1AE'>          if (names.contains(field))
</span>360 <span style=''></span><span style='background: #AEF1AE'>            None
</span>361 <span style=''></span><span style='background: #AEF1AE'>          else
</span>362 <span style=''></span><span style='background: #AEF1AE'>            Some(
</span>363 <span style=''></span><span style='background: #AEF1AE'>              if (!outputRule)
</span>364 <span style=''></span><span style='background: #AEF1AE'>                RuleNameError(field, id)
</span>365 <span style=''></span><span style='background: #AEF1AE'>              else
</span>366 <span style=''></span><span style='background: #AEF1AE'>                OutputRuleNameError(field, id)
</span>367 <span style=''></span><span style='background: #AEF1AE'>            )
</span>368 <span style=''></span><span style='background: #AEF1AE'>      }.toSet[RuleError]
</span>369 <span style=''></span><span style='background: #AEF1AE'>
</span>370 <span style=''></span><span style='background: #AEF1AE'>      val viewErrors = subQueryErrors(viewLookup, exprThunk, if (outputRule) OutputRuleViewError(_, id) else RuleViewError(_, id))
</span>371 <span style=''></span><span style='background: #AEF1AE'>
</span>372 <span style=''></span><span style='background: #AEF1AE'>      val unknown = unknownSparkFunctions.map{ name =&gt;
</span>373 <span style=''></span><span style='background: #AEF1AE'>        if (!outputRule)
</span>374 <span style=''></span><span style='background: #AEF1AE'>          SparkFunctionNameError(name, id)
</span>375 <span style=''></span><span style='background: #AEF1AE'>        else
</span>376 <span style=''></span><span style='background: #AEF1AE'>          OuputSparkFunctionNameError(name, id)
</span>377 <span style=''></span><span style='background: #AEF1AE'>      }
</span>378 <span style=''></span><span style='background: #AEF1AE'>
</span>379 <span style=''></span><span style='background: #AEF1AE'>      (rules ++ unknown ++ viewErrors, exl)</span><span style=''>
</span>380 <span style=''>    } catch {
</span>381 <span style=''>      case e: Throwable =&gt; </span><span style='background: #AEF1AE'>(Set(
</span>382 <span style=''></span><span style='background: #AEF1AE'>        if (!outputRule)
</span>383 <span style=''></span><span style='background: #AEF1AE'>          RuleSyntaxError(id, e.getMessage)
</span>384 <span style=''></span><span style='background: #AEF1AE'>        else
</span>385 <span style=''></span><span style='background: #AEF1AE'>          OutputRuleSyntaxError(id, e.getMessage)
</span>386 <span style=''></span><span style='background: #AEF1AE'>      ), ExpressionLookup())</span><span style=''>
</span>387 <span style=''>    }
</span>388 <span style=''>
</span>389 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          3182
        </td>
        <td>
          1023
          -
          1030
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warning
        </td>
      </tr><tr>
        <td>
          42
        </td>
        <td>
          3183
        </td>
        <td>
          1165
          -
          1170
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          false
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          3184
        </td>
        <td>
          1194
          -
          1195
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          3187
        </td>
        <td>
          1195
          -
          1202
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warning
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          3189
        </td>
        <td>
          1192
          -
          1236
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;, occurred when processing id &quot;, &quot;&quot;).s(RuleWarning.this.warning, RuleWarning.this.id)
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          3186
        </td>
        <td>
          1235
          -
          1236
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          3188
        </td>
        <td>
          1233
          -
          1235
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasId.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.id
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          3185
        </td>
        <td>
          1202
          -
          1233
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;, occurred when processing id &quot;
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          3190
        </td>
        <td>
          1274
          -
          1285
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleWarning.warningText
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleWarning.this.warningText
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          3191
        </td>
        <td>
          1377
          -
          1381
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          true
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          3192
        </td>
        <td>
          1557
          -
          1580
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Possible SOE detected&quot;
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          3193
        </td>
        <td>
          1666
          -
          1729
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter documentation is present on a non lambda expression&quot;
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          3196
        </td>
        <td>
          1861
          -
          1865
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ExtraDocParameter.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExtraDocParameter.this.name
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          3195
        </td>
        <td>
          1865
          -
          1904
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is not found in the lambda expression&quot;
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          3194
        </td>
        <td>
          1850
          -
          1861
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter &quot;
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          3197
        </td>
        <td>
          1848
          -
          1904
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Parameter &quot;, &quot; is not found in the lambda expression&quot;).s(ExtraDocParameter.this.name)
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          3198
        </td>
        <td>
          2071
          -
          2076
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.error
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.error
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          3199
        </td>
        <td>
          2210
          -
          2215
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          false
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          3202
        </td>
        <td>
          2275
          -
          2276
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          3205
        </td>
        <td>
          2235
          -
          2276
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot; occurred when processing id &quot;, &quot;&quot;).s(RuleError.this.error, RuleError.this.id)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          3201
        </td>
        <td>
          2243
          -
          2273
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; occurred when processing id &quot;
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          3204
        </td>
        <td>
          2273
          -
          2275
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasId.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.id
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          3203
        </td>
        <td>
          2238
          -
          2243
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.error
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.error
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          3200
        </td>
        <td>
          2237
          -
          2238
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          3206
        </td>
        <td>
          2314
          -
          2323
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleError.errorText
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleError.this.errorText
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          3207
        </td>
        <td>
          2411
          -
          2415
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          true
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          3208
        </td>
        <td>
          2519
          -
          2525
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Name &quot;
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          3211
        </td>
        <td>
          2517
          -
          2541
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Name &quot;, &quot; is missing&quot;).s(NameMissingError.this.name)
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          3210
        </td>
        <td>
          2525
          -
          2529
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.NameMissingError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NameMissingError.this.name
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          3209
        </td>
        <td>
          2529
          -
          2541
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; is missing&quot;
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          3214
        </td>
        <td>
          2651
          -
          2655
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ViewMissingError.name
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ViewMissingError.this.name
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          3213
        </td>
        <td>
          2655
          -
          2667
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot; is missing&quot;
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          3212
        </td>
        <td>
          2645
          -
          2651
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;View &quot;
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          3215
        </td>
        <td>
          2643
          -
          2667
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;View &quot;, &quot; is missing&quot;).s(ViewMissingError.this.name)
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          3216
        </td>
        <td>
          2863
          -
          2910
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;A lambda function seems to infinitely recurse&quot;
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          3217
        </td>
        <td>
          3179
          -
          3196
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;Lambda function &quot;
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          3220
        </td>
        <td>
          3243
          -
          3254
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; arguments&quot;
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          3223
        </td>
        <td>
          3234
          -
          3243
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.argLength
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.argLength
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          3219
        </td>
        <td>
          3211
          -
          3234
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; implementations with &quot;
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          3222
        </td>
        <td>
          3206
          -
          3211
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.count
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.count
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          3221
        </td>
        <td>
          3196
          -
          3200
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.name
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          3224
        </td>
        <td>
          3177
          -
          3254
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Lambda function &quot;, &quot; has &quot;, &quot; implementations with &quot;, &quot; arguments&quot;).s(LambdaMultipleImplementationWithSameArityError.this.name, LambdaMultipleImplementationWithSameArityError.this.count, LambdaMultipleImplementationWithSameArityError.this.argLength)
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          3218
        </td>
        <td>
          3200
          -
          3206
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot; has &quot;
        </td>
      </tr><tr>
        <td>
          108
        </td>
        <td>
          3225
        </td>
        <td>
          3266
          -
          3274
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.IterableLike.head
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.this.ids.head
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          3226
        </td>
        <td>
          4367
          -
          4400
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.dataFrameSyntaxErrorId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.dataFrameSyntaxErrorId
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          3227
        </td>
        <td>
          4680
          -
          4709
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.Id.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.Id.apply(-2147483648, -2147483648)
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          3228
        </td>
        <td>
          4741
          -
          4774
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.Id.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.Id.apply(-2147483647, -2147483647)
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          3229
        </td>
        <td>
          4844
          -
          4886
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalog.Catalog.tableExists
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active.catalog.tableExists(x$1)
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          3232
        </td>
        <td>
          4925
          -
          4925
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.Docs.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.Docs.apply$default$3
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          3231
        </td>
        <td>
          4925
          -
          4925
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.Docs.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.Docs.apply$default$2
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          3230
        </td>
        <td>
          4925
          -
          4925
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.util.Docs.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.Docs.apply$default$1
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          3233
        </td>
        <td>
          4925
          -
          4931
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.Docs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.Docs.apply(com.sparkutils.quality.impl.util.Docs.apply$default$1, com.sparkutils.quality.impl.util.Docs.apply$default$2, com.sparkutils.quality.impl.util.Docs.apply$default$3)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3235
        </td>
        <td>
          6803
          -
          6811
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.Dataset.schema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$2.schema
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3234
        </td>
        <td>
          6793
          -
          6801
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.identity
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.identity[org.apache.spark.sql.types.StructType](x)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          3236
        </td>
        <td>
          6774
          -
          6812
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.fold
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          schemaOrFrame.fold[org.apache.spark.sql.types.StructType]({
  ((x: org.apache.spark.sql.types.StructType) =&gt; scala.Predef.identity[org.apache.spark.sql.types.StructType](x))
}, ((x$2: org.apache.spark.sql.DataFrame) =&gt; x$2.schema))
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          3237
        </td>
        <td>
          6830
          -
          6853
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.LookupIdFunctionsImports.namesFromSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.namesFromSchema(schema)
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          3238
        </td>
        <td>
          6878
          -
          6904
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3244
        </td>
        <td>
          7024
          -
          7024
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._6
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._6
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3247
        </td>
        <td>
          7070
          -
          7070
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._9
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._9
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3241
        </td>
        <td>
          6951
          -
          6951
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._3
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3240
        </td>
        <td>
          6936
          -
          6936
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._2
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3243
        </td>
        <td>
          7005
          -
          7005
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._5
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3246
        </td>
        <td>
          7051
          -
          7051
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._8
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._8
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3239
        </td>
        <td>
          6916
          -
          6916
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._1
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3248
        </td>
        <td>
          7096
          -
          7096
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._10
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._10
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3242
        </td>
        <td>
          6971
          -
          6971
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._4
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          3245
        </td>
        <td>
          7042
          -
          7042
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple10._7
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3._7
        </td>
      </tr><tr>
        <td>
          174
        </td>
        <td>
          3249
        </td>
        <td>
          7299
          -
          7333
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.Growable.++=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.++=(lambdaDocWarnings)
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          3253
        </td>
        <td>
          7380
          -
          7380
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._4
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          3250
        </td>
        <td>
          7344
          -
          7344
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._1
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          3252
        </td>
        <td>
          7373
          -
          7373
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._3
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          3254
        </td>
        <td>
          7399
          -
          7399
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._5
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._5
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          3251
        </td>
        <td>
          7356
          -
          7356
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple5._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4._2
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          3255
        </td>
        <td>
          7488
          -
          7520
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.Growable.++=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.++=(ruleDocWarnings)
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          3256
        </td>
        <td>
          7531
          -
          7531
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._1
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          3257
        </td>
        <td>
          7540
          -
          7540
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5._2
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          3265
        </td>
        <td>
          7685
          -
          8049
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple5.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple5.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], Set[com.sparkutils.quality.impl.RuleWarning], String, com.sparkutils.quality.impl.util.RuleSuiteDocs, scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.ExpressionLookup]](unknownLambdaSparkFunctionErrors.++[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]](lambdaArityErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]).++[com.sparkutils.quality.impl.RuleError, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](dfErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]).++(ruleErrors).++(lambdaNameErrors).++(lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$6: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$6._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError]).++(lambdaViewErrors), potentialOverflows.map[com.sparkutils.quality.impl.LambdaPossibleSOE, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaPossibleSOE]](LambdaPossibleSOE)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]).++[com.sparkutils.quality.impl.RuleWarning, Set[com.sparkutils.quality.impl.RuleWarning]](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning]), showOut, com.sparkutils.quality.impl.util.RuleSuiteDocs.apply(rules, outputExpressions, lambdas), lambadaExpressionLookups.++[com.sparkutils.quality.impl.ExpressionLookup](ruleExpressionLookups))
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          3258
        </td>
        <td>
          7686
          -
          7853
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownLambdaSparkFunctionErrors.++[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]](lambdaArityErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError with Product with Serializable with com.sparkutils.quality.impl.LambdaRelevant]).++[com.sparkutils.quality.impl.RuleError, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](dfErrors)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleError]).++(ruleErrors).++(lambdaNameErrors).++(lambdaSyntaxErrors.map[com.sparkutils.quality.impl.LambdaSyntaxError, Seq[com.sparkutils.quality.impl.LambdaSyntaxError]](((x$6: (String, Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$6._2.right.get))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaSyntaxError]).toSet[com.sparkutils.quality.impl.LambdaSyntaxError]).++(lambdaViewErrors)
        </td>
      </tr><tr>
        <td>
          184
        </td>
        <td>
          3262
        </td>
        <td>
          7861
          -
          7931
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          potentialOverflows.map[com.sparkutils.quality.impl.LambdaPossibleSOE, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaPossibleSOE]](LambdaPossibleSOE)(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]).++[com.sparkutils.quality.impl.RuleWarning, Set[com.sparkutils.quality.impl.RuleWarning]](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning])
        </td>
      </tr><tr>
        <td>
          184
        </td>
        <td>
          3259
        </td>
        <td>
          7883
          -
          7883
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaPossibleSOE]
        </td>
      </tr><tr>
        <td>
          184
        </td>
        <td>
          3261
        </td>
        <td>
          7905
          -
          7905
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.RuleWarning]
        </td>
      </tr><tr>
        <td>
          184
        </td>
        <td>
          3260
        </td>
        <td>
          7909
          -
          7930
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          185
        </td>
        <td>
          3264
        </td>
        <td>
          7999
          -
          8048
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambadaExpressionLookups.++[com.sparkutils.quality.impl.ExpressionLookup](ruleExpressionLookups)
        </td>
      </tr><tr>
        <td>
          185
        </td>
        <td>
          3263
        </td>
        <td>
          7949
          -
          7997
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.RuleSuiteDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.RuleSuiteDocs.apply(rules, outputExpressions, lambdas)
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          3269
        </td>
        <td>
          8349
          -
          8524
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.RightProjection.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          schemaOrFrame.right.getOrElse[org.apache.spark.sql.DataFrame]({
  val session: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession.active;
  val empty: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = session.sparkContext.emptyRDD[org.apache.spark.sql.Row]((ClassTag.apply[org.apache.spark.sql.Row](classOf[org.apache.spark.sql.Row]): scala.reflect.ClassTag[org.apache.spark.sql.Row]));
  session.createDataFrame(empty, schema)
})
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          3266
        </td>
        <td>
          8401
          -
          8420
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.SparkSession.active
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.SparkSession.active
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          3267
        </td>
        <td>
          8439
          -
          8473
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.SparkContext.emptyRDD
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          session.sparkContext.emptyRDD[org.apache.spark.sql.Row]((ClassTag.apply[org.apache.spark.sql.Row](classOf[org.apache.spark.sql.Row]): scala.reflect.ClassTag[org.apache.spark.sql.Row]))
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          3268
        </td>
        <td>
          8480
          -
          8518
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.SparkSession.createDataFrame
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          session.createDataFrame(empty, schema)
        </td>
      </tr><tr>
        <td>
          195
        </td>
        <td>
          3271
        </td>
        <td>
          8544
          -
          8544
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._2
        </td>
      </tr><tr>
        <td>
          195
        </td>
        <td>
          3270
        </td>
        <td>
          8535
          -
          8535
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$7._1
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          3272
        </td>
        <td>
          8981
          -
          9000
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[String, scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError]](showOut, dfErrors)
        </td>
      </tr><tr>
        <td>
          210
        </td>
        <td>
          3273
        </td>
        <td>
          9179
          -
          9213
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.validateRule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.validateRule(lambdaLookups, names)(id, exprThunk, outputRule, viewLookup)
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          3274
        </td>
        <td>
          9233
          -
          9262
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]]
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          3275
        </td>
        <td>
          9291
          -
          9334
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]]
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          3276
        </td>
        <td>
          9357
          -
          9396
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup]
        </td>
      </tr><tr>
        <td>
          216
        </td>
        <td>
          3277
        </td>
        <td>
          9421
          -
          9447
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          3278
        </td>
        <td>
          9558
          -
          9577
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasRuleText.rule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expressionRule.rule
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          3280
        </td>
        <td>
          9617
          -
          9649
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.impl.util.WithDocs[T]](com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, parseddocs))
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          3279
        </td>
        <td>
          9623
          -
          9649
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.WithDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, parseddocs)
        </td>
      </tr><tr>
        <td>
          221
        </td>
        <td>
          3286
        </td>
        <td>
          9658
          -
          9658
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          221
        </td>
        <td>
          3285
        </td>
        <td>
          9658
          -
          9658
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          221
        </td>
        <td>
          3281
        </td>
        <td>
          9662
          -
          9688
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.nonEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parseddocs.params.nonEmpty
        </td>
      </tr><tr>
        <td>
          222
        </td>
        <td>
          3283
        </td>
        <td>
          9702
          -
          9744
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.+=(NonLambdaDocParameters.apply(id))
        </td>
      </tr><tr>
        <td>
          222
        </td>
        <td>
          3282
        </td>
        <td>
          9718
          -
          9744
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.NonLambdaDocParameters.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NonLambdaDocParameters.apply(id)
        </td>
      </tr><tr>
        <td>
          222
        </td>
        <td>
          3284
        </td>
        <td>
          9702
          -
          9744
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.mutable.SetLike.+=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          docsWarnings.+=(NonLambdaDocParameters.apply(id))
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3289
        </td>
        <td>
          9785
          -
          9816
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.impl.util.WithDocs[T]](com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, Validation.this.emptyDocs))
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3288
        </td>
        <td>
          9791
          -
          9816
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.WithDocs.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, Validation.this.emptyDocs)
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3290
        </td>
        <td>
          9541
          -
          9817
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.DocsParser.parse(expressionRule.rule).map[(com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[T])](((parseddocs: com.sparkutils.quality.impl.util.Docs) =&gt; {
  val res: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[T]) = scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.impl.util.WithDocs[T]](com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, parseddocs));
  if (parseddocs.params.nonEmpty)
    docsWarnings.+=(NonLambdaDocParameters.apply(id))
  else
    ();
  res
})).getOrElse[(com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[T])](scala.Predef.ArrowAssoc[com.sparkutils.quality.Id](id).-&gt;[com.sparkutils.quality.impl.util.WithDocs[T]](com.sparkutils.quality.impl.util.WithDocs.apply[T](rule, Validation.this.emptyDocs)))
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          3287
        </td>
        <td>
          9806
          -
          9815
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.emptyDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.emptyDocs
        </td>
      </tr><tr>
        <td>
          229
        </td>
        <td>
          3316
        </td>
        <td>
          9893
          -
          9893
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          3315
        </td>
        <td>
          9909
          -
          10771
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rs.rules.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((r: com.sparkutils.quality.Rule) =&gt; {
  rules = rules.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasRuleText]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$8: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup) = (doRule.apply(r.id, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasExpr].expr, false, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.impl.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup)((ruleErrors @ _), (exprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup](ruleErrors, exprLookup)
  };
  val ruleErrors: Set[com.sparkutils.quality.impl.RuleError] = x$8._1;
  val exprLookup: com.sparkutils.quality.impl.ExpressionLookup = x$8._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.impl.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](exprLookup));
  val outputErrors: scala.collection.immutable.Set[_ &lt;: com.sparkutils.quality.impl.RuleError] = if (r.runOnPassProcessor.!=(NoOpRunOnPassProcessor.noOp))
    {
      outputExpressions = outputExpressions.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]](addDocs[com.sparkutils.quality.impl.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup) @unchecked) match {
        case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.impl.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup](oErrors, oExprLookup)
      };
      val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
      val oExprLookup: com.sparkutils.quality.impl.ExpressionLookup = x$9._2;
      exprLookups = exprLookups.+[com.sparkutils.quality.impl.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](oExprLookup));
      oErrors
    }
  else
    scala.Predef.Set.empty[Nothing];
  ruleErrors.++(outputErrors)
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError])
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          3314
        </td>
        <td>
          9926
          -
          9926
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          3292
        </td>
        <td>
          9969
          -
          10007
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.expression.asInstanceOf[com.sparkutils.quality.impl.HasRuleText]
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          3291
        </td>
        <td>
          9960
          -
          9964
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.Rule.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.id
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          3294
        </td>
        <td>
          9943
          -
          10008
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rules.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasRuleText]))
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          3293
        </td>
        <td>
          9952
          -
          10008
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.addDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasRuleText])
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          3295
        </td>
        <td>
          10025
          -
          10025
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._1
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          3296
        </td>
        <td>
          10037
          -
          10037
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$8._2
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          3298
        </td>
        <td>
          10134
          -
          10175
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprLookups.+[com.sparkutils.quality.impl.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](exprLookup))
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          3297
        </td>
        <td>
          10149
          -
          10175
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](exprLookup)
        </td>
      </tr><tr>
        <td>
          237
        </td>
        <td>
          3310
        </td>
        <td>
          10275
          -
          10694
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  outputExpressions = outputExpressions.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]](addDocs[com.sparkutils.quality.impl.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.impl.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup](oErrors, oExprLookup)
  };
  val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
  val oExprLookup: com.sparkutils.quality.impl.ExpressionLookup = x$9._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.impl.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](oExprLookup));
  oErrors
}
        </td>
      </tr><tr>
        <td>
          237
        </td>
        <td>
          3300
        </td>
        <td>
          10222
          -
          10273
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.!=(NoOpRunOnPassProcessor.noOp)
        </td>
      </tr><tr>
        <td>
          237
        </td>
        <td>
          3299
        </td>
        <td>
          10246
          -
          10273
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.NoOpRunOnPassProcessor.noOp
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          NoOpRunOnPassProcessor.noOp
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          3304
        </td>
        <td>
          10312
          -
          10434
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.addDocs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          addDocs[com.sparkutils.quality.impl.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression])
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          3301
        </td>
        <td>
          10320
          -
          10343
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RunOnPassProcessor.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.id
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          3303
        </td>
        <td>
          10367
          -
          10433
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          3305
        </td>
        <td>
          10291
          -
          10434
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputExpressions.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]](addDocs[com.sparkutils.quality.impl.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]))
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          3302
        </td>
        <td>
          10345
          -
          10365
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.Rule.runOnPassProcessor
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.runOnPassProcessor
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          3307
        </td>
        <td>
          10464
          -
          10464
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$9._2
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          3306
        </td>
        <td>
          10455
          -
          10455
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$9._1
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          3309
        </td>
        <td>
          10585
          -
          10658
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprLookups.+[com.sparkutils.quality.impl.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](oExprLookup))
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          3308
        </td>
        <td>
          10600
          -
          10658
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](oExprLookup)
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          3312
        </td>
        <td>
          10714
          -
          10723
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          3311
        </td>
        <td>
          10714
          -
          10723
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          246
        </td>
        <td>
          3313
        </td>
        <td>
          10735
          -
          10761
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleErrors.++(outputErrors)
        </td>
      </tr><tr>
        <td>
          248
        </td>
        <td>
          3317
        </td>
        <td>
          9866
          -
          10785
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.ruleSets.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((rs: com.sparkutils.quality.RuleSet) =&gt; rs.rules.flatMap[com.sparkutils.quality.impl.RuleError, Seq[com.sparkutils.quality.impl.RuleError]](((r: com.sparkutils.quality.Rule) =&gt; {
  rules = rules.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]](addDocs[com.sparkutils.quality.Rule](r.id, r, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasRuleText]));
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$8: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup) = (doRule.apply(r.id, r.expression.asInstanceOf[com.sparkutils.quality.impl.HasExpr].expr, false, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup) @unchecked) match {
    case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.impl.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup)((ruleErrors @ _), (exprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup](ruleErrors, exprLookup)
  };
  val ruleErrors: Set[com.sparkutils.quality.impl.RuleError] = x$8._1;
  val exprLookup: com.sparkutils.quality.impl.ExpressionLookup = x$8._2;
  exprLookups = exprLookups.+[com.sparkutils.quality.impl.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.RuleId(r.id)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](exprLookup));
  val outputErrors: scala.collection.immutable.Set[_ &lt;: com.sparkutils.quality.impl.RuleError] = if (r.runOnPassProcessor.!=(NoOpRunOnPassProcessor.noOp))
    {
      outputExpressions = outputExpressions.+[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]](addDocs[com.sparkutils.quality.impl.RunOnPassProcessor](r.runOnPassProcessor.id, r.runOnPassProcessor, r.runOnPassProcessor.returnIfPassed.asInstanceOf[com.sparkutils.quality.OutputExpression]));
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$9: (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup) = (doRule.apply(r.runOnPassProcessor.id, r.runOnPassProcessor.returnIfPassed.expr, true, viewLookup): (Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup) @unchecked) match {
        case (_1: Set[com.sparkutils.quality.impl.RuleError], _2: com.sparkutils.quality.impl.ExpressionLookup)(Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup)((oErrors @ _), (oExprLookup @ _)) =&gt; scala.Tuple2.apply[Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup](oErrors, oExprLookup)
      };
      val oErrors: Set[com.sparkutils.quality.impl.RuleError] = x$9._1;
      val oExprLookup: com.sparkutils.quality.impl.ExpressionLookup = x$9._2;
      exprLookups = exprLookups.+[com.sparkutils.quality.impl.ExpressionLookup](scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.OutputExpressionId(r.runOnPassProcessor.id)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](oExprLookup));
      oErrors
    }
  else
    scala.Predef.Set.empty[Nothing];
  ruleErrors.++(outputErrors)
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError])))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.RuleError]).toSet[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          3319
        </td>
        <td>
          10827
          -
          10841
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]](rules)
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          3318
        </td>
        <td>
          10804
          -
          10825
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          3321
        </td>
        <td>
          10791
          -
          10883
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple5.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple5.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.RunOnPassProcessor]], scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.ExpressionLookup]](ruleErrors, scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.Rule]](rules), outputExpressions, scala.Predef.Map.apply[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, Nothing]().++[com.sparkutils.quality.impl.ExpressionLookup](exprLookups))
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          3320
        </td>
        <td>
          10862
          -
          10882
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, Nothing]().++[com.sparkutils.quality.impl.ExpressionLookup](exprLookups)
        </td>
      </tr><tr>
        <td>
          257
        </td>
        <td>
          3322
        </td>
        <td>
          11489
          -
          11528
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[com.sparkutils.quality.Id, com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]]
        </td>
      </tr><tr>
        <td>
          258
        </td>
        <td>
          3323
        </td>
        <td>
          11552
          -
          11578
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.mutable.Set.apply[com.sparkutils.quality.impl.RuleWarning]()
        </td>
      </tr><tr>
        <td>
          260
        </td>
        <td>
          3330
        </td>
        <td>
          11635
          -
          11635
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          262
        </td>
        <td>
          3325
        </td>
        <td>
          11716
          -
          11720
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaFunction.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.id
        </td>
      </tr><tr>
        <td>
          262
        </td>
        <td>
          3327
        </td>
        <td>
          11662
          -
          11722
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$10: String) =&gt; LambdaViewError.apply(x$10, f.id)))
        </td>
      </tr><tr>
        <td>
          262
        </td>
        <td>
          3324
        </td>
        <td>
          11689
          -
          11695
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.HasRuleText.expr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.expr
        </td>
      </tr><tr>
        <td>
          262
        </td>
        <td>
          3326
        </td>
        <td>
          11697
          -
          11721
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaViewError.apply(x$10, f.id)
        </td>
      </tr><tr>
        <td>
          262
        </td>
        <td>
          3328
        </td>
        <td>
          11662
          -
          11722
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$10: String) =&gt; LambdaViewError.apply(x$10, f.id)))
        </td>
      </tr><tr>
        <td>
          265
        </td>
        <td>
          3329
        </td>
        <td>
          11842
          -
          11868
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.ImmutableSetFactory.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.empty[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          3331
        </td>
        <td>
          11601
          -
          11888
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.lambdaFunctions.flatMap[com.sparkutils.quality.impl.LambdaViewError, Seq[com.sparkutils.quality.impl.LambdaViewError]](((f: com.sparkutils.quality.impl.LambdaFunction) =&gt; try {
  Validation.this.subQueryErrors[com.sparkutils.quality.impl.LambdaViewError](viewLookup, f.expr, ((x$10: String) =&gt; LambdaViewError.apply(x$10, f.id)))
} catch {
  case (_: Throwable) =&gt; scala.Predef.Set.empty[com.sparkutils.quality.impl.LambdaViewError]
}))(collection.this.Seq.canBuildFrom[com.sparkutils.quality.impl.LambdaViewError]).toSet[com.sparkutils.quality.impl.LambdaViewError]
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          3333
        </td>
        <td>
          11922
          -
          11922
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$12._2
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          3332
        </td>
        <td>
          11899
          -
          11899
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$12._1
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          3334
        </td>
        <td>
          12900
          -
          12904
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          3336
        </td>
        <td>
          12926
          -
          12926
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          3339
        </td>
        <td>
          12865
          -
          12948
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.mapValues
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaLeftExpressions.groupBy[String](((p: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; p._1)).mapValues[scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]](((e: Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])]) =&gt; e.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$13: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$13._2.left.get))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]).toMap[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])))
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          3335
        </td>
        <td>
          12927
          -
          12940
        </td>
        <td>
          Select
        </td>
        <td>
          scala.util.Either.LeftProjection.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$13._2.left.get
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          3338
        </td>
        <td>
          12921
          -
          12947
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.map[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression), Seq[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]](((x$13: (String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])) =&gt; x$13._2.left.get))(collection.this.Seq.canBuildFrom[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]).toMap[com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)])
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          3337
        </td>
        <td>
          12942
          -
          12942
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)]
        </td>
      </tr><tr>
        <td>
          303
        </td>
        <td>
          3340
        </td>
        <td>
          12959
          -
          12959
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._1
        </td>
      </tr><tr>
        <td>
          303
        </td>
        <td>
          3342
        </td>
        <td>
          12994
          -
          12994
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._3
        </td>
      </tr><tr>
        <td>
          303
        </td>
        <td>
          3341
        </td>
        <td>
          12974
          -
          12974
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$14._2
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          3349
        </td>
        <td>
          13794
          -
          13890
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          m.map[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup), scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.ExpressionLookup]](((pair: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))))(immutable.this.Map.canBuildFrom[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup])
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          3352
        </td>
        <td>
          13749
          -
          13897
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaNameToExpressions.values.flatMap[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup), Iterable[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup)]](((m: scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) =&gt; m.map[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup), scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.ExpressionLookup]](((pair: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))))(immutable.this.Map.canBuildFrom[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup])))(collection.this.Iterable.canBuildFrom[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup)]).toMap[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup](scala.Predef.$conforms[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup)])
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          3343
        </td>
        <td>
          13817
          -
          13824
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pair._1
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          3351
        </td>
        <td>
          13892
          -
          13892
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup)]
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          3345
        </td>
        <td>
          13866
          -
          13873
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pair._2
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          3348
        </td>
        <td>
          13799
          -
          13799
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Map.canBuildFrom[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup]
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          3350
        </td>
        <td>
          13787
          -
          13787
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Iterable.canBuildFrom[(com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither, com.sparkutils.quality.impl.ExpressionLookup)]
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          3344
        </td>
        <td>
          13808
          -
          13825
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.util.RuleSuiteDocs.LambdaId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.util.RuleSuiteDocs.LambdaId(pair._1)
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          3347
        </td>
        <td>
          13808
          -
          13889
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither](com.sparkutils.quality.impl.util.RuleSuiteDocs.LambdaId(pair._1)).-&gt;[com.sparkutils.quality.impl.ExpressionLookup](VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups))
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          3346
        </td>
        <td>
          13829
          -
          13889
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.VariablesLookup.fieldsFromExpression
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          VariablesLookup.fieldsFromExpression(pair._2, lambdaLookups)
        </td>
      </tr><tr>
        <td>
          318
        </td>
        <td>
          3357
        </td>
        <td>
          13977
          -
          13977
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          318
        </td>
        <td>
          3356
        </td>
        <td>
          13983
          -
          14047
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.map[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((name: String) =&gt; LambdaSparkFunctionNameError.apply(name, p._1)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError])
        </td>
      </tr><tr>
        <td>
          318
        </td>
        <td>
          3355
        </td>
        <td>
          13991
          -
          13991
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3358
        </td>
        <td>
          13942
          -
          14054
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownLambdaSparkFunctions.flatMap[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((p: (com.sparkutils.quality.Id, Set[String])) =&gt; p._2.map[com.sparkutils.quality.impl.LambdaSparkFunctionNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]](((name: String) =&gt; LambdaSparkFunctionNameError.apply(name, p._1)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError])))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]).toSet[com.sparkutils.quality.impl.LambdaSparkFunctionNameError]
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3354
        </td>
        <td>
          14006
          -
          14046
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaSparkFunctionNameError.apply(name, p._1)
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          3353
        </td>
        <td>
          14041
          -
          14045
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          3359
        </td>
        <td>
          14120
          -
          14133
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.size.&gt;(1)
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          3373
        </td>
        <td>
          14143
          -
          14143
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]
        </td>
      </tr><tr>
        <td>
          323
        </td>
        <td>
          3360
        </td>
        <td>
          14178
          -
          14186
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pairs._2
        </td>
      </tr><tr>
        <td>
          325
        </td>
        <td>
          3361
        </td>
        <td>
          14221
          -
          14243
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.-
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$15._2.children.size.-(1)
        </td>
      </tr><tr>
        <td>
          325
        </td>
        <td>
          3362
        </td>
        <td>
          14209
          -
          14244
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableLike.groupBy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          map.groupBy[Int](((x$15: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$15._2.children.size.-(1)))
        </td>
      </tr><tr>
        <td>
          326
        </td>
        <td>
          3363
        </td>
        <td>
          14328
          -
          14341
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.size.&gt;(1)
        </td>
      </tr><tr>
        <td>
          326
        </td>
        <td>
          3365
        </td>
        <td>
          14296
          -
          14348
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.collectFirst
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          counts.collectFirst[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] with Serializable {
    def &lt;init&gt;(): &lt;$anon: ((Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]), B1 &gt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
      case (f @ _) if f._2.size.&gt;(1) =&gt; f
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): Boolean = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
      case (f @ _) if f._2.size.&gt;(1) =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]))
        </td>
      </tr><tr>
        <td>
          326
        </td>
        <td>
          3364
        </td>
        <td>
          14316
          -
          14316
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          327
        </td>
        <td>
          3372
        </td>
        <td>
          14357
          -
          14484
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet))))
        </td>
      </tr><tr>
        <td>
          327
        </td>
        <td>
          3371
        </td>
        <td>
          14357
          -
          14484
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet)))
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          3367
        </td>
        <td>
          14445
          -
          14454
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.size
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.size
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          3370
        </td>
        <td>
          14388
          -
          14474
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet)
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          3369
        </td>
        <td>
          14462
          -
          14473
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.immutable.MapLike.keySet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._2.keySet
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          3366
        </td>
        <td>
          14435
          -
          14443
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          pairs._1
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          3368
        </td>
        <td>
          14456
          -
          14460
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f._1
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          3374
        </td>
        <td>
          14084
          -
          14496
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaNameToExpressions.filter(((p: (String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; p._2.size.&gt;(1))).flatMap[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError, scala.collection.immutable.Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]](((pairs: (String, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; {
  val map: scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression] = pairs._2;
  val counts: scala.collection.immutable.Map[Int,scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]] = map.groupBy[Int](((x$15: (com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression)) =&gt; x$15._2.children.size.-(1)));
  val moreThan1: Option[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] = counts.collectFirst[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](({
    @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])] with Serializable {
      def &lt;init&gt;(): &lt;$anon: ((Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])&gt; = {
        $anonfun.super.&lt;init&gt;();
        ()
      };
      final override def applyOrElse[A1 &lt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]), B1 &gt;: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
        case (f @ _) if f._2.size.&gt;(1) =&gt; f
        case (defaultCase$ @ _) =&gt; default.apply(x1)
      };
      final def isDefinedAt(x1: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): Boolean = ((x1.asInstanceOf[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])): (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]) @unchecked) match {
        case (f @ _) if f._2.size.&gt;(1) =&gt; true
        case (defaultCase$ @ _) =&gt; false
      }
    };
    new $anonfun()
  }: PartialFunction[(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression]),(Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])]));
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](moreThan1.map[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError](((f: (Int, scala.collection.immutable.Map[com.sparkutils.quality.Id,org.apache.spark.sql.catalyst.expressions.Expression])) =&gt; LambdaMultipleImplementationWithSameArityError.apply(pairs._1, f._2.size, f._1, f._2.keySet))))
}))(immutable.this.Iterable.canBuildFrom[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]).toSet[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError]
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          3389
        </td>
        <td>
          14652
          -
          14652
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          335
        </td>
        <td>
          3387
        </td>
        <td>
          14680
          -
          14680
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Iterable.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          335
        </td>
        <td>
          3388
        </td>
        <td>
          14667
          -
          14887
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((pair: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.VariablesLookup.Identifiers)) =&gt; {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$16: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.VariablesLookup.Identifiers) = (pair: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.VariablesLookup.Identifiers) @unchecked) match {
    case (_1: com.sparkutils.quality.Id, _2: com.sparkutils.quality.impl.VariablesLookup.Identifiers)(com.sparkutils.quality.Id, com.sparkutils.quality.impl.VariablesLookup.Identifiers)((id @ _), (identifiers @ _)) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, com.sparkutils.quality.impl.VariablesLookup.Identifiers](id, identifiers)
  };
  val id: com.sparkutils.quality.Id = x$16._1;
  val identifiers: com.sparkutils.quality.impl.VariablesLookup.Identifiers = x$16._2;
  if (identifiers.diff(names).isEmpty)
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
}))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]])
        </td>
      </tr><tr>
        <td>
          336
        </td>
        <td>
          3376
        </td>
        <td>
          14709
          -
          14709
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$16._2
        </td>
      </tr><tr>
        <td>
          336
        </td>
        <td>
          3375
        </td>
        <td>
          14705
          -
          14705
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$16._1
        </td>
      </tr><tr>
        <td>
          337
        </td>
        <td>
          3377
        </td>
        <td>
          14743
          -
          14774
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SetLike.isEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.diff(names).isEmpty
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          3379
        </td>
        <td>
          14788
          -
          14792
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          3378
        </td>
        <td>
          14788
          -
          14792
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          3380
        </td>
        <td>
          14788
          -
          14792
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          3385
        </td>
        <td>
          14820
          -
          14877
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          3381
        </td>
        <td>
          14853
          -
          14875
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          LambdaNameError.apply(x$17, id)
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          3384
        </td>
        <td>
          14820
          -
          14877
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError]))
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          3383
        </td>
        <td>
          14825
          -
          14876
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          3386
        </td>
        <td>
          14820
          -
          14877
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          3382
        </td>
        <td>
          14852
          -
          14852
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError]
        </td>
      </tr><tr>
        <td>
          342
        </td>
        <td>
          3390
        </td>
        <td>
          14896
          -
          14896
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]
        </td>
      </tr><tr>
        <td>
          342
        </td>
        <td>
          3391
        </td>
        <td>
          14630
          -
          14909
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lambdaLookups.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((p: (String, Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.VariablesLookup.Identifiers])) =&gt; p._2.flatMap[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]](((pair: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.VariablesLookup.Identifiers)) =&gt; {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$16: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.VariablesLookup.Identifiers) = (pair: (com.sparkutils.quality.Id, com.sparkutils.quality.impl.VariablesLookup.Identifiers) @unchecked) match {
    case (_1: com.sparkutils.quality.Id, _2: com.sparkutils.quality.impl.VariablesLookup.Identifiers)(com.sparkutils.quality.Id, com.sparkutils.quality.impl.VariablesLookup.Identifiers)((id @ _), (identifiers @ _)) =&gt; scala.Tuple2.apply[com.sparkutils.quality.Id, com.sparkutils.quality.impl.VariablesLookup.Identifiers](id, identifiers)
  };
  val id: com.sparkutils.quality.Id = x$16._1;
  val identifiers: com.sparkutils.quality.impl.VariablesLookup.Identifiers = x$16._2;
  if (identifiers.diff(names).isEmpty)
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](scala.Some.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](identifiers.diff(names).map[com.sparkutils.quality.impl.LambdaNameError, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]](((x$17: com.sparkutils.quality.impl.VariablesLookup.Identifier) =&gt; LambdaNameError.apply(x$17, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.LambdaNameError])))
}))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]])))(immutable.this.Iterable.canBuildFrom[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]).flatten[com.sparkutils.quality.impl.LambdaNameError](scala.Predef.$conforms[scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaNameError]]).toSet[com.sparkutils.quality.impl.LambdaNameError]
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3394
        </td>
        <td>
          14920
          -
          15112
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple10.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple10.apply[Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.impl.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError]](lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]](lambdas), scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), exprLookups, viewErrors)
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3393
        </td>
        <td>
          15065
          -
          15086
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings)
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3392
        </td>
        <td>
          15047
          -
          15063
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]](lambdas)
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          3395
        </td>
        <td>
          14914
          -
          15113
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, (Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.impl.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError])](scala.Tuple10.apply[Seq[(String, scala.util.Either[(com.sparkutils.quality.Id, org.apache.spark.sql.catalyst.expressions.Expression),com.sparkutils.quality.impl.LambdaSyntaxError])], com.sparkutils.quality.impl.VariablesLookup.ProcessedLambdas, com.sparkutils.quality.impl.VariablesLookup.PossibleOverflowIds, scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaSparkFunctionNameError], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaMultipleImplementationWithSameArityError], Set[com.sparkutils.quality.impl.LambdaNameError], scala.collection.immutable.Map[com.sparkutils.quality.Id,com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]], scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleWarning], scala.collection.immutable.Map[com.sparkutils.quality.impl.util.RuleSuiteDocs.IdTrEither,com.sparkutils.quality.impl.ExpressionLookup], scala.collection.immutable.Set[com.sparkutils.quality.impl.LambdaViewError]](lambdaSyntaxErrors, lambdaLookups, potentialOverflows, unknownLambdaSparkFunctionErrors, lambdaArityErrors, lambdaNameErrors, scala.Predef.Map.apply[com.sparkutils.quality.Id, Nothing]().++[com.sparkutils.quality.impl.util.WithDocs[com.sparkutils.quality.impl.LambdaFunction]](lambdas), scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleWarning]().++(docsWarnings), exprLookups, viewErrors))
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          3402
        </td>
        <td>
          15250
          -
          15250
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          347
        </td>
        <td>
          3401
        </td>
        <td>
          15286
          -
          15396
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.trees.TreeNode.collect
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          s.plan.collect[T](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T] with Serializable {
    def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =&gt; T&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, B1 &gt;: T](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
      case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; f.apply(rel.tableName)
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
      case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T]))
        </td>
      </tr><tr>
        <td>
          347
        </td>
        <td>
          3400
        </td>
        <td>
          15300
          -
          15300
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun.$anonfun.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anonfun()
        </td>
      </tr><tr>
        <td>
          348
        </td>
        <td>
          3396
        </td>
        <td>
          15348
          -
          15361
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedRelation.tableName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rel.tableName
        </td>
      </tr><tr>
        <td>
          348
        </td>
        <td>
          3397
        </td>
        <td>
          15340
          -
          15362
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lookup.apply(rel.tableName).unary_!
        </td>
      </tr><tr>
        <td>
          349
        </td>
        <td>
          3399
        </td>
        <td>
          15374
          -
          15390
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Function1.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.apply(rel.tableName)
        </td>
      </tr><tr>
        <td>
          349
        </td>
        <td>
          3398
        </td>
        <td>
          15376
          -
          15389
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedRelation.tableName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rel.tableName
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          3403
        </td>
        <td>
          15402
          -
          15402
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[Seq[T]]
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          3404
        </td>
        <td>
          15231
          -
          15415
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.TraversableOnce.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expression.collect[Seq[T]](({
  @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.expressions.Expression,Seq[T]] with Serializable {
    def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.expressions.Expression =&gt; Seq[T]&gt; = {
      $anonfun.super.&lt;init&gt;();
      ()
    };
    final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.expressions.Expression, B1 &gt;: Seq[T]](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.expressions.Expression]: org.apache.spark.sql.catalyst.expressions.Expression): org.apache.spark.sql.catalyst.expressions.Expression @unchecked) match {
      case (s @ (_: org.apache.spark.sql.catalyst.expressions.SubqueryExpression)) =&gt; s.plan.collect[T](({
        @SerialVersionUID(value = 0) final &lt;synthetic&gt; class $anonfun extends scala.runtime.AbstractPartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T] with Serializable {
          def &lt;init&gt;(): &lt;$anon: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =&gt; T&gt; = {
            $anonfun.super.&lt;init&gt;();
            ()
          };
          final override def applyOrElse[A1 &lt;: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, B1 &gt;: T](x1: A1, default: A1 =&gt; B1): B1 = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
            case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; f.apply(rel.tableName)
            case (defaultCase$ @ _) =&gt; default.apply(x1)
          };
          final def isDefinedAt(x1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan): org.apache.spark.sql.catalyst.plans.logical.LogicalPlan @unchecked) match {
            case (rel @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedRelation)) if lookup.apply(rel.tableName).unary_! =&gt; true
            case (defaultCase$ @ _) =&gt; false
          }
        };
        new $anonfun()
      }: PartialFunction[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,T]))
      case (defaultCase$ @ _) =&gt; default.apply(x1)
    };
    final def isDefinedAt(x1: org.apache.spark.sql.catalyst.expressions.Expression): Boolean = ((x1.asInstanceOf[org.apache.spark.sql.catalyst.expressions.Expression]: org.apache.spark.sql.catalyst.expressions.Expression): org.apache.spark.sql.catalyst.expressions.Expression @unchecked) match {
      case (s @ (_: org.apache.spark.sql.catalyst.expressions.SubqueryExpression)) =&gt; true
      case (defaultCase$ @ _) =&gt; false
    }
  };
  new $anonfun()
}: PartialFunction[org.apache.spark.sql.catalyst.expressions.Expression,Seq[T]])).flatten[T](scala.Predef.$conforms[Seq[T]]).toSet[T]
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          3436
        </td>
        <td>
          15656
          -
          16499
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val expr: org.apache.spark.sql.catalyst.expressions.Expression = exprThunk;
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$18: (com.sparkutils.quality.impl.ExpressionLookup, com.sparkutils.quality.impl.VariablesLookup.Identifiers, com.sparkutils.quality.impl.VariablesLookup.Identifiers) = (VariablesLookup.fieldsFromExpression(expr, lambdaLookups): com.sparkutils.quality.impl.ExpressionLookup @unchecked) match {
    case (exl @ (attributesUsed: com.sparkutils.quality.impl.VariablesLookup.Identifiers, unknownSparkFunctions: com.sparkutils.quality.impl.VariablesLookup.Identifiers, lambdas: Set[com.sparkutils.quality.Id], sparkFunctions: Set[String])com.sparkutils.quality.impl.ExpressionLookup((exprFields @ _), (unknownSparkFunctions @ _), _, _)) =&gt; scala.Tuple3.apply[com.sparkutils.quality.impl.ExpressionLookup, com.sparkutils.quality.impl.VariablesLookup.Identifiers, com.sparkutils.quality.impl.VariablesLookup.Identifiers](exl, exprFields, unknownSparkFunctions)
  };
  val exl: com.sparkutils.quality.impl.ExpressionLookup = x$18._1;
  val exprFields: com.sparkutils.quality.impl.VariablesLookup.Identifiers = x$18._2;
  val unknownSparkFunctions: com.sparkutils.quality.impl.VariablesLookup.Identifiers = x$18._3;
  val rules: scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError] = exprFields.flatMap[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((field: com.sparkutils.quality.impl.VariablesLookup.Identifier) =&gt; if (names.contains(field))
  scala.this.Option.option2Iterable[Nothing](scala.None)
else
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
    RuleNameError.apply(field, id)
  else
    OutputRuleNameError.apply(field, id)))))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]).toSet[com.sparkutils.quality.impl.RuleError];
  val viewErrors: Set[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable] = Validation.this.subQueryErrors[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable](viewLookup, exprThunk, if (outputRule)
    ((x$19: String) =&gt; OutputRuleViewError.apply(x$19, id))
  else
    ((x$20: String) =&gt; RuleViewError.apply(x$20, id)));
  val unknown: scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable] = unknownSparkFunctions.map[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((name: com.sparkutils.quality.impl.VariablesLookup.Identifier) =&gt; if (outputRule.unary_!)
    SparkFunctionNameError.apply(name, id)
  else
    OuputSparkFunctionNameError.apply(name, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]);
  scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup](rules.++(unknown).++(viewErrors), exl)
}
        </td>
      </tr><tr>
        <td>
          356
        </td>
        <td>
          3405
        </td>
        <td>
          15687
          -
          15687
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._1
        </td>
      </tr><tr>
        <td>
          356
        </td>
        <td>
          3407
        </td>
        <td>
          15722
          -
          15722
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._3
        </td>
      </tr><tr>
        <td>
          356
        </td>
        <td>
          3406
        </td>
        <td>
          15710
          -
          15710
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple3._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$18._2
        </td>
      </tr><tr>
        <td>
          357
        </td>
        <td>
          3420
        </td>
        <td>
          15847
          -
          15847
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]
        </td>
      </tr><tr>
        <td>
          359
        </td>
        <td>
          3408
        </td>
        <td>
          15880
          -
          15901
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          names.contains(field)
        </td>
      </tr><tr>
        <td>
          360
        </td>
        <td>
          3411
        </td>
        <td>
          15915
          -
          15919
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          360
        </td>
        <td>
          3410
        </td>
        <td>
          15915
          -
          15919
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          360
        </td>
        <td>
          3409
        </td>
        <td>
          15915
          -
          15919
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          3417
        </td>
        <td>
          15947
          -
          16104
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id))
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          3419
        </td>
        <td>
          15947
          -
          16104
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id)))
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          3418
        </td>
        <td>
          15947
          -
          16104
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
  RuleNameError.apply(field, id)
else
  OutputRuleNameError.apply(field, id)))
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          3412
        </td>
        <td>
          15971
          -
          15982
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          364
        </td>
        <td>
          3414
        </td>
        <td>
          16000
          -
          16024
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          364
        </td>
        <td>
          3413
        </td>
        <td>
          16000
          -
          16024
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          366
        </td>
        <td>
          3416
        </td>
        <td>
          16060
          -
          16090
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          366
        </td>
        <td>
          3415
        </td>
        <td>
          16060
          -
          16090
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleNameError.apply(field, id)
        </td>
      </tr><tr>
        <td>
          368
        </td>
        <td>
          3421
        </td>
        <td>
          15829
          -
          16129
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.toSet
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          exprFields.flatMap[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((field: com.sparkutils.quality.impl.VariablesLookup.Identifier) =&gt; if (names.contains(field))
  scala.this.Option.option2Iterable[Nothing](scala.None)
else
  scala.this.Option.option2Iterable[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](scala.Some.apply[com.sparkutils.quality.impl.NameMissingError with Product with Serializable](if (outputRule.unary_!)
    RuleNameError.apply(field, id)
  else
    OutputRuleNameError.apply(field, id)))))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]).toSet[com.sparkutils.quality.impl.RuleError]
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          3423
        </td>
        <td>
          16208
          -
          16234
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((x$19: String) =&gt; OutputRuleViewError.apply(x$19, id))
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          3426
        </td>
        <td>
          16154
          -
          16261
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.subQueryErrors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          Validation.this.subQueryErrors[com.sparkutils.quality.impl.ViewMissingError with Product with Serializable](viewLookup, exprThunk, if (outputRule)
  ((x$19: String) =&gt; OutputRuleViewError.apply(x$19, id))
else
  ((x$20: String) =&gt; RuleViewError.apply(x$20, id)))
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          3425
        </td>
        <td>
          16240
          -
          16260
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.quality.impl.Validation.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((x$20: String) =&gt; RuleViewError.apply(x$20, id))
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          3422
        </td>
        <td>
          16208
          -
          16234
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleViewError.apply(x$19, id)
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          3424
        </td>
        <td>
          16240
          -
          16260
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleViewError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleViewError.apply(x$20, id)
        </td>
      </tr><tr>
        <td>
          372
        </td>
        <td>
          3432
        </td>
        <td>
          16308
          -
          16308
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Set.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]
        </td>
      </tr><tr>
        <td>
          372
        </td>
        <td>
          3433
        </td>
        <td>
          16283
          -
          16454
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SetLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          unknownSparkFunctions.map[com.sparkutils.quality.impl.NameMissingError with Product with Serializable, scala.collection.immutable.Set[com.sparkutils.quality.impl.NameMissingError with Product with Serializable]](((name: com.sparkutils.quality.impl.VariablesLookup.Identifier) =&gt; if (outputRule.unary_!)
  SparkFunctionNameError.apply(name, id)
else
  OuputSparkFunctionNameError.apply(name, id)))(immutable.this.Set.canBuildFrom[com.sparkutils.quality.impl.NameMissingError with Product with Serializable])
        </td>
      </tr><tr>
        <td>
          373
        </td>
        <td>
          3427
        </td>
        <td>
          16330
          -
          16341
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          374
        </td>
        <td>
          3429
        </td>
        <td>
          16353
          -
          16385
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.SparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          SparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          374
        </td>
        <td>
          3428
        </td>
        <td>
          16353
          -
          16385
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.SparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          SparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          376
        </td>
        <td>
          3430
        </td>
        <td>
          16409
          -
          16446
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OuputSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OuputSparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          376
        </td>
        <td>
          3431
        </td>
        <td>
          16409
          -
          16446
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OuputSparkFunctionNameError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OuputSparkFunctionNameError.apply(name, id)
        </td>
      </tr><tr>
        <td>
          379
        </td>
        <td>
          3435
        </td>
        <td>
          16462
          -
          16499
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup](rules.++(unknown).++(viewErrors), exl)
        </td>
      </tr><tr>
        <td>
          379
        </td>
        <td>
          3434
        </td>
        <td>
          16463
          -
          16493
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SetLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          rules.++(unknown).++(viewErrors)
        </td>
      </tr><tr>
        <td>
          381
        </td>
        <td>
          3450
        </td>
        <td>
          16541
          -
          16707
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[scala.collection.immutable.Set[com.sparkutils.quality.impl.RuleError], com.sparkutils.quality.impl.ExpressionLookup](scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleError](if (outputRule.unary_!)
  RuleSyntaxError.apply(id, e.getMessage())
else
  OutputRuleSyntaxError.apply(id, e.getMessage())), ExpressionLookup.apply(ExpressionLookup.apply$default$1, ExpressionLookup.apply$default$2, ExpressionLookup.apply$default$3, ExpressionLookup.apply$default$4))
        </td>
      </tr><tr>
        <td>
          381
        </td>
        <td>
          3444
        </td>
        <td>
          16542
          -
          16686
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Set.apply[com.sparkutils.quality.impl.RuleError](if (outputRule.unary_!)
  RuleSyntaxError.apply(id, e.getMessage())
else
  OutputRuleSyntaxError.apply(id, e.getMessage()))
        </td>
      </tr><tr>
        <td>
          382
        </td>
        <td>
          3437
        </td>
        <td>
          16559
          -
          16570
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          outputRule.unary_!
        </td>
      </tr><tr>
        <td>
          383
        </td>
        <td>
          3439
        </td>
        <td>
          16582
          -
          16615
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          383
        </td>
        <td>
          3438
        </td>
        <td>
          16602
          -
          16614
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Throwable.getMessage
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.getMessage()
        </td>
      </tr><tr>
        <td>
          383
        </td>
        <td>
          3440
        </td>
        <td>
          16582
          -
          16615
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          385
        </td>
        <td>
          3441
        </td>
        <td>
          16665
          -
          16677
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Throwable.getMessage
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.getMessage()
        </td>
      </tr><tr>
        <td>
          385
        </td>
        <td>
          3443
        </td>
        <td>
          16639
          -
          16678
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          385
        </td>
        <td>
          3442
        </td>
        <td>
          16639
          -
          16678
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.OutputRuleSyntaxError.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputRuleSyntaxError.apply(id, e.getMessage())
        </td>
      </tr><tr>
        <td>
          386
        </td>
        <td>
          3447
        </td>
        <td>
          16688
          -
          16688
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ExpressionLookup.apply$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExpressionLookup.apply$default$3
        </td>
      </tr><tr>
        <td>
          386
        </td>
        <td>
          3446
        </td>
        <td>
          16688
          -
          16688
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ExpressionLookup.apply$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExpressionLookup.apply$default$2
        </td>
      </tr><tr>
        <td>
          386
        </td>
        <td>
          3449
        </td>
        <td>
          16688
          -
          16706
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.ExpressionLookup.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExpressionLookup.apply(ExpressionLookup.apply$default$1, ExpressionLookup.apply$default$2, ExpressionLookup.apply$default$3, ExpressionLookup.apply$default$4)
        </td>
      </tr><tr>
        <td>
          386
        </td>
        <td>
          3448
        </td>
        <td>
          16688
          -
          16688
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ExpressionLookup.apply$default$4
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExpressionLookup.apply$default$4
        </td>
      </tr><tr>
        <td>
          386
        </td>
        <td>
          3445
        </td>
        <td>
          16688
          -
          16688
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ExpressionLookup.apply$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExpressionLookup.apply$default$1
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>