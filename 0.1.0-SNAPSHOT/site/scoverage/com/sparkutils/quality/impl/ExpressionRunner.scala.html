<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/impl/ExpressionRunner.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality.impl
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality.impl.ExpressionRunner.expressionsResultToRow
</span>4 <span style=''>import com.sparkutils.quality.impl.RuleRunnerUtils.{flattenExpressions, reincorporateExpressions}
</span>5 <span style=''>import com.sparkutils.quality.{GeneralExpressionResult, GeneralExpressionsResult, RuleSuite, VersionedId, expressionsResultsType, packId}
</span>6 <span style=''>import org.apache.spark.sql.{Column, DataFrame}
</span>7 <span style=''>import org.apache.spark.sql.QualitySparkUtils.cast
</span>8 <span style=''>import org.apache.spark.sql.catalyst.InternalRow
</span>9 <span style=''>import org.apache.spark.sql.catalyst.expressions.{Cast, Expression, NonSQLExpression, UnaryExpression}
</span>10 <span style=''>import org.apache.spark.sql.catalyst.expressions.codegen.{CodegenContext, CodegenFallback, ExprCode}
</span>11 <span style=''>import org.apache.spark.sql.catalyst.util.ArrayBasedMapData
</span>12 <span style=''>import org.apache.spark.sql.functions.col
</span>13 <span style=''>import org.apache.spark.sql.types.{DataType, StringType}
</span>14 <span style=''>import org.apache.spark.unsafe.types.UTF8String
</span>15 <span style=''>
</span>16 <span style=''>object ExpressionRunner {
</span>17 <span style=''>  def run(ruleSuite: RuleSuite, dataFrame: DataFrame, name: String = &quot;expressionResults&quot;): DataFrame = {
</span>18 <span style=''>    </span><span style='background: #AEF1AE'>com.sparkutils.quality.registerLambdaFunctions( ruleSuite.lambdaFunctions )</span><span style=''>
</span>19 <span style=''>    val expressions = </span><span style='background: #AEF1AE'>flattenExpressions(ruleSuite)</span><span style=''>
</span>20 <span style=''>    val res = </span><span style='background: #AEF1AE'>dataFrame.select(expressions.zipWithIndex.map( p =&gt; new Column(p._1).as(s&quot;f_${p._2}&quot;)) :_*)</span><span style=''>
</span>21 <span style=''>    // cast all the results to string
</span>22 <span style=''>    val collectExpressions = </span><span style='background: #AEF1AE'>expressions.indices.map( i =&gt; cast(col(s&quot;f_$i&quot;).expr, StringType))</span><span style=''>
</span>23 <span style=''>    </span><span style='background: #AEF1AE'>res.select(new Column(ExpressionRunner(ruleSuite, collectExpressions)).as(name))</span><span style=''>
</span>24 <span style=''>  }
</span>25 <span style=''>
</span>26 <span style=''>  def expressionsResultToRow(ruleSuiteResult: GeneralExpressionsResult): InternalRow =
</span>27 <span style=''>    </span><span style='background: #AEF1AE'>InternalRow(
</span>28 <span style=''></span><span style='background: #AEF1AE'>      packId(ruleSuiteResult.id),
</span>29 <span style=''></span><span style='background: #AEF1AE'>      ArrayBasedMapData(
</span>30 <span style=''></span><span style='background: #AEF1AE'>        ruleSuiteResult.ruleSetResults, packId, (a: Any) =&gt; {
</span>31 <span style=''></span><span style='background: #AEF1AE'>          val v = a.asInstanceOf[Map[VersionedId, GeneralExpressionResult]]
</span>32 <span style=''></span><span style='background: #AEF1AE'>          ArrayBasedMapData(
</span>33 <span style=''></span><span style='background: #AEF1AE'>            v, packId, (a: Any) =&gt; {
</span>34 <span style=''></span><span style='background: #AEF1AE'>              val r = a.asInstanceOf[GeneralExpressionResult]
</span>35 <span style=''></span><span style='background: #AEF1AE'>              InternalRow(UTF8String.fromString( r.ruleResult ), UTF8String.fromString( r.resultType) )
</span>36 <span style=''></span><span style='background: #AEF1AE'>            }
</span>37 <span style=''></span><span style='background: #AEF1AE'>          )
</span>38 <span style=''></span><span style='background: #AEF1AE'>        }
</span>39 <span style=''></span><span style='background: #AEF1AE'>      )
</span>40 <span style=''></span><span style='background: #AEF1AE'>    )</span><span style=''>
</span>41 <span style=''>}
</span>42 <span style=''>
</span>43 <span style=''>/**
</span>44 <span style=''> * Creates an extensible wrapper result column for aggregate expressions, adding casts as needed to string
</span>45 <span style=''> *
</span>46 <span style=''> * @param ruleSuite
</span>47 <span style=''> * @param children
</span>48 <span style=''> */
</span>49 <span style=''>case class ExpressionRunner(ruleSuite: RuleSuite, children: Seq[Expression])
</span>50 <span style=''>  extends Expression with CodegenFallback with NonSQLExpression {
</span>51 <span style=''>  override def nullable: Boolean = </span><span style='background: #AEF1AE'>false</span><span style=''>
</span>52 <span style=''>
</span>53 <span style=''>  // used only for eval, compiled uses the children directly
</span>54 <span style=''>  lazy val reincorporated = reincorporateExpressions(ruleSuite, children, false)
</span>55 <span style=''>
</span>56 <span style=''>  // keep it simple for this one. - can return an internal row or whatever..
</span>57 <span style=''>  override def eval(input: InternalRow): Any = {
</span>58 <span style=''>    val res = </span><span style='background: #AEF1AE'>reincorporated.evalAggregates(input)</span><span style=''>
</span>59 <span style=''>    </span><span style='background: #AEF1AE'>expressionsResultToRow(res)</span><span style=''>
</span>60 <span style=''>  }
</span>61 <span style=''>
</span>62 <span style=''>  // not really worth it in this case.
</span>63 <span style=''>  // override protected def doGenCode(ctx: CodegenContext, ev: ExprCode): ExprCode = ???
</span>64 <span style=''>
</span>65 <span style=''>  override def dataType: DataType = </span><span style='background: #AEF1AE'>expressionsResultsType</span><span style=''>
</span>66 <span style=''>
</span>67 <span style=''>  protected def withNewChildrenInternal(newChildren: IndexedSeq[Expression]): Expression =
</span>68 <span style=''>    </span><span style='background: #AEF1AE'>copy(children = newChildren)</span><span style=''>
</span>69 <span style=''>
</span>70 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          18
        </td>
        <td>
          752
        </td>
        <td>
          1043
          -
          1118
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.LambdaFunctionsImports.registerLambdaFunctions
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.registerLambdaFunctions(ruleSuite.lambdaFunctions)
        </td>
      </tr><tr>
        <td>
          18
        </td>
        <td>
          751
        </td>
        <td>
          1091
          -
          1116
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.RuleSuite.lambdaFunctions
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuite.lambdaFunctions
        </td>
      </tr><tr>
        <td>
          19
        </td>
        <td>
          753
        </td>
        <td>
          1141
          -
          1170
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleRunnerUtils.flattenExpressions
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.RuleRunnerUtils.flattenExpressions(ruleSuite)
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          756
        </td>
        <td>
          1259
          -
          1262
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;f_&quot;
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          759
        </td>
        <td>
          1257
          -
          1269
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;f_&quot;, &quot;&quot;).s(p._2)
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          762
        </td>
        <td>
          1202
          -
          1271
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expressions.zipWithIndex[org.apache.spark.sql.catalyst.expressions.Expression, Seq[(org.apache.spark.sql.catalyst.expressions.Expression, Int)]](collection.this.Seq.canBuildFrom[(org.apache.spark.sql.catalyst.expressions.Expression, Int)]).map[org.apache.spark.sql.Column, Seq[org.apache.spark.sql.Column]](((p: (org.apache.spark.sql.catalyst.expressions.Expression, Int)) =&gt; new org.apache.spark.sql.Column(p._1).as(scala.StringContext.apply(&quot;f_&quot;, &quot;&quot;).s(p._2))))(collection.this.Seq.canBuildFrom[org.apache.spark.sql.Column])
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          761
        </td>
        <td>
          1230
          -
          1230
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[org.apache.spark.sql.Column]
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          755
        </td>
        <td>
          1248
          -
          1252
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._1
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          758
        </td>
        <td>
          1263
          -
          1267
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p._2
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          757
        </td>
        <td>
          1268
          -
          1269
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          760
        </td>
        <td>
          1237
          -
          1270
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.sql.Column(p._1).as(scala.StringContext.apply(&quot;f_&quot;, &quot;&quot;).s(p._2))
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          763
        </td>
        <td>
          1185
          -
          1276
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.select
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          dataFrame.select((expressions.zipWithIndex[org.apache.spark.sql.catalyst.expressions.Expression, Seq[(org.apache.spark.sql.catalyst.expressions.Expression, Int)]](collection.this.Seq.canBuildFrom[(org.apache.spark.sql.catalyst.expressions.Expression, Int)]).map[org.apache.spark.sql.Column, Seq[org.apache.spark.sql.Column]](((p: (org.apache.spark.sql.catalyst.expressions.Expression, Int)) =&gt; new org.apache.spark.sql.Column(p._1).as(scala.StringContext.apply(&quot;f_&quot;, &quot;&quot;).s(p._2))))(collection.this.Seq.canBuildFrom[org.apache.spark.sql.Column]): _*))
        </td>
      </tr><tr>
        <td>
          20
        </td>
        <td>
          754
        </td>
        <td>
          1214
          -
          1214
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[(org.apache.spark.sql.catalyst.expressions.Expression, Int)]
        </td>
      </tr><tr>
        <td>
          22
        </td>
        <td>
          765
        </td>
        <td>
          1379
          -
          1396
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.Column.expr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.col(scala.StringContext.apply(&quot;f_&quot;, &quot;&quot;).s(i)).expr
        </td>
      </tr><tr>
        <td>
          22
        </td>
        <td>
          768
        </td>
        <td>
          1367
          -
          1367
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.IndexedSeq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.IndexedSeq.canBuildFrom[org.apache.spark.sql.catalyst.expressions.Expression]
        </td>
      </tr><tr>
        <td>
          22
        </td>
        <td>
          764
        </td>
        <td>
          1383
          -
          1390
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;f_&quot;, &quot;&quot;).s(i)
        </td>
      </tr><tr>
        <td>
          22
        </td>
        <td>
          767
        </td>
        <td>
          1374
          -
          1409
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.QualitySparkUtils.cast
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.QualitySparkUtils.cast(org.apache.spark.sql.functions.col(scala.StringContext.apply(&quot;f_&quot;, &quot;&quot;).s(i)).expr, org.apache.spark.sql.types.StringType)
        </td>
      </tr><tr>
        <td>
          22
        </td>
        <td>
          766
        </td>
        <td>
          1398
          -
          1408
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StringType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.StringType
        </td>
      </tr><tr>
        <td>
          22
        </td>
        <td>
          769
        </td>
        <td>
          1344
          -
          1410
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expressions.indices.map[org.apache.spark.sql.catalyst.expressions.Expression, scala.collection.immutable.IndexedSeq[org.apache.spark.sql.catalyst.expressions.Expression]](((i: Int) =&gt; org.apache.spark.sql.QualitySparkUtils.cast(org.apache.spark.sql.functions.col(scala.StringContext.apply(&quot;f_&quot;, &quot;&quot;).s(i)).expr, org.apache.spark.sql.types.StringType)))(immutable.this.IndexedSeq.canBuildFrom[org.apache.spark.sql.catalyst.expressions.Expression])
        </td>
      </tr><tr>
        <td>
          23
        </td>
        <td>
          771
        </td>
        <td>
          1415
          -
          1495
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.select
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          res.select(new org.apache.spark.sql.Column(ExpressionRunner.apply(ruleSuite, collectExpressions)).as(name))
        </td>
      </tr><tr>
        <td>
          23
        </td>
        <td>
          770
        </td>
        <td>
          1426
          -
          1494
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.sql.Column(ExpressionRunner.apply(ruleSuite, collectExpressions)).as(name)
        </td>
      </tr><tr>
        <td>
          27
        </td>
        <td>
          786
        </td>
        <td>
          1592
          -
          2083
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.InternalRow.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.InternalRow.apply(com.sparkutils.quality.`package`.packId.apply(ruleSuiteResult.id), org.apache.spark.sql.catalyst.util.ArrayBasedMapData.apply(ruleSuiteResult.ruleSetResults, com.sparkutils.quality.`package`.packId, ((a: Any) =&gt; {
  val v: Map[com.sparkutils.quality.VersionedId,com.sparkutils.quality.GeneralExpressionResult] = a.asInstanceOf[Map[com.sparkutils.quality.VersionedId,com.sparkutils.quality.GeneralExpressionResult]];
  org.apache.spark.sql.catalyst.util.ArrayBasedMapData.apply(v, com.sparkutils.quality.`package`.packId, ((a: Any) =&gt; {
    val r: com.sparkutils.quality.GeneralExpressionResult = a.asInstanceOf[com.sparkutils.quality.GeneralExpressionResult];
    org.apache.spark.sql.catalyst.InternalRow.apply(org.apache.spark.unsafe.types.UTF8String.fromString(r.ruleResult), org.apache.spark.unsafe.types.UTF8String.fromString(r.resultType))
  }))
})))
        </td>
      </tr><tr>
        <td>
          28
        </td>
        <td>
          773
        </td>
        <td>
          1611
          -
          1637
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Function1.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.packId.apply(ruleSuiteResult.id)
        </td>
      </tr><tr>
        <td>
          28
        </td>
        <td>
          772
        </td>
        <td>
          1618
          -
          1636
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.GeneralExpressionsResult.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuiteResult.id
        </td>
      </tr><tr>
        <td>
          29
        </td>
        <td>
          785
        </td>
        <td>
          1645
          -
          2077
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.util.ArrayBasedMapData.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.util.ArrayBasedMapData.apply(ruleSuiteResult.ruleSetResults, com.sparkutils.quality.`package`.packId, ((a: Any) =&gt; {
  val v: Map[com.sparkutils.quality.VersionedId,com.sparkutils.quality.GeneralExpressionResult] = a.asInstanceOf[Map[com.sparkutils.quality.VersionedId,com.sparkutils.quality.GeneralExpressionResult]];
  org.apache.spark.sql.catalyst.util.ArrayBasedMapData.apply(v, com.sparkutils.quality.`package`.packId, ((a: Any) =&gt; {
    val r: com.sparkutils.quality.GeneralExpressionResult = a.asInstanceOf[com.sparkutils.quality.GeneralExpressionResult];
    org.apache.spark.sql.catalyst.InternalRow.apply(org.apache.spark.unsafe.types.UTF8String.fromString(r.ruleResult), org.apache.spark.unsafe.types.UTF8String.fromString(r.resultType))
  }))
}))
        </td>
      </tr><tr>
        <td>
          30
        </td>
        <td>
          774
        </td>
        <td>
          1672
          -
          1702
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.GeneralExpressionsResult.ruleSetResults
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ruleSuiteResult.ruleSetResults
        </td>
      </tr><tr>
        <td>
          30
        </td>
        <td>
          775
        </td>
        <td>
          1704
          -
          1710
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleRunnerImports.packId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.packId
        </td>
      </tr><tr>
        <td>
          31
        </td>
        <td>
          776
        </td>
        <td>
          1744
          -
          1801
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          a.asInstanceOf[Map[com.sparkutils.quality.VersionedId,com.sparkutils.quality.GeneralExpressionResult]]
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          784
        </td>
        <td>
          1812
          -
          2059
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.util.ArrayBasedMapData.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.util.ArrayBasedMapData.apply(v, com.sparkutils.quality.`package`.packId, ((a: Any) =&gt; {
  val r: com.sparkutils.quality.GeneralExpressionResult = a.asInstanceOf[com.sparkutils.quality.GeneralExpressionResult];
  org.apache.spark.sql.catalyst.InternalRow.apply(org.apache.spark.unsafe.types.UTF8String.fromString(r.ruleResult), org.apache.spark.unsafe.types.UTF8String.fromString(r.resultType))
}))
        </td>
      </tr><tr>
        <td>
          33
        </td>
        <td>
          777
        </td>
        <td>
          1846
          -
          1852
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleRunnerImports.packId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.packId
        </td>
      </tr><tr>
        <td>
          34
        </td>
        <td>
          778
        </td>
        <td>
          1890
          -
          1929
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          a.asInstanceOf[com.sparkutils.quality.GeneralExpressionResult]
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          783
        </td>
        <td>
          1944
          -
          2033
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.InternalRow.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.InternalRow.apply(org.apache.spark.unsafe.types.UTF8String.fromString(r.ruleResult), org.apache.spark.unsafe.types.UTF8String.fromString(r.resultType))
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          779
        </td>
        <td>
          1979
          -
          1991
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.GeneralExpressionResult.ruleResult
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.ruleResult
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          782
        </td>
        <td>
          1995
          -
          2031
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.unsafe.types.UTF8String.fromString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.unsafe.types.UTF8String.fromString(r.resultType)
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          781
        </td>
        <td>
          2018
          -
          2030
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.GeneralExpressionResult.resultType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          r.resultType
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          780
        </td>
        <td>
          1956
          -
          1993
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.unsafe.types.UTF8String.fromString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.unsafe.types.UTF8String.fromString(r.ruleResult)
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          787
        </td>
        <td>
          2422
          -
          2427
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          false
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          788
        </td>
        <td>
          2712
          -
          2748
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.RuleSuite.evalAggregates
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExpressionRunner.this.reincorporated.evalAggregates(input)
        </td>
      </tr><tr>
        <td>
          59
        </td>
        <td>
          789
        </td>
        <td>
          2753
          -
          2780
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.ExpressionRunner.expressionsResultToRow
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.ExpressionRunner.expressionsResultToRow(res)
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          790
        </td>
        <td>
          2951
          -
          2973
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.RuleSparkTypes.expressionsResultsType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.`package`.expressionsResultsType
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          792
        </td>
        <td>
          3070
          -
          3098
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.ExpressionRunner.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExpressionRunner.this.copy(x$2, x$1)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          791
        </td>
        <td>
          3070
          -
          3070
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.impl.ExpressionRunner.copy$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExpressionRunner.this.copy$default$1
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>