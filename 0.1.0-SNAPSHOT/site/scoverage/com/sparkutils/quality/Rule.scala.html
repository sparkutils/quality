<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/quality/Rule.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.quality
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.quality.impl._
</span>4 <span style=''>import org.apache.spark.internal.Logging
</span>5 <span style=''>import org.apache.spark.sql.QualitySparkUtils
</span>6 <span style=''>import org.apache.spark.sql.catalyst.analysis.{UnresolvedAttribute, UnresolvedFunction}
</span>7 <span style=''>import org.apache.spark.sql.catalyst.expressions.{EqualTo, Literal}
</span>8 <span style=''>
</span>9 <span style=''>/**
</span>10 <span style=''>  * A versioned rule ID - note the name is never persisted in results, the id and version are sufficient to retrieve the name
</span>11 <span style=''>  * @param id a unique ID to identify this rule
</span>12 <span style=''>  * @param version the version of the rule - again tied to ID
</span>13 <span style=''>  */
</span>14 <span style=''>case class Id(id: Int, version: Int) extends VersionedId
</span>15 <span style=''>
</span>16 <span style=''>object LambdaFunction {
</span>17 <span style=''>  def apply(name: String, rule: String, id: Id): LambdaFunction = </span><span style='background: #AEF1AE'>LambdaFunctionImpl(name, rule, id)</span><span style=''>
</span>18 <span style=''>}
</span>19 <span style=''>
</span>20 <span style=''>/**
</span>21 <span style=''> * The result of serializing or loading rules
</span>22 <span style=''> * @param rule
</span>23 <span style=''> */
</span>24 <span style=''>case class ExpressionRule( rule: String ) extends ExprLogic with HasRuleText {
</span>25 <span style=''>  override def reset(): Unit = </span><span style='background: #AEF1AE'>super[HasRuleText].reset()</span><span style=''>
</span>26 <span style=''>}
</span>27 <span style=''>
</span>28 <span style=''>/**
</span>29 <span style=''> * Used as a result of serializing
</span>30 <span style=''> * @param rule
</span>31 <span style=''> */
</span>32 <span style=''>case class OutputExpression( rule: String ) extends OutputExprLogic with HasRuleText with Logging {
</span>33 <span style=''>  private[quality] override def expression() = {
</span>34 <span style=''>    val parsed = </span><span style='background: #AEF1AE'>RuleLogicUtils.expr(rule)</span><span style=''>
</span>35 <span style=''>    // output expressions can be:
</span>36 <span style=''>    // 1. simple expressions for ruleEngine
</span>37 <span style=''>    // 2. single argument lambda's returning the same type as the arg for folder
</span>38 <span style=''>    // 3. as of 0.0.2 #8 set( attribute = valueExpression, attribute = valueExpression) converted to the form of 2 with an updateField call
</span>39 <span style=''>    parsed match {
</span>40 <span style=''>      case uf: UnresolvedFunction if </span><span style='background: #AEF1AE'>VariablesLookup.toName(uf) == &quot;set&quot;</span><span style=''> =&gt;
</span>41 <span style=''>        // case 3
</span>42 <span style=''>        val args = </span><span style='background: #AEF1AE'>QualitySparkUtils.arguments(uf)</span><span style=''>
</span>43 <span style=''>        val paired =
</span>44 <span style=''>          </span><span style='background: #AEF1AE'>args.flatMap {
</span>45 <span style=''></span><span style='background: #AEF1AE'>            case EqualTo(name: UnresolvedAttribute, right) =&gt;
</span>46 <span style=''></span><span style='background: #AEF1AE'>              // updateField takes paired args of field names to expression
</span>47 <span style=''></span><span style='background: #AEF1AE'>              Some(Seq(Literal(name.name), right))
</span>48 <span style=''></span><span style='background: #AEF1AE'>            case a =&gt;
</span>49 <span style=''></span><span style='background: #AEF1AE'>              logInfo(s&quot;Attempt to convert set OutputExpression argument $a failed as types do not match expected EqualTo(attribute, expression), will default to full expression&quot;)
</span>50 <span style=''></span><span style='background: #AEF1AE'>              None
</span>51 <span style=''></span><span style='background: #AEF1AE'>          }</span><span style=''>
</span>52 <span style=''>
</span>53 <span style=''>        if (</span><span style='background: #AEF1AE'>paired.size != args.size</span><span style=''>)
</span>54 <span style=''>          // one of the args didn't match type
</span>55 <span style=''>          </span><span style='background: #AEF1AE'>parsed</span><span style=''>
</span>56 <span style=''>        else
</span>57 <span style=''>          // need to keep first arg
</span>58 <span style=''>          </span><span style='background: #AEF1AE'>UpdateFolderExpression.withArgsAndSubstitutedLambdaVariable(paired.flatten)</span><span style=''>
</span>59 <span style=''>      case _ =&gt;
</span>60 <span style=''>        // for everything else (1+2) it's already good enough
</span>61 <span style=''>        parsed
</span>62 <span style=''>    }
</span>63 <span style=''>  }
</span>64 <span style=''>
</span>65 <span style=''>  override def reset(): Unit = </span><span style='background: #AEF1AE'>super[HasRuleText].reset()</span><span style=''>
</span>66 <span style=''>}
</span>67 <span style=''>
</span>68 <span style=''>object RunOnPassProcessor {
</span>69 <span style=''>  /**
</span>70 <span style=''>   * Creates a RunOnPassProcesser using a given OutputExpression
</span>71 <span style=''>   *
</span>72 <span style=''>   * @param salience
</span>73 <span style=''>   * @param id
</span>74 <span style=''>   * @param e
</span>75 <span style=''>   * @return
</span>76 <span style=''>   */
</span>77 <span style=''>  def apply(salience: Int, id: Id, e: OutputExpression) =
</span>78 <span style=''>    </span><span style='background: #AEF1AE'>RunOnPassProcessorImpl(salience, id, e.rule, e)</span><span style=''>
</span>79 <span style=''>
</span>80 <span style=''>}
</span>81 <span style=''>
</span>82 <span style=''>/**
</span>83 <span style=''>  * A rule to run over a row
</span>84 <span style=''>  * @param id
</span>85 <span style=''>  * @param expression
</span>86 <span style=''>  */
</span>87 <span style=''>case class Rule(id: Id, expression: RuleLogic, runOnPassProcessor: RunOnPassProcessor = NoOpRunOnPassProcessor.noOp) extends Serializable
</span>88 <span style=''>
</span>89 <span style=''>case class RuleSet(id: Id, rules: Seq[Rule]) extends Serializable
</span>90 <span style=''>
</span>91 <span style=''>/**
</span>92 <span style=''> * Represents a versioned collection of RuleSet's
</span>93 <span style=''> * @param id
</span>94 <span style=''> * @param ruleSets
</span>95 <span style=''> * @param lambdaFunctions
</span>96 <span style=''> * @param probablePass override to specify a different percentage for treating probability results as passes - defaults to 80% (0.8)
</span>97 <span style=''> */
</span>98 <span style=''>case class RuleSuite(id: Id, ruleSets: Seq[RuleSet], lambdaFunctions: Seq[LambdaFunction] = Seq.empty, probablePass: Double = 0.8) extends Serializable {
</span>99 <span style=''>
</span>100 <span style=''>  /**
</span>101 <span style=''>   * Use a different probable pass value for this RuleSuite
</span>102 <span style=''>   * @param probablePass
</span>103 <span style=''>   * @return
</span>104 <span style=''>   */
</span>105 <span style=''>  def withProbablePass(probablePass: Double) = </span><span style='background: #AEF1AE'>copy(probablePass = probablePass)</span><span style=''>
</span>106 <span style=''>
</span>107 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          17
        </td>
        <td>
          319
        </td>
        <td>
          706
          -
          740
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.LambdaFunctionImpl.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.LambdaFunctionImpl.apply(name, rule, id)
        </td>
      </tr><tr>
        <td>
          25
        </td>
        <td>
          320
        </td>
        <td>
          923
          -
          949
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.HasRuleText.reset
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ExpressionRule.super[HasRuleText].reset()
        </td>
      </tr><tr>
        <td>
          34
        </td>
        <td>
          322
        </td>
        <td>
          1177
          -
          1202
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RuleLogicUtils.expr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.RuleLogicUtils.expr(OutputExpression.this.rule)
        </td>
      </tr><tr>
        <td>
          34
        </td>
        <td>
          321
        </td>
        <td>
          1197
          -
          1201
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.OutputExpression.rule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputExpression.this.rule
        </td>
      </tr><tr>
        <td>
          40
        </td>
        <td>
          323
        </td>
        <td>
          1558
          -
          1593
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.VariablesLookup.toName(uf).==(&quot;set&quot;)
        </td>
      </tr><tr>
        <td>
          42
        </td>
        <td>
          324
        </td>
        <td>
          1634
          -
          1665
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.QualitySparkUtils.arguments
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.QualitySparkUtils.arguments(uf)
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          334
        </td>
        <td>
          1710
          -
          1710
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[Seq[org.apache.spark.sql.catalyst.expressions.Expression]]
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          335
        </td>
        <td>
          1697
          -
          2133
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          args.flatMap[Seq[org.apache.spark.sql.catalyst.expressions.Expression], Seq[Seq[org.apache.spark.sql.catalyst.expressions.Expression]]](((x0$1: org.apache.spark.sql.catalyst.expressions.Expression) =&gt; x0$1 match {
  case (left: org.apache.spark.sql.catalyst.expressions.Expression, right: org.apache.spark.sql.catalyst.expressions.Expression)org.apache.spark.sql.catalyst.expressions.EqualTo((name @ (_: org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute)), (right @ _)) =&gt; scala.this.Option.option2Iterable[Seq[org.apache.spark.sql.catalyst.expressions.Expression]](scala.Some.apply[Seq[org.apache.spark.sql.catalyst.expressions.Expression]](scala.collection.Seq.apply[org.apache.spark.sql.catalyst.expressions.Expression](org.apache.spark.sql.catalyst.expressions.Literal.apply(name.name), right)))
  case (a @ _) =&gt; {
    OutputExpression.this.logInfo(scala.StringContext.apply(&quot;Attempt to convert set OutputExpression argument &quot;, &quot; failed as types do not match expected EqualTo(attribute, expression), will default to full expression&quot;).s(a));
    scala.this.Option.option2Iterable[Nothing](scala.None)
  }
}))(collection.this.Seq.canBuildFrom[Seq[org.apache.spark.sql.catalyst.expressions.Expression]])
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          325
        </td>
        <td>
          1881
          -
          1890
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          name.name
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          328
        </td>
        <td>
          1864
          -
          1900
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[Seq[org.apache.spark.sql.catalyst.expressions.Expression]](scala.collection.Seq.apply[org.apache.spark.sql.catalyst.expressions.Expression](org.apache.spark.sql.catalyst.expressions.Literal.apply(name.name), right))
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          327
        </td>
        <td>
          1869
          -
          1899
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.apply[org.apache.spark.sql.catalyst.expressions.Expression](org.apache.spark.sql.catalyst.expressions.Literal.apply(name.name), right)
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          326
        </td>
        <td>
          1873
          -
          1891
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.Literal.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.expressions.Literal.apply(name.name)
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          329
        </td>
        <td>
          1864
          -
          1900
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Seq[org.apache.spark.sql.catalyst.expressions.Expression]](scala.Some.apply[Seq[org.apache.spark.sql.catalyst.expressions.Expression]](scala.collection.Seq.apply[org.apache.spark.sql.catalyst.expressions.Expression](org.apache.spark.sql.catalyst.expressions.Literal.apply(name.name), right)))
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          331
        </td>
        <td>
          1937
          -
          2102
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.internal.Logging.logInfo
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputExpression.this.logInfo(scala.StringContext.apply(&quot;Attempt to convert set OutputExpression argument &quot;, &quot; failed as types do not match expected EqualTo(attribute, expression), will default to full expression&quot;).s(a))
        </td>
      </tr><tr>
        <td>
          49
        </td>
        <td>
          330
        </td>
        <td>
          1945
          -
          2101
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;Attempt to convert set OutputExpression argument &quot;, &quot; failed as types do not match expected EqualTo(attribute, expression), will default to full expression&quot;).s(a)
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          333
        </td>
        <td>
          2117
          -
          2121
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          332
        </td>
        <td>
          2117
          -
          2121
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          337
        </td>
        <td>
          2147
          -
          2171
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.!=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          paired.size.!=(args.size)
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          336
        </td>
        <td>
          2162
          -
          2171
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SeqLike.size
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          args.size
        </td>
      </tr><tr>
        <td>
          55
        </td>
        <td>
          338
        </td>
        <td>
          2230
          -
          2236
        </td>
        <td>
          Ident
        </td>
        <td>
          com.sparkutils.quality.OutputExpression.parsed
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parsed
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          340
        </td>
        <td>
          2356
          -
          2370
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.generic.GenericTraversableTemplate.flatten
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          paired.flatten[org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[Seq[org.apache.spark.sql.catalyst.expressions.Expression]])
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          339
        </td>
        <td>
          2363
          -
          2363
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[Seq[org.apache.spark.sql.catalyst.expressions.Expression]]
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          342
        </td>
        <td>
          2296
          -
          2371
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.quality.impl.UpdateFolderExpression.withArgsAndSubstitutedLambdaVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.UpdateFolderExpression.withArgsAndSubstitutedLambdaVariable(paired.flatten[org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[Seq[org.apache.spark.sql.catalyst.expressions.Expression]]))
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          341
        </td>
        <td>
          2296
          -
          2371
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.UpdateFolderExpression.withArgsAndSubstitutedLambdaVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.UpdateFolderExpression.withArgsAndSubstitutedLambdaVariable(paired.flatten[org.apache.spark.sql.catalyst.expressions.Expression](scala.Predef.$conforms[Seq[org.apache.spark.sql.catalyst.expressions.Expression]]))
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          343
        </td>
        <td>
          2507
          -
          2533
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.HasRuleText.reset
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OutputExpression.super[HasRuleText].reset()
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          345
        </td>
        <td>
          2772
          -
          2819
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.impl.RunOnPassProcessorImpl.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.quality.impl.RunOnPassProcessorImpl.apply(salience, id, e.rule, e)
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          344
        </td>
        <td>
          2809
          -
          2815
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.OutputExpression.rule
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.rule
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          346
        </td>
        <td>
          3665
          -
          3665
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.RuleSuite.copy$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSuite.this.copy$default$1
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          349
        </td>
        <td>
          3665
          -
          3698
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.quality.RuleSuite.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSuite.this.copy(x$2, x$3, x$4, x$1)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          348
        </td>
        <td>
          3665
          -
          3665
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.RuleSuite.copy$default$3
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSuite.this.copy$default$3
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          347
        </td>
        <td>
          3665
          -
          3665
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.quality.RuleSuite.copy$default$2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          RuleSuite.this.copy$default$2
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>