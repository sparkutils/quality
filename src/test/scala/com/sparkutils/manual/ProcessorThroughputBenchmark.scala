package com.sparkutils.manual

import com.sparkutils.quality.sparkless.{ProcessFunctions, Processor}
import com.sparkutils.qualityTests.ResultHelper.longSchema
import com.sparkutils.qualityTests.RowTools
import org.apache.spark.sql.types.{IntegerType, LongType}
import org.apache.spark.sql.{Row, ShimUtils}
import org.scalameter.api.Bench
import org.scalameter.api._

object ProcessorThroughputBenchmark extends Bench.OfflineReport with RowTools {

  def evaluate[T](processor: (Int, Int) => Processor[Row, T])(params: (Int, Int)) = {
    val inst = processor(params._1, params._2)
    val row = Row((0L to params._2.toLong).toIndexedSeq : _*)
    for{i <- 0 until writeRows} {
      inst(row)
    }
  }

  def startup[T](processor: (Int, Int) => Processor[Row, T])(params: (Int, Int)) = {
    processor(params._1, params._2)
  }

  /* for mutable compiled it's for 780 rules (150 in against 50 columns) 10 rows/ms 0.1ms each row, 180 rules is (150 in against 10 fields) 3.5ms - 0.000035 ms per row,
  columns more than rules dominates

  // generated by
  for{
      rules <- 25 to 150 by 25
      fields <- 10 to 50 by 10
    } {
      println(s"$rules rules $fields fields config is ${genRules(rules, fields).ruleSets.flatMap(_.rules).size} generated rules")
    }
25 rules 10 fields config is 30 generated rules
25 rules 20 fields config is 55 generated rules
25 rules 30 fields config is 80 generated rules
25 rules 40 fields config is 105 generated rules
25 rules 50 fields config is 130 generated rules
50 rules 10 fields config is 60 generated rules
50 rules 20 fields config is 110 generated rules
50 rules 30 fields config is 160 generated rules
50 rules 40 fields config is 210 generated rules
50 rules 50 fields config is 260 generated rules
75 rules 10 fields config is 90 generated rules
75 rules 20 fields config is 165 generated rules
75 rules 30 fields config is 240 generated rules
75 rules 40 fields config is 315 generated rules
75 rules 50 fields config is 390 generated rules
100 rules 10 fields config is 120 generated rules
100 rules 20 fields config is 220 generated rules
100 rules 30 fields config is 320 generated rules
100 rules 40 fields config is 420 generated rules
100 rules 50 fields config is 520 generated rules
125 rules 10 fields config is 150 generated rules
125 rules 20 fields config is 275 generated rules
125 rules 30 fields config is 400 generated rules
125 rules 40 fields config is 525 generated rules
125 rules 50 fields config is 650 generated rules
150 rules 10 fields config is 180 generated rules
150 rules 20 fields config is 330 generated rules
150 rules 30 fields config is 480 generated rules
150 rules 40 fields config is 630 generated rules
150 rules 50 fields config is 780 generated rules
25 rules 10 fields config is 30 generated rules
25 rules 20 fields config is 55 generated rules
25 rules 30 fields config is 80 generated rules
25 rules 40 fields config is 105 generated rules
25 rules 50 fields config is 130 generated rules
50 rules 10 fields config is 60 generated rules
50 rules 20 fields config is 110 generated rules
50 rules 30 fields config is 160 generated rules
50 rules 40 fields config is 210 generated rules
50 rules 50 fields config is 260 generated rules
75 rules 10 fields config is 90 generated rules
75 rules 20 fields config is 165 generated rules
75 rules 30 fields config is 240 generated rules
75 rules 40 fields config is 315 generated rules
75 rules 50 fields config is 390 generated rules
100 rules 10 fields config is 120 generated rules
100 rules 20 fields config is 220 generated rules
100 rules 30 fields config is 320 generated rules
100 rules 40 fields config is 420 generated rules
100 rules 50 fields config is 520 generated rules
125 rules 10 fields config is 150 generated rules
125 rules 20 fields config is 275 generated rules
125 rules 30 fields config is 400 generated rules
125 rules 40 fields config is 525 generated rules
125 rules 50 fields config is 650 generated rules
150 rules 10 fields config is 180 generated rules
150 rules 20 fields config is 330 generated rules
150 rules 30 fields config is 480 generated rules
150 rules 40 fields config is 630 generated rules
150 rules 50 fields config is 780 generated rules
*/

  performance of "processingDQ" config (
    exec.minWarmupRuns -> 2,
    exec.maxWarmupRuns -> 4,
    exec.benchRuns -> 4,
    exec.jvmcmd -> (System.getProperty("java.home")+"/bin/java"),
    exec.jvmflags -> List("-Xmx24g","-Xms24g")
    //  verbose -> true
  ) in {

    measure method "VarCompilation" in {
      val s = sparkSession

      val processor = (rules: Int, cols: Int) => {
        implicit val renc = ShimUtils.rowEncoder(longSchema(cols, LongType))
        ProcessFunctions.dqFactory[Row](genRules(rules, cols),
          forceVarCompilation = true).instance
      }
      using(generator) in evaluate( processor )
    }

    measure method "CompiledProjections" in {
      val s = sparkSession

      val processor = (rules: Int, cols: Int) => {
        implicit val renc = ShimUtils.rowEncoder(longSchema(cols, LongType))
        ProcessFunctions.dqFactory[Row](genRules(rules, cols),
          forceVarCompilation = false).instance
      }
      using(generator) in evaluate( processor )
    }

    measure method "MutableProjectionsCompiled" in {
      val s = sparkSession

      val processor = (rules: Int, cols: Int) => {
        implicit val renc = ShimUtils.rowEncoder(longSchema(cols, LongType))
        ProcessFunctions.dqFactory[Row](genRules(rules, cols),
          forceMutable = true).instance
      }
      using(generator) in evaluate( processor )
    }

    measure method "interpreted" in {
      val s = sparkSession

      val processor = (rules: Int, cols: Int) => {
        implicit val renc = ShimUtils.rowEncoder(longSchema(cols, LongType))
        ProcessFunctions.dqFactory[Row](genRules(rules, cols),
          compile = false).instance
      }
      using(generator) in evaluate( processor )
    }
  }

  performance of "startupTimeOnly" config (
    exec.minWarmupRuns -> 2,
    exec.maxWarmupRuns -> 4,
    exec.benchRuns -> 4,
    exec.jvmcmd -> (System.getProperty("java.home")+"/bin/java"),
    exec.jvmflags -> List("-Xmx24g","-Xms24g")
    //  verbose -> true
  ) in {
      measure method "VarCompilationStartup" in {
        val s = sparkSession

        val processor = (rules: Int, cols: Int) => {
          implicit val renc = ShimUtils.rowEncoder(longSchema(cols, LongType))
          ProcessFunctions.dqFactory[Row](genRules(rules, cols),
            forceVarCompilation = true).instance
        }
        using(generator) in startup( processor )
      }

      measure method "CompiledProjectionsStartup" in {
        val s = sparkSession

        val processor = (rules: Int, cols: Int) => {
          implicit val renc = ShimUtils.rowEncoder(longSchema(cols, LongType))
          ProcessFunctions.dqFactory[Row](genRules(rules, cols),
            forceVarCompilation = false).instance
        }
        using(generator) in startup( processor )
      }

      measure method "MutableProjectionsCompiledStartup" in {
        val s = sparkSession

        val processor = (rules: Int, cols: Int) => {
          implicit val renc = ShimUtils.rowEncoder(longSchema(cols, LongType))
          ProcessFunctions.dqFactory[Row](genRules(rules, cols),
            forceMutable = true).instance
        }
        using(generator) in startup( processor )
      }
      measure method "interpretedStartup" in {
        val s = sparkSession

        val processor = (rules: Int, cols: Int) => {
          implicit val renc = ShimUtils.rowEncoder(longSchema(cols, LongType))
          ProcessFunctions.dqFactory[Row](genRules(rules, cols),
            compile = false).instance
        }
        using(generator) in startup( processor )
      }
  }

}
